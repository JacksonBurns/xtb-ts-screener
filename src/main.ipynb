{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `XTBTSScreener.jl` - Screening Likely Transition States with Julia and Machine Learning\n",
    "This Jupyter notebook demonstrates the use of machine learning to predict if a partially-optimized initialization of a transition state, used in the study of chemical kinetics to predict rate constants, is _like to converge\"_ and produze a valid transition state or not after further simulation with expensive Density Functional Theory simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "The input data is saved in a CSV file, load it using `CSV.jl` and then partition the data into training and testing sets using `MLUtils.jl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLUtils, CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_dataloaders (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_dataloaders()\n",
    "    csv_reader = CSV.File(\"data/roo_co2_full_data_augmented_expanded.csv\")\n",
    "    n_samples = 20501\n",
    "    # there are 3274 failed examples, so we will keep all of those and balance with converged\n",
    "    x_data = Array{Float32}(undef, 60, 6, 6548)\n",
    "    labels = Float32[]\n",
    "    iter = 1\n",
    "    println(\"Progress:\")\n",
    "    \n",
    "    # keep track of number of failed to balance the dataset\n",
    "    number_converged = 0\n",
    "    number_failed = 0\n",
    "    \n",
    "    for row in csv_reader[1:n_samples]\n",
    "        # print some updates as we go\n",
    "        if mod(iter, div(n_samples, 60)) == 0\n",
    "            println(\" - row $iter of $n_samples\")\n",
    "            flush(stdout)\n",
    "        end\n",
    "        \n",
    "        # get if it converged or not, add alternating samples\n",
    "        if parse(Bool, \"$(row.converged)\") \n",
    "            if number_converged<number_failed\n",
    "                push!(labels, 1.0f0)\n",
    "                number_converged+=1\n",
    "            else\n",
    "                continue\n",
    "            end\n",
    "        else\n",
    "            push!(labels, 0.0f0)\n",
    "            number_failed+=1\n",
    "        end\n",
    "        \n",
    "        # array for descriptors for this transition state\n",
    "        m = Array{Float32}(undef, 60, 6)\n",
    "        \n",
    "        # pull out the augmented descriptors\n",
    "        split_gibbs = split(\"$(row.gibbs)\")\n",
    "        split_steps = split(\"$(row.steps)\")\n",
    "        split_e0_zpe = split(\"$(row.e0_zpe)\")\n",
    "        split_descriptors = [split_gibbs,split_steps,split_e0_zpe]\n",
    "        for i in 1:3\n",
    "            for j in 1:3\n",
    "                temp = String(split_descriptors[i][j])\n",
    "                temp = replace(temp,\"]\"=>\"\")\n",
    "                temp = replace(temp,\"[\"=>\"\")\n",
    "                temp = replace(temp,\",\"=>\"\")\n",
    "                m[i,j] = parse(Float32, temp)\n",
    "            end\n",
    "            m[i,4] = Float32(0.0)\n",
    "            m[i,5] = Float32(0.0)\n",
    "            m[i,6] = Float32(0.0)\n",
    "        end\n",
    "\n",
    "        # get the final coordinates of the atoms\n",
    "        split_array = split(\"$(row.std_xyz)\")\n",
    "        n_atoms = Int(length(split_array)/6)\n",
    "        row_counter = 4\n",
    "        column_counter = 1\n",
    "        for value in split_array\n",
    "            temp = String(value)\n",
    "            temp = replace(temp,\"]\"=>\"\")\n",
    "            temp = replace(temp,\"[\"=>\"\")\n",
    "            temp = replace(temp,\",\"=>\"\")\n",
    "            m[row_counter, column_counter] = parse(Float32, temp)\n",
    "            column_counter += 1\n",
    "            if column_counter > 6\n",
    "                column_counter = 1\n",
    "                row_counter += 1\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # zero-padding\n",
    "        for i in n_atoms+1:60\n",
    "            m[i, 1:6] = [0,0,0,0,0,0]\n",
    "        end\n",
    "        x_data[1:60, 1:6, iter] = m\n",
    "        iter += 1\n",
    "    end\n",
    "    remainingsamples = length(labels)\n",
    "    println(\"downsampled to $remainingsamples samples, $number_converged converged $number_failed failed\")\n",
    "    println(\"...loading done, partitioning data.\")\n",
    "    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)\n",
    "    return (DataLoader(collect.((x_train, y_train)); batchsize=2^6, shuffle=true),\n",
    "            DataLoader(collect.((x_val, y_val)); batchsize=2^6, shuffle=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of debugging and as a reference, the original tutorial dataloading function is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_tutorial_dataloaders (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_tutorial_dataloaders()\n",
    "    dataset_size=1000\n",
    "    sequence_length=50\n",
    "    data = [MLUtils.Datasets.make_spiral(sequence_length) for _ in 1:dataset_size]\n",
    "    # Get the labels\n",
    "    labels = vcat(repeat([0.0f0], dataset_size รท 2), repeat([1.0f0], dataset_size รท 2))\n",
    "    clockwise_spirals = [reshape(d[1][:, 1:sequence_length], :, sequence_length, 1)\n",
    "                         for d in data[1:(dataset_size รท 2)]]\n",
    "    anticlockwise_spirals = [reshape(d[1][:, (sequence_length + 1):end], :, sequence_length,\n",
    "                                     1) for d in data[((dataset_size รท 2) + 1):end]]\n",
    "    x_data = Float32.(cat(clockwise_spirals..., anticlockwise_spirals...; dims=3))\n",
    "    # Split the dataset\n",
    "    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)\n",
    "    return (DataLoader(collect.((x_train, y_train)); batchsize=128, shuffle=true),\n",
    "            DataLoader(collect.((x_val, y_val)); batchsize=128, shuffle=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Neural Network\n",
    "Following from the tutorial in the [Lux documentation](https://lux.csail.mit.edu/stable/examples/generated/beginner/SimpleRNN/main/) we write a series of functions that will create our NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Lux, Random, Optimisers, Zygote, NNlib, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeding\n",
    "rng = Random.default_rng()\n",
    "Random.seed!(rng, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct StateClassifier{L, C} <:\n",
    "       Lux.AbstractExplicitContainerLayer{(:lstm_cell, :classifier)}\n",
    "    lstm_cell::L\n",
    "    classifier::C\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateClassifier"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function StateClassifier(in_dims, hidden_dims, out_dims)\n",
    "    return StateClassifier(LSTMCell(in_dims => hidden_dims),\n",
    "                            Dense(hidden_dims => out_dims, sigmoid))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (s::StateClassifier)(x::AbstractArray{T, 3}, ps::NamedTuple,\n",
    "                               st::NamedTuple) where {T}\n",
    "    x_init, x_rest = Iterators.peel(eachslice(x; dims=2))\n",
    "    (y, carry), st_lstm = s.lstm_cell(x_init, ps.lstm_cell, st.lstm_cell)\n",
    "    for x in x_rest\n",
    "        (y, carry), st_lstm = s.lstm_cell((x, carry), ps.lstm_cell, st_lstm)\n",
    "    end\n",
    "    y, st_classifier = s.classifier(y, ps.classifier, st.classifier)\n",
    "    st = merge(st, (classifier=st_classifier, lstm_cell=st_lstm))\n",
    "    return vec(y), st\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function xlogy(x, y)\n",
    "    result = x * log(y)\n",
    "    return ifelse(iszero(x), zero(result), result)\n",
    "end\n",
    "\n",
    "function binarycrossentropy(y_pred, y_true)\n",
    "    y_pred = y_pred .+ eps(eltype(y_pred))\n",
    "    return mean(@. -xlogy(y_true, y_pred) - xlogy(1 - y_true, 1 - y_pred))\n",
    "end\n",
    "\n",
    "function compute_loss(x, y, model, ps, st)\n",
    "    y_pred, st = model(x, ps, st)\n",
    "    return binarycrossentropy(y_pred, y), y_pred, st\n",
    "end\n",
    "\n",
    "matches(y_pred, y_true) = sum((y_pred .> 0.5) .== y_true)\n",
    "accuracy(y_pred, y_true) = matches(y_pred, y_true) / length(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_optimiser (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_optimiser(ps)\n",
    "    opt = Optimisers.ADAM(0.0001f0)\n",
    "    return Optimisers.setup(opt, ps)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NN\n",
    "Actual training and evaluation steps.\n",
    "\n",
    "Load the data from the file and parition it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:\n",
      " - row 341 of 20501\n",
      " - row 341 of 20501\n",
      " - row 341 of 20501\n",
      " - row 682 of 20501\n",
      " - row 1023 of 20501\n",
      " - row 1364 of 20501\n",
      " - row 1705 of 20501\n",
      " - row 2046 of 20501\n",
      " - row 2387 of 20501\n",
      " - row 2387 of 20501\n",
      " - row 2728 of 20501\n",
      " - row 3069 of 20501\n",
      " - row 3410 of 20501\n",
      " - row 3751 of 20501\n",
      " - row 3751 of 20501\n",
      " - row 3751 of 20501\n",
      " - row 3751 of 20501\n",
      " - row 3751 of 20501\n",
      " - row 3751 of 20501\n",
      " - row 3751 of 20501\n",
      " - row 3751 of 20501\n",
      " - row 4092 of 20501\n",
      " - row 4433 of 20501\n",
      " - row 4433 of 20501\n",
      " - row 4433 of 20501\n",
      " - row 4774 of 20501\n",
      " - row 5115 of 20501\n",
      " - row 5115 of 20501\n",
      " - row 5115 of 20501\n",
      " - row 5115 of 20501\n",
      " - row 5115 of 20501\n",
      " - row 5456 of 20501\n",
      " - row 5797 of 20501\n",
      " - row 5797 of 20501\n",
      " - row 6138 of 20501\n",
      " - row 6479 of 20501\n",
      " - row 6479 of 20501\n",
      " - row 6479 of 20501\n",
      " - row 6479 of 20501\n",
      " - row 6479 of 20501\n",
      " - row 6479 of 20501\n",
      " - row 6479 of 20501\n",
      " - row 6479 of 20501\n",
      " - row 6479 of 20501\n",
      " - row 6479 of 20501\n",
      "downsampled to 6548 samples, 3274 converged 3274 failed\n",
      "...loading done, partitioning data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DataLoader(::Tuple{Array{Float32, 3}, Vector{Float32}}, shuffle=true, batchsize=64), DataLoader(::Tuple{Array{Float32, 3}, Vector{Float32}}, batchsize=64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_loader, val_loader) = get_dataloaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(lstm_cell = (weight_i = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 โฆ 0.0 0.0; 0.0 0.0 โฆ 0.0 0.0; โฆ ; 0.0 0.0 โฆ 0.0 0.0; 0.0 0.0 โฆ 0.0 0.0], Float32[0.0 0.0 โฆ 0.0 0.0; 0.0 0.0 โฆ 0.0 0.0; โฆ ; 0.0 0.0 โฆ 0.0 0.0; 0.0 0.0 โฆ 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, weight_h = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 โฆ 0.0 0.0; 0.0 0.0 โฆ 0.0 0.0; โฆ ; 0.0 0.0 โฆ 0.0 0.0; 0.0 0.0 โฆ 0.0 0.0], Float32[0.0 0.0 โฆ 0.0 0.0; 0.0 0.0 โฆ 0.0 0.0; โฆ ; 0.0 0.0 โฆ 0.0 0.0; 0.0 0.0 โฆ 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0; 0.0; โฆ ; 0.0; 0.0;;], Float32[0.0; 0.0; โฆ ; 0.0; 0.0;;], (0.9, 0.999))\u001b[32m)\u001b[39m), classifier = (weight = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 โฆ 0.0 0.0], Float32[0.0 0.0 โฆ 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0;;], Float32[0.0;;], (0.9, 0.999))\u001b[32m)\u001b[39m))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StateClassifier(60, 6, 1)\n",
    "rng = Random.default_rng()\n",
    "Random.seed!(rng, 0)\n",
    "ps, st = Lux.setup(rng, model)\n",
    "opt_state = create_optimiser(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual model training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1:\n",
      " - loss of 0.7282473619391279\n",
      " - accuracy of 0.5146825396825397\n",
      "Epoch # 5:\n",
      " - loss of 0.7089660269458119\n",
      " - accuracy of 0.5236111111111111\n",
      "Epoch # 10:\n",
      " - loss of 0.6943259777092352\n",
      " - accuracy of 0.5287202380952382\n",
      "Epoch # 15:\n",
      " - loss of 0.686766859961719\n",
      " - accuracy of 0.5387896825396825\n",
      "Epoch # 20:\n",
      " - loss of 0.6815697768839394\n",
      " - accuracy of 0.5472718253968254\n",
      "Epoch # 25:\n",
      " - loss of 0.6774497729976002\n",
      " - accuracy of 0.5570436507936508\n",
      "Epoch # 30:\n",
      " - loss of 0.6739311807039308\n",
      " - accuracy of 0.5617063492063492\n",
      "Epoch # 35:\n",
      " - loss of 0.6705420882236667\n",
      " - accuracy of 0.5556547619047618\n",
      "Epoch # 40:\n",
      " - loss of 0.6674438722249938\n",
      " - accuracy of 0.5660714285714286\n",
      "Epoch # 45:\n",
      " - loss of 0.6641433820491884\n",
      " - accuracy of 0.5712797619047618\n",
      "Epoch # 50:\n",
      " - loss of 0.661274130751447\n",
      " - accuracy of 0.5734126984126984\n",
      "Epoch # 55:\n",
      " - loss of 0.6587260307335272\n",
      " - accuracy of 0.5696924603174602\n"
     ]
    }
   ],
   "source": [
    "loss_vector = Float64[]\n",
    "accuracy_vector = Float64[]\n",
    "for epoch in 1:55\n",
    "    # Train the model\n",
    "    epoch_loss = Float64[]\n",
    "    for (x, y) in train_loader\n",
    "        (loss, y_pred, st), back = pullback(p -> compute_loss(x, y, model, p, st), ps)\n",
    "        gs = back((one(loss), nothing, nothing))[1]\n",
    "        opt_state, ps = Optimisers.update(opt_state, ps, gs)\n",
    "        push!(epoch_loss, loss)\n",
    "    end\n",
    "    avg_loss = mean(epoch_loss)\n",
    "    push!(loss_vector, avg_loss)\n",
    "\n",
    "    # Validate the model\n",
    "    epoch_accuracy = Float64[]\n",
    "    st_ = Lux.testmode(st)\n",
    "    for (x, y) in val_loader\n",
    "        (loss, y_pred, st_) = compute_loss(x, y, model, ps, st_)\n",
    "        acc = accuracy(y_pred, y)\n",
    "        push!(epoch_accuracy, acc)\n",
    "    end\n",
    "    avg_accuracy = mean(epoch_accuracy)\n",
    "    if epoch == 1 || mod(epoch, 5) == 0\n",
    "        println(\"Epoch # $epoch:\\n - loss of $avg_loss\")\n",
    "        println(\" - accuracy of $avg_accuracy\")\n",
    "        flush(stdout)\n",
    "    end\n",
    "    push!(accuracy_vector, avg_accuracy)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "plot(loss_vector, label=\"loss\", legend=:bottom, color=:red, rightmargin = 1.5Plots.cm, bottommargin = 0.5Plots.cm, box = :on, fmt = :png)\n",
    "plot!(twinx(), accuracy_vector, label=\"accuracy\", legend=:bottomleft, xlabel=\"epoch\", rightmargin = 1.5Plots.cm, bottommargin = 0.5Plots.cm, box = :on)\n",
    "using Dates\n",
    "timestamp = now()\n",
    "savefig(\"result-$timestamp.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JuliaLuxMLUtils 1.7.3",
   "language": "julia",
   "name": "julialuxmlutils-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
