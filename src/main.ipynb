{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `XTBTSScreener.jl` - Screening Likely Transition States with Julia and Machine Learning\n",
    "This Jupyter notebook demonstrates the use of machine learning to predict if a partially-optimized initialization of a transition state, used in the study of chemical kinetics to predict rate constants, is _like to converge\"_ and produze a valid transition state or not after further simulation with expensive Density Functional Theory simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "The input data is saved in a CSV file, load it using `CSV.jl` and then partition the data into training and testing sets using `MLUtils.jl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLUtils, CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_dataloaders (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_dataloaders()\n",
    "    csv_reader = CSV.File(\"data/roo_co2_full_data.csv\")\n",
    "    n_samples = 16517\n",
    "    x_data = Array{Float32}(undef, 55, 6, n_samples)\n",
    "    labels = Float32[]\n",
    "    iter = 1\n",
    "    println(\"Progress:\")\n",
    "    for row in csv_reader[1:n_samples]\n",
    "        # print some updates as we go\n",
    "        if mod(iter, div(n_samples, 25)) == 0\n",
    "            println(\" - row $iter of $n_samples\")\n",
    "            flush(stdout)\n",
    "        end\n",
    "        \n",
    "        # get if it converged or not\n",
    "        if parse(Bool, \"$(row.converged)\")\n",
    "            push!(labels, 1.0f0)\n",
    "        else\n",
    "            push!(labels, 0.0f0)\n",
    "        end\n",
    "\n",
    "        # get the final coordinates of the atoms\n",
    "        split_array = split(\"$(row.std_xyz)\")\n",
    "        n_atoms = Int(length(split_array)/6)\n",
    "        m = Array{Float32}(undef, 55, 6)\n",
    "        row_counter = 1\n",
    "        column_counter = 1\n",
    "        for value in split_array\n",
    "            temp = String(value)\n",
    "            temp = replace(temp,\"]\"=>\"\")\n",
    "            temp = replace(temp,\"[\"=>\"\")\n",
    "            temp = replace(temp,\",\"=>\"\")\n",
    "            m[row_counter, column_counter] = parse(Float32, temp)\n",
    "            column_counter += 1\n",
    "            if column_counter > 6\n",
    "                column_counter = 1\n",
    "                row_counter += 1\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # zero-padding\n",
    "        for i in n_atoms+1:55\n",
    "            m[i, 1:6] = [0,0,0,0,0,0]\n",
    "        end\n",
    "        x_data[1:55, 1:6, iter] = m\n",
    "        iter += 1\n",
    "    end\n",
    "    println(\"loading done, partitioning data.\")\n",
    "    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)\n",
    "    return (DataLoader(collect.((x_train, y_train)); batchsize=2^4, shuffle=true),\n",
    "            DataLoader(collect.((x_val, y_val)); batchsize=2^4, shuffle=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of debuggin and as a reference, the original tutorial dataloading function is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_tutorial_dataloaders (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_tutorial_dataloaders()\n",
    "    dataset_size=1000\n",
    "    sequence_length=50\n",
    "    data = [MLUtils.Datasets.make_spiral(sequence_length) for _ in 1:dataset_size]\n",
    "    # Get the labels\n",
    "    labels = vcat(repeat([0.0f0], dataset_size ÷ 2), repeat([1.0f0], dataset_size ÷ 2))\n",
    "    clockwise_spirals = [reshape(d[1][:, 1:sequence_length], :, sequence_length, 1)\n",
    "                         for d in data[1:(dataset_size ÷ 2)]]\n",
    "    anticlockwise_spirals = [reshape(d[1][:, (sequence_length + 1):end], :, sequence_length,\n",
    "                                     1) for d in data[((dataset_size ÷ 2) + 1):end]]\n",
    "    x_data = Float32.(cat(clockwise_spirals..., anticlockwise_spirals...; dims=3))\n",
    "    # Split the dataset\n",
    "    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)\n",
    "    return (DataLoader(collect.((x_train, y_train)); batchsize=128, shuffle=true),\n",
    "            DataLoader(collect.((x_val, y_val)); batchsize=128, shuffle=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Neural Network\n",
    "Following from the tutorial in the [Lux documentation](https://lux.csail.mit.edu/stable/examples/generated/beginner/SimpleRNN/main/) we write a series of functions that will create our NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Lux, Random, Optimisers, Zygote, NNlib, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeding\n",
    "rng = Random.default_rng()\n",
    "Random.seed!(rng, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct StateClassifier{L, C} <:\n",
    "       Lux.AbstractExplicitContainerLayer{(:lstm_cell, :classifier)}\n",
    "    lstm_cell::L\n",
    "    classifier::C\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateClassifier"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function StateClassifier(in_dims, hidden_dims, out_dims)\n",
    "    return StateClassifier(LSTMCell(in_dims => hidden_dims),\n",
    "                            Dense(hidden_dims => out_dims, sigmoid))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (s::StateClassifier)(x::AbstractArray{T, 3}, ps::NamedTuple,\n",
    "                               st::NamedTuple) where {T}\n",
    "    x_init, x_rest = Iterators.peel(eachslice(x; dims=2))\n",
    "    (y, carry), st_lstm = s.lstm_cell(x_init, ps.lstm_cell, st.lstm_cell)\n",
    "    for x in x_rest\n",
    "        (y, carry), st_lstm = s.lstm_cell((x, carry), ps.lstm_cell, st_lstm)\n",
    "    end\n",
    "    y, st_classifier = s.classifier(y, ps.classifier, st.classifier)\n",
    "    st = merge(st, (classifier=st_classifier, lstm_cell=st_lstm))\n",
    "    return vec(y), st\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function xlogy(x, y)\n",
    "    result = x * log(y)\n",
    "    return ifelse(iszero(x), zero(result), result)\n",
    "end\n",
    "\n",
    "function binarycrossentropy(y_pred, y_true)\n",
    "    y_pred = y_pred .+ eps(eltype(y_pred))\n",
    "    return mean(@. -xlogy(y_true, y_pred) - xlogy(1 - y_true, 1 - y_pred))\n",
    "end\n",
    "\n",
    "function compute_loss(x, y, model, ps, st)\n",
    "    y_pred, st = model(x, ps, st)\n",
    "    return binarycrossentropy(y_pred, y), y_pred, st\n",
    "end\n",
    "\n",
    "matches(y_pred, y_true) = sum((y_pred .> 0.5) .== y_true)\n",
    "accuracy(y_pred, y_true) = matches(y_pred, y_true) / length(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_optimiser (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_optimiser(ps)\n",
    "    opt = Optimisers.ADAM(0.0001f0)\n",
    "    return Optimisers.setup(opt, ps)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NN\n",
    "Actual training and evaluation steps.\n",
    "\n",
    "Load the data from the file and parition it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:\n",
      " - row 660 of 16517\n",
      " - row 1320 of 16517\n",
      " - row 1980 of 16517\n",
      " - row 2640 of 16517\n",
      " - row 3300 of 16517\n",
      " - row 3960 of 16517\n",
      " - row 4620 of 16517\n",
      " - row 5280 of 16517\n",
      " - row 5940 of 16517\n",
      " - row 6600 of 16517\n",
      " - row 7260 of 16517\n",
      " - row 7920 of 16517\n",
      " - row 8580 of 16517\n",
      " - row 9240 of 16517\n",
      " - row 9900 of 16517\n",
      " - row 10560 of 16517\n",
      " - row 11220 of 16517\n",
      " - row 11880 of 16517\n",
      " - row 12540 of 16517\n",
      " - row 13200 of 16517\n",
      " - row 13860 of 16517\n",
      " - row 14520 of 16517\n",
      " - row 15180 of 16517\n",
      " - row 15840 of 16517\n",
      " - row 16500 of 16517\n",
      "loading done, partitioning data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DataLoader(::Tuple{Array{Float32, 3}, Vector{Float32}}, shuffle=true, batchsize=16), DataLoader(::Tuple{Array{Float32, 3}, Vector{Float32}}, batchsize=16))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_loader, val_loader) = get_dataloaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(lstm_cell = (weight_i = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, weight_h = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0; 0.0; … ; 0.0; 0.0;;], Float32[0.0; 0.0; … ; 0.0; 0.0;;], (0.9, 0.999))\u001b[32m)\u001b[39m), classifier = (weight = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0;;], Float32[0.0;;], (0.9, 0.999))\u001b[32m)\u001b[39m))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StateClassifier(55, 6, 1)\n",
    "rng = Random.default_rng()\n",
    "Random.seed!(rng, 0)\n",
    "ps, st = Lux.setup(rng, model)\n",
    "opt_state = create_optimiser(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual model training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1:\n",
      " - loss of 0.5211532165005478\n",
      " - accuracy of 0.8057712215320911\n",
      "Epoch # 2:\n",
      " - loss of 0.49489579337128137\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 3:\n",
      " - loss of 0.4861325481252578\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 4:\n",
      " - loss of 0.48275915587424656\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 5:\n",
      " - loss of 0.48101673636035247\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 6:\n",
      " - loss of 0.47967421896665496\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 7:\n",
      " - loss of 0.4784496566573875\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 8:\n",
      " - loss of 0.4773907147474208\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 9:\n",
      " - loss of 0.4764636383543003\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 10:\n",
      " - loss of 0.4755229091420589\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 11:\n",
      " - loss of 0.4746417457521972\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 12:\n",
      " - loss of 0.4738314503185974\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 13:\n",
      " - loss of 0.4730674123828983\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 14:\n",
      " - loss of 0.4723413454562642\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 15:\n",
      " - loss of 0.4717325728936865\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 16:\n",
      " - loss of 0.4710771930528033\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 17:\n",
      " - loss of 0.4704794599415315\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 18:\n",
      " - loss of 0.46991492237796506\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 19:\n",
      " - loss of 0.46930605063066066\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 20:\n",
      " - loss of 0.4687926310315259\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 21:\n",
      " - loss of 0.46826593599509964\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 22:\n",
      " - loss of 0.46780917165715236\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 23:\n",
      " - loss of 0.4672096983031268\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 24:\n",
      " - loss of 0.46679676031878725\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 25:\n",
      " - loss of 0.46629284287985534\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 26:\n",
      " - loss of 0.4658414035963377\n",
      " - accuracy of 0.8066770186335404\n",
      "Epoch # 27:\n",
      " - loss of 0.4653898224270661\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 28:\n",
      " - loss of 0.4649319184750102\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 29:\n",
      " - loss of 0.46449331136433897\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 30:\n",
      " - loss of 0.464021550829705\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 31:\n",
      " - loss of 0.4635823269805377\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 32:\n",
      " - loss of 0.4632180029882646\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 33:\n",
      " - loss of 0.4628146000873956\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 34:\n",
      " - loss of 0.46236113197289713\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 35:\n",
      " - loss of 0.46198523845568695\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 36:\n",
      " - loss of 0.46160054378229537\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 37:\n",
      " - loss of 0.4611719611662352\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 38:\n",
      " - loss of 0.4608061144412574\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 39:\n",
      " - loss of 0.46036471617712527\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 40:\n",
      " - loss of 0.4599296160890173\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 41:\n",
      " - loss of 0.45955928254502737\n",
      " - accuracy of 0.8060731538992408\n",
      "Epoch # 42:\n",
      " - loss of 0.459129830375855\n",
      " - accuracy of 0.8060731538992408\n",
      "Epoch # 43:\n",
      " - loss of 0.45872469448437125\n",
      " - accuracy of 0.8060731538992408\n",
      "Epoch # 44:\n",
      " - loss of 0.45836144673117135\n",
      " - accuracy of 0.8057712215320911\n",
      "Epoch # 45:\n",
      " - loss of 0.4579828336257623\n",
      " - accuracy of 0.8057712215320911\n",
      "Epoch # 46:\n",
      " - loss of 0.45754403736415267\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 47:\n",
      " - loss of 0.45722438395023346\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 48:\n",
      " - loss of 0.4568095062171576\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 49:\n",
      " - loss of 0.456493322861541\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 50:\n",
      " - loss of 0.45606797648544173\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 51:\n",
      " - loss of 0.4556802340916225\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 52:\n",
      " - loss of 0.4553516900423941\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 53:\n",
      " - loss of 0.45498689785419305\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 54:\n",
      " - loss of 0.4545823011105343\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 55:\n",
      " - loss of 0.454195418023024\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 56:\n",
      " - loss of 0.45383943958302675\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 57:\n",
      " - loss of 0.4534666621403602\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 58:\n",
      " - loss of 0.45315601431356506\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 59:\n",
      " - loss of 0.4527703383644326\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 60:\n",
      " - loss of 0.4524763646844513\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 61:\n",
      " - loss of 0.452010570910306\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 62:\n",
      " - loss of 0.45176442059492083\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 63:\n",
      " - loss of 0.45138081220896425\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 64:\n",
      " - loss of 0.45099506251171195\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 65:\n",
      " - loss of 0.450724787468916\n",
      " - accuracy of 0.8048654244306418\n",
      "Epoch # 66:\n",
      " - loss of 0.45036390059363757\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 67:\n",
      " - loss of 0.4500322169635544\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 68:\n",
      " - loss of 0.4496834811553828\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 69:\n",
      " - loss of 0.44937525774390585\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 70:\n",
      " - loss of 0.4489819662911551\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 71:\n",
      " - loss of 0.4486882532552137\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 72:\n",
      " - loss of 0.44836947495077195\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 73:\n",
      " - loss of 0.44799616687522964\n",
      " - accuracy of 0.8048654244306418\n",
      "Epoch # 74:\n",
      " - loss of 0.4476895712983522\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 75:\n",
      " - loss of 0.44733956448968326\n",
      " - accuracy of 0.8045634920634921\n",
      "Epoch # 76:\n",
      " - loss of 0.4470516158037844\n",
      " - accuracy of 0.8045634920634921\n",
      "Epoch # 77:\n",
      " - loss of 0.44667626174108166\n",
      " - accuracy of 0.8042615596963423\n",
      "Epoch # 78:\n",
      " - loss of 0.446425578694511\n",
      " - accuracy of 0.8042615596963423\n",
      "Epoch # 79:\n",
      " - loss of 0.44609734316787186\n",
      " - accuracy of 0.8042615596963423\n",
      "Epoch # 80:\n",
      " - loss of 0.4457911539092191\n",
      " - accuracy of 0.8042615596963423\n",
      "Epoch # 81:\n",
      " - loss of 0.4454896572896124\n",
      " - accuracy of 0.8042615596963423\n",
      "Epoch # 82:\n",
      " - loss of 0.445161677716575\n",
      " - accuracy of 0.8039596273291926\n",
      "Epoch # 83:\n",
      " - loss of 0.4447978606163445\n",
      " - accuracy of 0.8039596273291926\n",
      "Epoch # 84:\n",
      " - loss of 0.4445753701879095\n",
      " - accuracy of 0.8036576949620428\n",
      "Epoch # 85:\n",
      " - loss of 0.44414173633076665\n",
      " - accuracy of 0.8036576949620428\n",
      "Epoch # 86:\n",
      " - loss of 0.44392924984921556\n",
      " - accuracy of 0.8036576949620428\n",
      "Epoch # 87:\n",
      " - loss of 0.44361990066042245\n",
      " - accuracy of 0.803355762594893\n",
      "Epoch # 88:\n",
      " - loss of 0.443363579382475\n",
      " - accuracy of 0.8030538302277432\n",
      "Epoch # 89:\n",
      " - loss of 0.4429672764699915\n",
      " - accuracy of 0.8030538302277432\n",
      "Epoch # 90:\n",
      " - loss of 0.4426994161369148\n",
      " - accuracy of 0.8030538302277432\n",
      "Epoch # 91:\n",
      " - loss of 0.4424131919808018\n",
      " - accuracy of 0.8030538302277432\n",
      "Epoch # 92:\n",
      " - loss of 0.4421354240803251\n",
      " - accuracy of 0.8027518978605935\n",
      "Epoch # 93:\n",
      " - loss of 0.44185787946274435\n",
      " - accuracy of 0.8027518978605935\n",
      "Epoch # 94:\n",
      " - loss of 0.4415348783748779\n",
      " - accuracy of 0.8027518978605935\n",
      "Epoch # 95:\n",
      " - loss of 0.44124522440802966\n",
      " - accuracy of 0.8027518978605935\n",
      "Epoch # 96:\n",
      " - loss of 0.4409714300032101\n",
      " - accuracy of 0.8024499654934438\n",
      "Epoch # 97:\n",
      " - loss of 0.44062508096057046\n",
      " - accuracy of 0.8024499654934438\n",
      "Epoch # 98:\n",
      " - loss of 0.4403729555862291\n",
      " - accuracy of 0.802148033126294\n",
      "Epoch # 99:\n",
      " - loss of 0.44006335342045844\n",
      " - accuracy of 0.802148033126294\n",
      "Epoch # 100:\n",
      " - loss of 0.4398000379686061\n",
      " - accuracy of 0.8012422360248448\n",
      "Epoch # 101:\n",
      " - loss of 0.43948172992568907\n",
      " - accuracy of 0.8015441683919945\n",
      "Epoch # 102:\n",
      " - loss of 0.43926552923048956\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 103:\n",
      " - loss of 0.4390054465729301\n",
      " - accuracy of 0.8012422360248448\n",
      "Epoch # 104:\n",
      " - loss of 0.4386323889667849\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 105:\n",
      " - loss of 0.43839434844601816\n",
      " - accuracy of 0.8012422360248448\n",
      "Epoch # 106:\n",
      " - loss of 0.43809672423410645\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 107:\n",
      " - loss of 0.4378488444459352\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 108:\n",
      " - loss of 0.4375979846239667\n",
      " - accuracy of 0.8003364389233955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 109:\n",
      " - loss of 0.4373639938004369\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 110:\n",
      " - loss of 0.4370436503869858\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 111:\n",
      " - loss of 0.4367962864748502\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 112:\n",
      " - loss of 0.43652178890119164\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 113:\n",
      " - loss of 0.4362448503152799\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 114:\n",
      " - loss of 0.43593391263744735\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 115:\n",
      " - loss of 0.4356836666855916\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 116:\n",
      " - loss of 0.43544008770447956\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 117:\n",
      " - loss of 0.43521992562758144\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 118:\n",
      " - loss of 0.43491322370403906\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 119:\n",
      " - loss of 0.43472839754805437\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 120:\n",
      " - loss of 0.4344160493201696\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 121:\n",
      " - loss of 0.43425438630667496\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 122:\n",
      " - loss of 0.4339536415282231\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 123:\n",
      " - loss of 0.43365487838772826\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 124:\n",
      " - loss of 0.4334413312537907\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 125:\n",
      " - loss of 0.43319054855344946\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 126:\n",
      " - loss of 0.43290165723380397\n",
      " - accuracy of 0.7997325741890959\n",
      "Epoch # 127:\n",
      " - loss of 0.432648395095697\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 128:\n",
      " - loss of 0.4324733333134478\n",
      " - accuracy of 0.7997325741890959\n",
      "Epoch # 129:\n",
      " - loss of 0.4321729929590052\n",
      " - accuracy of 0.7997325741890959\n",
      "Epoch # 130:\n",
      " - loss of 0.4319809294208776\n",
      " - accuracy of 0.7988267770876467\n",
      "Epoch # 131:\n",
      " - loss of 0.43172282914994126\n",
      " - accuracy of 0.7994306418219462\n",
      "Epoch # 132:\n",
      " - loss of 0.43142384959984637\n",
      " - accuracy of 0.7997325741890959\n",
      "Epoch # 133:\n",
      " - loss of 0.4312666960367279\n",
      " - accuracy of 0.7991287094547964\n",
      "Epoch # 134:\n",
      " - loss of 0.43098023173018174\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 135:\n",
      " - loss of 0.4307320887182296\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 136:\n",
      " - loss of 0.4305471742196464\n",
      " - accuracy of 0.7994306418219462\n",
      "Epoch # 137:\n",
      " - loss of 0.4303511242059761\n",
      " - accuracy of 0.7997325741890959\n",
      "Epoch # 138:\n",
      " - loss of 0.43012203553975636\n",
      " - accuracy of 0.7988267770876467\n",
      "Epoch # 139:\n",
      " - loss of 0.42991800229211696\n",
      " - accuracy of 0.7988267770876467\n",
      "Epoch # 140:\n",
      " - loss of 0.4296494650566549\n",
      " - accuracy of 0.7988267770876467\n",
      "Epoch # 141:\n",
      " - loss of 0.4294239082362404\n",
      " - accuracy of 0.7994306418219462\n",
      "Epoch # 142:\n",
      " - loss of 0.42923822455992133\n",
      " - accuracy of 0.7988267770876467\n",
      "Epoch # 143:\n",
      " - loss of 0.4290398236986511\n",
      " - accuracy of 0.7988267770876467\n",
      "Epoch # 144:\n",
      " - loss of 0.42885783022454516\n",
      " - accuracy of 0.7991287094547964\n",
      "Epoch # 145:\n",
      " - loss of 0.4286087171939037\n",
      " - accuracy of 0.7988267770876467\n",
      "Epoch # 146:\n",
      " - loss of 0.42814464472035807\n",
      " - accuracy of 0.7952035886818496\n",
      "Epoch # 147:\n",
      " - loss of 0.42816583469473996\n",
      " - accuracy of 0.7973171152518979\n",
      "Epoch # 148:\n",
      " - loss of 0.4279610459798762\n",
      " - accuracy of 0.7973171152518979\n",
      "Epoch # 149:\n",
      " - loss of 0.42772898229502015\n",
      " - accuracy of 0.7976190476190477\n",
      "Epoch # 150:\n",
      " - loss of 0.4276640875756596\n",
      " - accuracy of 0.7961093857832988\n",
      "Epoch # 151:\n",
      " - loss of 0.427326007739395\n",
      " - accuracy of 0.7955055210489993\n",
      "Epoch # 152:\n",
      " - loss of 0.4271588762793645\n",
      " - accuracy of 0.7958074534161491\n",
      "Epoch # 153:\n",
      " - loss of 0.42697796377085023\n",
      " - accuracy of 0.7964113181504486\n",
      "Epoch # 154:\n",
      " - loss of 0.4266583631243602\n",
      " - accuracy of 0.7958074534161491\n",
      "Epoch # 155:\n",
      " - loss of 0.4266290273382069\n",
      " - accuracy of 0.7967132505175983\n",
      "Epoch # 156:\n",
      " - loss of 0.42641808401080655\n",
      " - accuracy of 0.7967132505175983\n",
      "Epoch # 157:\n",
      " - loss of 0.42619386820469873\n",
      " - accuracy of 0.7967132505175983\n",
      "Epoch # 158:\n",
      " - loss of 0.4260590240521668\n",
      " - accuracy of 0.7955055210489993\n",
      "Epoch # 159:\n",
      " - loss of 0.42589277378114315\n",
      " - accuracy of 0.7939958592132506\n",
      "Epoch # 160:\n",
      " - loss of 0.4256568490899648\n",
      " - accuracy of 0.7961093857832988\n",
      "Epoch # 161:\n",
      " - loss of 0.42544611153749806\n",
      " - accuracy of 0.7949016563146998\n",
      "Epoch # 162:\n",
      " - loss of 0.4252355741494793\n",
      " - accuracy of 0.793391994478951\n",
      "Epoch # 163:\n",
      " - loss of 0.4250010404618543\n",
      " - accuracy of 0.7936939268461007\n",
      "Epoch # 164:\n",
      " - loss of 0.4249696021687609\n",
      " - accuracy of 0.792184265010352\n",
      "Epoch # 165:\n",
      " - loss of 0.42471475799998704\n",
      " - accuracy of 0.7924861973775017\n",
      "Epoch # 166:\n",
      " - loss of 0.4244812905211137\n",
      " - accuracy of 0.792184265010352\n",
      "Epoch # 167:\n",
      " - loss of 0.42438777524427695\n",
      " - accuracy of 0.7927881297446515\n",
      "Epoch # 168:\n",
      " - loss of 0.4240787696932188\n",
      " - accuracy of 0.7927881297446515\n",
      "Epoch # 169:\n",
      " - loss of 0.42400836074143\n",
      " - accuracy of 0.7930900621118012\n",
      "Epoch # 170:\n",
      " - loss of 0.4238911950667603\n",
      " - accuracy of 0.7927881297446515\n",
      "Epoch # 171:\n",
      " - loss of 0.4235994925510508\n",
      " - accuracy of 0.7942977915804003\n",
      "Epoch # 172:\n",
      " - loss of 0.4234238840170547\n",
      " - accuracy of 0.7927881297446515\n",
      "Epoch # 173:\n",
      " - loss of 0.4233015351646893\n",
      " - accuracy of 0.7927881297446515\n",
      "Epoch # 174:\n",
      " - loss of 0.42304466293164084\n",
      " - accuracy of 0.7930900621118012\n",
      "Epoch # 175:\n",
      " - loss of 0.4229082439194003\n",
      " - accuracy of 0.7924861973775017\n",
      "Epoch # 176:\n",
      " - loss of 0.4227206339793546\n",
      " - accuracy of 0.7930900621118012\n",
      "Epoch # 177:\n",
      " - loss of 0.4225425393327385\n",
      " - accuracy of 0.7924861973775017\n",
      "Epoch # 178:\n",
      " - loss of 0.42237218627232614\n",
      " - accuracy of 0.7927881297446515\n",
      "Epoch # 179:\n",
      " - loss of 0.42225073730757967\n",
      " - accuracy of 0.7924861973775017\n",
      "Epoch # 180:\n",
      " - loss of 0.4219737468562461\n",
      " - accuracy of 0.792184265010352\n",
      "Epoch # 181:\n",
      " - loss of 0.42195328308797053\n",
      " - accuracy of 0.7912784679089027\n",
      "Epoch # 182:\n",
      " - loss of 0.42167570655737024\n",
      " - accuracy of 0.7918823326432022\n",
      "Epoch # 183:\n",
      " - loss of 0.42149496534004915\n",
      " - accuracy of 0.7918823326432022\n",
      "Epoch # 184:\n",
      " - loss of 0.42134844113060116\n",
      " - accuracy of 0.7915804002760525\n",
      "Epoch # 185:\n",
      " - loss of 0.42124852588621237\n",
      " - accuracy of 0.792184265010352\n",
      "Epoch # 186:\n",
      " - loss of 0.42105759535949977\n",
      " - accuracy of 0.7900707384403037\n",
      "Epoch # 187:\n",
      " - loss of 0.4208724689884134\n",
      " - accuracy of 0.790976535541753\n",
      "Epoch # 188:\n",
      " - loss of 0.4206340988290656\n",
      " - accuracy of 0.7906746031746031\n",
      "Epoch # 189:\n",
      " - loss of 0.4205280524874715\n",
      " - accuracy of 0.7903726708074534\n",
      "Epoch # 190:\n",
      " - loss of 0.42034915094117276\n",
      " - accuracy of 0.7888630089717047\n",
      "Epoch # 191:\n",
      " - loss of 0.420277924842898\n",
      " - accuracy of 0.7906746031746031\n",
      "Epoch # 192:\n",
      " - loss of 0.4200550489506479\n",
      " - accuracy of 0.7906746031746031\n",
      "Epoch # 193:\n",
      " - loss of 0.4199296296292298\n",
      " - accuracy of 0.7891649413388544\n",
      "Epoch # 194:\n",
      " - loss of 0.41975841368153943\n",
      " - accuracy of 0.7897688060731539\n",
      "Epoch # 195:\n",
      " - loss of 0.41956099111938594\n",
      " - accuracy of 0.7903726708074534\n",
      "Epoch # 196:\n",
      " - loss of 0.4194504350207331\n",
      " - accuracy of 0.7894668737060042\n",
      "Epoch # 197:\n",
      " - loss of 0.4192451851636388\n",
      " - accuracy of 0.7894668737060042\n",
      "Epoch # 198:\n",
      " - loss of 0.41911907250526165\n",
      " - accuracy of 0.7888630089717047\n",
      "Epoch # 199:\n",
      " - loss of 0.4189272057851348\n",
      " - accuracy of 0.7879572118702554\n",
      "Epoch # 200:\n",
      " - loss of 0.41872914675758477\n",
      " - accuracy of 0.7879572118702554\n",
      "Epoch # 201:\n",
      " - loss of 0.41859194225029567\n",
      " - accuracy of 0.7891649413388544\n",
      "Epoch # 202:\n",
      " - loss of 0.4184363760577276\n",
      " - accuracy of 0.7888630089717047\n",
      "Epoch # 203:\n",
      " - loss of 0.41844017782922804\n",
      " - accuracy of 0.7879572118702554\n",
      "Epoch # 204:\n",
      " - loss of 0.41821242178864687\n",
      " - accuracy of 0.7885610766045549\n",
      "Epoch # 205:\n",
      " - loss of 0.4181544164299388\n",
      " - accuracy of 0.7888630089717047\n",
      "Epoch # 206:\n",
      " - loss of 0.41793201692384324\n",
      " - accuracy of 0.7870514147688061\n",
      "Epoch # 207:\n",
      " - loss of 0.41782237284480805\n",
      " - accuracy of 0.7882591442374052\n",
      "Epoch # 208:\n",
      " - loss of 0.41755875329922243\n",
      " - accuracy of 0.7888630089717047\n",
      "Epoch # 209:\n",
      " - loss of 0.41750849447873833\n",
      " - accuracy of 0.7894668737060042\n",
      "Epoch # 210:\n",
      " - loss of 0.41728691759431336\n",
      " - accuracy of 0.7870514147688061\n",
      "Epoch # 211:\n",
      " - loss of 0.41723751607768184\n",
      " - accuracy of 0.7888630089717047\n",
      "Epoch # 212:\n",
      " - loss of 0.41706465476036936\n",
      " - accuracy of 0.7876552795031057\n",
      "Epoch # 213:\n",
      " - loss of 0.4167851680578533\n",
      " - accuracy of 0.7867494824016563\n",
      "Epoch # 214:\n",
      " - loss of 0.416743661631034\n",
      " - accuracy of 0.7888630089717047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 215:\n",
      " - loss of 0.4166417224806244\n",
      " - accuracy of 0.7891649413388544\n",
      "Epoch # 216:\n",
      " - loss of 0.4164211796934899\n",
      " - accuracy of 0.7879572118702554\n",
      "Epoch # 217:\n",
      " - loss of 0.41637068799275173\n",
      " - accuracy of 0.7876552795031057\n",
      "Epoch # 218:\n",
      " - loss of 0.4160949053292413\n",
      " - accuracy of 0.7897688060731539\n",
      "Epoch # 219:\n",
      " - loss of 0.41605679141515395\n",
      " - accuracy of 0.7885610766045549\n",
      "Epoch # 220:\n",
      " - loss of 0.41582299029278696\n",
      " - accuracy of 0.7873533471359558\n",
      "Epoch # 221:\n",
      " - loss of 0.4157549711823752\n",
      " - accuracy of 0.7888630089717047\n",
      "Epoch # 222:\n",
      " - loss of 0.41566831549092875\n",
      " - accuracy of 0.7879572118702554\n",
      "Epoch # 223:\n",
      " - loss of 0.4154517865281994\n",
      " - accuracy of 0.7906746031746031\n",
      "Epoch # 224:\n",
      " - loss of 0.41527546446130004\n",
      " - accuracy of 0.7867494824016563\n",
      "Epoch # 225:\n",
      " - loss of 0.41521252229918004\n",
      " - accuracy of 0.7894668737060042\n",
      "Epoch # 226:\n",
      " - loss of 0.4150763784172171\n",
      " - accuracy of 0.7867494824016563\n",
      "Epoch # 227:\n",
      " - loss of 0.41487452054067037\n",
      " - accuracy of 0.7873533471359558\n",
      "Epoch # 228:\n",
      " - loss of 0.4147314222362659\n",
      " - accuracy of 0.7891649413388544\n",
      "Epoch # 229:\n",
      " - loss of 0.4146679582989822\n",
      " - accuracy of 0.7867494824016563\n",
      "Epoch # 230:\n",
      " - loss of 0.4145428053403305\n",
      " - accuracy of 0.7888630089717047\n",
      "Epoch # 231:\n",
      " - loss of 0.4144089533958683\n",
      " - accuracy of 0.7879572118702554\n",
      "Epoch # 232:\n",
      " - loss of 0.4142343606935142\n",
      " - accuracy of 0.7885610766045549\n",
      "Epoch # 233:\n",
      " - loss of 0.4140906043116175\n",
      " - accuracy of 0.7885610766045549\n",
      "Epoch # 234:\n",
      " - loss of 0.4139978510415583\n",
      " - accuracy of 0.7882591442374052\n",
      "Epoch # 235:\n",
      " - loss of 0.41382595250883636\n",
      " - accuracy of 0.7864475500345066\n",
      "Epoch # 236:\n",
      " - loss of 0.41367388366931285\n",
      " - accuracy of 0.7867494824016563\n",
      "Epoch # 237:\n",
      " - loss of 0.413536781621037\n",
      " - accuracy of 0.7876552795031057\n",
      "Epoch # 238:\n",
      " - loss of 0.41340808483792274\n",
      " - accuracy of 0.7867494824016563\n",
      "Epoch # 239:\n",
      " - loss of 0.4133610604894652\n",
      " - accuracy of 0.783428226363009\n",
      "Epoch # 240:\n",
      " - loss of 0.4130591803814395\n",
      " - accuracy of 0.7876552795031057\n",
      "Epoch # 241:\n",
      " - loss of 0.4130702619474679\n",
      " - accuracy of 0.7867494824016563\n",
      "Epoch # 242:\n",
      " - loss of 0.4129860305089783\n",
      " - accuracy of 0.7876552795031057\n",
      "Epoch # 243:\n",
      " - loss of 0.4127745200174051\n",
      " - accuracy of 0.7873533471359558\n",
      "Epoch # 244:\n",
      " - loss of 0.41251958614400164\n",
      " - accuracy of 0.7858436853002071\n",
      "Epoch # 245:\n",
      " - loss of 0.41262255376317597\n",
      " - accuracy of 0.7879572118702554\n",
      "Epoch # 246:\n",
      " - loss of 0.4125351708102746\n",
      " - accuracy of 0.7858436853002071\n",
      "Epoch # 247:\n",
      " - loss of 0.41220428823486654\n",
      " - accuracy of 0.7879572118702554\n",
      "Epoch # 248:\n",
      " - loss of 0.41216420971272066\n",
      " - accuracy of 0.7864475500345066\n",
      "Epoch # 249:\n",
      " - loss of 0.4120543203237703\n",
      " - accuracy of 0.7870514147688061\n",
      "Epoch # 250:\n",
      " - loss of 0.41188507803127206\n",
      " - accuracy of 0.7864475500345066\n",
      "Epoch # 251:\n",
      " - loss of 0.41179716765664104\n",
      " - accuracy of 0.7849378881987578\n",
      "Epoch # 252:\n",
      " - loss of 0.41160724734206466\n",
      " - accuracy of 0.7876552795031057\n",
      "Epoch # 253:\n",
      " - loss of 0.41160430227007183\n",
      " - accuracy of 0.7870514147688061\n",
      "Epoch # 254:\n",
      " - loss of 0.4114239962532503\n",
      " - accuracy of 0.7855417529330573\n",
      "Epoch # 255:\n",
      " - loss of 0.41130486639446556\n",
      " - accuracy of 0.7849378881987578\n",
      "Epoch # 256:\n",
      " - loss of 0.41119190334335654\n",
      " - accuracy of 0.7846359558316081\n",
      "Epoch # 257:\n",
      " - loss of 0.4110521901913041\n",
      " - accuracy of 0.7867494824016563\n",
      "Epoch # 258:\n",
      " - loss of 0.411001811358744\n",
      " - accuracy of 0.7858436853002071\n",
      "Epoch # 259:\n",
      " - loss of 0.4108002748313308\n",
      " - accuracy of 0.7864475500345066\n",
      "Epoch # 260:\n",
      " - loss of 0.41062048734244655\n",
      " - accuracy of 0.7852398205659076\n",
      "Epoch # 261:\n",
      " - loss of 0.4105536124283407\n",
      " - accuracy of 0.7831262939958592\n",
      "Epoch # 262:\n",
      " - loss of 0.41048501636697654\n",
      " - accuracy of 0.7852398205659076\n",
      "Epoch # 263:\n",
      " - loss of 0.41042813631654074\n",
      " - accuracy of 0.7828243616287095\n",
      "Epoch # 264:\n",
      " - loss of 0.41020191101848935\n",
      " - accuracy of 0.7855417529330573\n",
      "Epoch # 265:\n",
      " - loss of 0.4101441187590144\n",
      " - accuracy of 0.7855417529330573\n",
      "Epoch # 266:\n",
      " - loss of 0.41005486538566055\n",
      " - accuracy of 0.7861456176673568\n",
      "Epoch # 267:\n",
      " - loss of 0.40999718732031437\n",
      " - accuracy of 0.7846359558316081\n",
      "Epoch # 268:\n",
      " - loss of 0.40978238021742924\n",
      " - accuracy of 0.7819185645272602\n",
      "Epoch # 269:\n",
      " - loss of 0.40978399527058473\n",
      " - accuracy of 0.783428226363009\n",
      "Epoch # 270:\n",
      " - loss of 0.4095385260609391\n",
      " - accuracy of 0.78222049689441\n",
      "Epoch # 271:\n",
      " - loss of 0.40944204811394647\n",
      " - accuracy of 0.7840320910973085\n",
      "Epoch # 272:\n",
      " - loss of 0.409097126209274\n",
      " - accuracy of 0.7837301587301587\n",
      "Epoch # 273:\n",
      " - loss of 0.409211185875802\n",
      " - accuracy of 0.783428226363009\n",
      "Epoch # 274:\n",
      " - loss of 0.4091172154280233\n",
      " - accuracy of 0.7819185645272602\n",
      "Epoch # 275:\n",
      " - loss of 0.40890988023820857\n",
      " - accuracy of 0.7819185645272602\n",
      "Epoch # 276:\n",
      " - loss of 0.4088670095613736\n",
      " - accuracy of 0.7798050379572119\n",
      "Epoch # 277:\n",
      " - loss of 0.40865201255888395\n",
      " - accuracy of 0.78222049689441\n",
      "Epoch # 278:\n",
      " - loss of 0.4086719955662694\n",
      " - accuracy of 0.7813146997929606\n",
      "Epoch # 279:\n",
      " - loss of 0.408456187965867\n",
      " - accuracy of 0.7828243616287095\n",
      "Epoch # 280:\n",
      " - loss of 0.4084302046884203\n",
      " - accuracy of 0.7837301587301587\n",
      "Epoch # 281:\n",
      " - loss of 0.4083816803649032\n",
      " - accuracy of 0.7831262939958592\n",
      "Epoch # 282:\n",
      " - loss of 0.4081486907604965\n",
      " - accuracy of 0.7819185645272602\n",
      "Epoch # 283:\n",
      " - loss of 0.4081022664002587\n",
      " - accuracy of 0.7825224292615597\n",
      "Epoch # 284:\n",
      " - loss of 0.4079373505498682\n",
      " - accuracy of 0.7819185645272602\n",
      "Epoch # 285:\n",
      " - loss of 0.40788849999735777\n",
      " - accuracy of 0.7801069703243616\n",
      "Epoch # 286:\n",
      " - loss of 0.40764746069006136\n",
      " - accuracy of 0.7813146997929606\n",
      "Epoch # 287:\n",
      " - loss of 0.4075795514170829\n",
      " - accuracy of 0.7828243616287095\n",
      "Epoch # 288:\n",
      " - loss of 0.40756654245079865\n",
      " - accuracy of 0.7828243616287095\n",
      "Epoch # 289:\n",
      " - loss of 0.40742503746117287\n",
      " - accuracy of 0.7792011732229124\n",
      "Epoch # 290:\n",
      " - loss of 0.4073217291357875\n",
      " - accuracy of 0.7816166321601105\n",
      "Epoch # 291:\n",
      " - loss of 0.40709380239031795\n",
      " - accuracy of 0.7798050379572119\n",
      "Epoch # 292:\n",
      " - loss of 0.40709748546667307\n",
      " - accuracy of 0.7792011732229124\n",
      "Epoch # 293:\n",
      " - loss of 0.4069442701758253\n",
      " - accuracy of 0.7807108350586611\n",
      "Epoch # 294:\n",
      " - loss of 0.4068865202475547\n",
      " - accuracy of 0.7785973084886129\n",
      "Epoch # 295:\n",
      " - loss of 0.4067449507914646\n",
      " - accuracy of 0.7773895790200138\n",
      "Epoch # 296:\n",
      " - loss of 0.4067449131957988\n",
      " - accuracy of 0.7819185645272602\n",
      "Epoch # 297:\n",
      " - loss of 0.40655520017152835\n",
      " - accuracy of 0.7785973084886129\n",
      "Epoch # 298:\n",
      " - loss of 0.40644070398757015\n",
      " - accuracy of 0.7801069703243616\n",
      "Epoch # 299:\n",
      " - loss of 0.4063148383890024\n",
      " - accuracy of 0.7801069703243616\n",
      "Epoch # 300:\n",
      " - loss of 0.4062334922915798\n",
      " - accuracy of 0.7807108350586611\n",
      "Epoch # 301:\n",
      " - loss of 0.40599654780894734\n",
      " - accuracy of 0.7825224292615597\n",
      "Epoch # 302:\n",
      " - loss of 0.4060658906782655\n",
      " - accuracy of 0.7795031055900621\n",
      "Epoch # 303:\n",
      " - loss of 0.4058658314765077\n",
      " - accuracy of 0.7804089026915114\n",
      "Epoch # 304:\n",
      " - loss of 0.40577519737346407\n",
      " - accuracy of 0.7801069703243616\n",
      "Epoch # 305:\n",
      " - loss of 0.4057026422575802\n",
      " - accuracy of 0.7807108350586611\n",
      "Epoch # 306:\n",
      " - loss of 0.4055682194507151\n",
      " - accuracy of 0.7798050379572119\n",
      "Epoch # 307:\n",
      " - loss of 0.4054788196274501\n",
      " - accuracy of 0.7801069703243616\n",
      "Epoch # 308:\n",
      " - loss of 0.4052720390819464\n",
      " - accuracy of 0.7758799171842651\n",
      "Epoch # 309:\n",
      " - loss of 0.4052875598319795\n",
      " - accuracy of 0.7779934437543133\n",
      "Epoch # 310:\n",
      " - loss of 0.4049311658462225\n",
      " - accuracy of 0.7773895790200138\n",
      "Epoch # 311:\n",
      " - loss of 0.4050610312429814\n",
      " - accuracy of 0.7773895790200138\n",
      "Epoch # 312:\n",
      " - loss of 0.40492271447946604\n",
      " - accuracy of 0.7773895790200138\n",
      "Epoch # 313:\n",
      " - loss of 0.4048232616220779\n",
      " - accuracy of 0.7798050379572119\n",
      "Epoch # 314:\n",
      " - loss of 0.4046773448965307\n",
      " - accuracy of 0.7804089026915114\n",
      "Epoch # 315:\n",
      " - loss of 0.40447834530985094\n",
      " - accuracy of 0.7779934437543133\n",
      "Epoch # 316:\n",
      " - loss of 0.4045459688269053\n",
      " - accuracy of 0.7743702553485162\n",
      "Epoch # 317:\n",
      " - loss of 0.4044453011821171\n",
      " - accuracy of 0.778295376121463\n",
      "Epoch # 318:\n",
      " - loss of 0.404341913218504\n",
      " - accuracy of 0.7770876466528641\n",
      "Epoch # 319:\n",
      " - loss of 0.4041101201358488\n",
      " - accuracy of 0.7801069703243616\n",
      "Epoch # 320:\n",
      " - loss of 0.4041098655442782\n",
      " - accuracy of 0.7755779848171153\n",
      "Epoch # 321:\n",
      " - loss of 0.4039188927855821\n",
      " - accuracy of 0.7767857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 322:\n",
      " - loss of 0.40387605199225013\n",
      " - accuracy of 0.7752760524499656\n",
      "Epoch # 323:\n",
      " - loss of 0.40376224222685464\n",
      " - accuracy of 0.7795031055900621\n",
      "Epoch # 324:\n",
      " - loss of 0.4038120326168889\n",
      " - accuracy of 0.774672187715666\n",
      "Epoch # 325:\n",
      " - loss of 0.40355072330151287\n",
      " - accuracy of 0.7743702553485162\n",
      "Epoch # 326:\n",
      " - loss of 0.4034786410900352\n",
      " - accuracy of 0.774672187715666\n",
      "Epoch # 327:\n",
      " - loss of 0.4034137670627229\n",
      " - accuracy of 0.7776915113871635\n",
      "Epoch # 328:\n",
      " - loss of 0.4031844324732231\n",
      " - accuracy of 0.7776915113871635\n",
      "Epoch # 329:\n",
      " - loss of 0.403312124564486\n",
      " - accuracy of 0.7755779848171153\n",
      "Epoch # 330:\n",
      " - loss of 0.4030350019690777\n",
      " - accuracy of 0.7764837819185646\n",
      "Epoch # 331:\n",
      " - loss of 0.40291855901876605\n",
      " - accuracy of 0.7795031055900621\n",
      "Epoch # 332:\n",
      " - loss of 0.4029647286340919\n",
      " - accuracy of 0.7767857142857143\n",
      "Epoch # 333:\n",
      " - loss of 0.40271264200998563\n",
      " - accuracy of 0.7776915113871635\n",
      "Epoch # 334:\n",
      " - loss of 0.4026538949757454\n",
      " - accuracy of 0.7770876466528641\n",
      "Epoch # 335:\n",
      " - loss of 0.40256919626137533\n",
      " - accuracy of 0.7749741200828157\n",
      "Epoch # 336:\n",
      " - loss of 0.4023555379369934\n",
      " - accuracy of 0.7737663906142167\n",
      "Epoch # 337:\n",
      " - loss of 0.4023288655800623\n",
      " - accuracy of 0.7788992408557626\n",
      "Epoch # 338:\n",
      " - loss of 0.4022259339600008\n",
      " - accuracy of 0.7752760524499656\n",
      "Epoch # 339:\n",
      " - loss of 0.4022197495180816\n",
      " - accuracy of 0.7767857142857143\n",
      "Epoch # 340:\n",
      " - loss of 0.402082544956672\n",
      " - accuracy of 0.774672187715666\n",
      "Epoch # 341:\n",
      " - loss of 0.4020392216074553\n",
      " - accuracy of 0.7737663906142167\n",
      "Epoch # 342:\n",
      " - loss of 0.40196684957200046\n",
      " - accuracy of 0.7749741200828157\n",
      "Epoch # 343:\n",
      " - loss of 0.4018498759166525\n",
      " - accuracy of 0.7779934437543133\n",
      "Epoch # 344:\n",
      " - loss of 0.40185230165792146\n",
      " - accuracy of 0.774672187715666\n",
      "Epoch # 345:\n",
      " - loss of 0.40170814519969084\n",
      " - accuracy of 0.7758799171842651\n",
      "Epoch # 346:\n",
      " - loss of 0.40152195699458837\n",
      " - accuracy of 0.7767857142857143\n",
      "Epoch # 347:\n",
      " - loss of 0.4015682644636954\n",
      " - accuracy of 0.7752760524499656\n",
      "Epoch # 348:\n",
      " - loss of 0.4014037971003725\n",
      " - accuracy of 0.773464458247067\n",
      "Epoch # 349:\n",
      " - loss of 0.4012828186136325\n",
      " - accuracy of 0.7728605935127675\n",
      "Epoch # 350:\n",
      " - loss of 0.40127060537116005\n",
      " - accuracy of 0.7743702553485162\n",
      "Epoch # 351:\n",
      " - loss of 0.40122852816311844\n",
      " - accuracy of 0.772256728778468\n",
      "Epoch # 352:\n",
      " - loss of 0.401065017062873\n",
      " - accuracy of 0.772256728778468\n",
      "Epoch # 353:\n",
      " - loss of 0.4011090478113431\n",
      " - accuracy of 0.7743702553485162\n",
      "Epoch # 354:\n",
      " - loss of 0.40091938647209296\n",
      " - accuracy of 0.7752760524499656\n",
      "Epoch # 355:\n",
      " - loss of 0.40081844357976615\n",
      " - accuracy of 0.7743702553485162\n",
      "Epoch # 356:\n",
      " - loss of 0.40075128024881457\n",
      " - accuracy of 0.774672187715666\n",
      "Epoch # 357:\n",
      " - loss of 0.4006168927104363\n",
      " - accuracy of 0.7764837819185646\n",
      "Epoch # 358:\n",
      " - loss of 0.40048315601545154\n",
      " - accuracy of 0.7758799171842651\n",
      "Epoch # 359:\n",
      " - loss of 0.4003608349088318\n",
      " - accuracy of 0.7740683229813665\n",
      "Epoch # 360:\n",
      " - loss of 0.40027048091514633\n",
      " - accuracy of 0.7770876466528641\n",
      "Epoch # 361:\n",
      " - loss of 0.40025984189195724\n",
      " - accuracy of 0.7755779848171153\n",
      "Epoch # 362:\n",
      " - loss of 0.40021942776896186\n",
      " - accuracy of 0.7725586611456177\n",
      "Epoch # 363:\n",
      " - loss of 0.4001186463900686\n",
      " - accuracy of 0.7752760524499656\n",
      "Epoch # 364:\n",
      " - loss of 0.3999856442898584\n",
      " - accuracy of 0.7758799171842651\n",
      "Epoch # 365:\n",
      " - loss of 0.399980823989714\n",
      " - accuracy of 0.7740683229813665\n",
      "Epoch # 366:\n",
      " - loss of 0.39978914124300347\n",
      " - accuracy of 0.7728605935127675\n",
      "Epoch # 367:\n",
      " - loss of 0.39957671924595684\n",
      " - accuracy of 0.778295376121463\n",
      "Epoch # 368:\n",
      " - loss of 0.3998163231799591\n",
      " - accuracy of 0.7719547964113181\n",
      "Epoch # 369:\n",
      " - loss of 0.3997068633088621\n",
      " - accuracy of 0.7752760524499656\n",
      "Epoch # 370:\n",
      " - loss of 0.39958389098000585\n",
      " - accuracy of 0.7719547964113181\n",
      "Epoch # 371:\n",
      " - loss of 0.39943511377271385\n",
      " - accuracy of 0.7713509316770186\n",
      "Epoch # 372:\n",
      " - loss of 0.3992332519994954\n",
      " - accuracy of 0.7680296756383713\n",
      "Epoch # 373:\n",
      " - loss of 0.39945539862783425\n",
      " - accuracy of 0.7710489993098689\n",
      "Epoch # 374:\n",
      " - loss of 0.3991641386008436\n",
      " - accuracy of 0.7743702553485162\n",
      "Epoch # 375:\n",
      " - loss of 0.3991369743342117\n",
      " - accuracy of 0.7698412698412699\n",
      "Epoch # 376:\n",
      " - loss of 0.39894247494331286\n",
      " - accuracy of 0.7713509316770186\n",
      "Epoch # 377:\n",
      " - loss of 0.39902011402510557\n",
      " - accuracy of 0.7701432022084196\n",
      "Epoch # 378:\n",
      " - loss of 0.3989465928323044\n",
      " - accuracy of 0.7698412698412699\n",
      "Epoch # 379:\n",
      " - loss of 0.39880685337771804\n",
      " - accuracy of 0.7719547964113181\n",
      "Epoch # 380:\n",
      " - loss of 0.39878679346518714\n",
      " - accuracy of 0.7710489993098689\n",
      "Epoch # 381:\n",
      " - loss of 0.39860475039871784\n",
      " - accuracy of 0.7737663906142167\n",
      "Epoch # 382:\n",
      " - loss of 0.3985126437235975\n",
      " - accuracy of 0.7695393374741201\n",
      "Epoch # 383:\n",
      " - loss of 0.398519829285419\n",
      " - accuracy of 0.7710489993098689\n",
      "Epoch # 384:\n",
      " - loss of 0.3984211518386374\n",
      " - accuracy of 0.7737663906142167\n",
      "Epoch # 385:\n",
      " - loss of 0.3984250344299953\n",
      " - accuracy of 0.7713509316770186\n",
      "Epoch # 386:\n",
      " - loss of 0.3981349055923648\n",
      " - accuracy of 0.7701432022084196\n",
      "Epoch # 387:\n",
      " - loss of 0.39822493765061184\n",
      " - accuracy of 0.7701432022084196\n",
      "Epoch # 388:\n",
      " - loss of 0.3980580774963479\n",
      " - accuracy of 0.7731625258799172\n",
      "Epoch # 389:\n",
      " - loss of 0.3979540646491126\n",
      " - accuracy of 0.7710489993098689\n",
      "Epoch # 390:\n",
      " - loss of 0.3979309802608831\n",
      " - accuracy of 0.772256728778468\n",
      "Epoch # 391:\n",
      " - loss of 0.3978182779349946\n",
      " - accuracy of 0.7737663906142167\n",
      "Epoch # 392:\n",
      " - loss of 0.3978949971406858\n",
      " - accuracy of 0.7707470669427191\n",
      "Epoch # 393:\n",
      " - loss of 0.39780363490124016\n",
      " - accuracy of 0.7710489993098689\n",
      "Epoch # 394:\n",
      " - loss of 0.39772158025901483\n",
      " - accuracy of 0.7695393374741201\n",
      "Epoch # 395:\n",
      " - loss of 0.3975346059545189\n",
      " - accuracy of 0.7689354727398205\n",
      "Epoch # 396:\n",
      " - loss of 0.3973971957985772\n",
      " - accuracy of 0.7680296756383713\n",
      "Epoch # 397:\n",
      " - loss of 0.39764427036479943\n",
      " - accuracy of 0.7686335403726708\n",
      "Epoch # 398:\n",
      " - loss of 0.3973780494300563\n",
      " - accuracy of 0.7695393374741201\n",
      "Epoch # 399:\n",
      " - loss of 0.3972558312244334\n",
      " - accuracy of 0.7719547964113181\n",
      "Epoch # 400:\n",
      " - loss of 0.39730679247411055\n",
      " - accuracy of 0.7713509316770186\n",
      "Epoch # 401:\n",
      " - loss of 0.3971903382487072\n",
      " - accuracy of 0.7713509316770186\n",
      "Epoch # 402:\n",
      " - loss of 0.39705328184200256\n",
      " - accuracy of 0.7701432022084196\n",
      "Epoch # 403:\n",
      " - loss of 0.397091823515029\n",
      " - accuracy of 0.7698412698412699\n",
      "Epoch # 404:\n",
      " - loss of 0.39692602672819366\n",
      " - accuracy of 0.7740683229813665\n",
      "Epoch # 405:\n",
      " - loss of 0.39682410025098713\n",
      " - accuracy of 0.7716528640441684\n",
      "Epoch # 406:\n",
      " - loss of 0.3967630553350177\n",
      " - accuracy of 0.7719547964113181\n",
      "Epoch # 407:\n",
      " - loss of 0.3966916024360183\n",
      " - accuracy of 0.7707470669427191\n",
      "Epoch # 408:\n",
      " - loss of 0.3965624134545609\n",
      " - accuracy of 0.7725586611456177\n",
      "Epoch # 409:\n",
      " - loss of 0.3965244313057052\n",
      " - accuracy of 0.7695393374741201\n",
      "Epoch # 410:\n",
      " - loss of 0.39662418860860943\n",
      " - accuracy of 0.7713509316770186\n",
      "Epoch # 411:\n",
      " - loss of 0.396384801291669\n",
      " - accuracy of 0.7698412698412699\n",
      "Epoch # 412:\n",
      " - loss of 0.3962885838714552\n",
      " - accuracy of 0.7698412698412699\n",
      "Epoch # 413:\n",
      " - loss of 0.396271664387666\n",
      " - accuracy of 0.7704451345755694\n",
      "Epoch # 414:\n",
      " - loss of 0.39605684289776383\n",
      " - accuracy of 0.7719547964113181\n",
      "Epoch # 415:\n",
      " - loss of 0.3961289843801436\n",
      " - accuracy of 0.7704451345755694\n",
      "Epoch # 416:\n",
      " - loss of 0.3959471691968077\n",
      " - accuracy of 0.768331608005521\n",
      "Epoch # 417:\n",
      " - loss of 0.39593090352401605\n",
      " - accuracy of 0.7713509316770186\n",
      "Epoch # 418:\n",
      " - loss of 0.3958479533689074\n",
      " - accuracy of 0.7719547964113181\n",
      "Epoch # 419:\n",
      " - loss of 0.39591533672650847\n",
      " - accuracy of 0.7728605935127675\n",
      "Epoch # 420:\n",
      " - loss of 0.39585407296551917\n",
      " - accuracy of 0.772256728778468\n",
      "Epoch # 421:\n",
      " - loss of 0.3955836558746079\n",
      " - accuracy of 0.7719547964113181\n",
      "Epoch # 422:\n",
      " - loss of 0.39560057661218734\n",
      " - accuracy of 0.7698412698412699\n",
      "Epoch # 423:\n",
      " - loss of 0.3955231655849094\n",
      " - accuracy of 0.7716528640441684\n",
      "Epoch # 424:\n",
      " - loss of 0.39528058424195134\n",
      " - accuracy of 0.7701432022084196\n",
      "Epoch # 425:\n",
      " - loss of 0.39535462518941983\n",
      " - accuracy of 0.7725586611456177\n",
      "Epoch # 426:\n",
      " - loss of 0.3952255019552771\n",
      " - accuracy of 0.7692374051069704\n",
      "Epoch # 427:\n",
      " - loss of 0.3953873648355573\n",
      " - accuracy of 0.7737663906142167\n",
      "Epoch # 428:\n",
      " - loss of 0.3951275643529528\n",
      " - accuracy of 0.7692374051069704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 429:\n",
      " - loss of 0.3950811293851088\n",
      " - accuracy of 0.7713509316770186\n",
      "Epoch # 430:\n",
      " - loss of 0.3950887733380385\n",
      " - accuracy of 0.7705314009661836\n",
      "Epoch # 431:\n",
      " - loss of 0.39489469835061136\n",
      " - accuracy of 0.7728605935127675\n",
      "Epoch # 432:\n",
      " - loss of 0.39487209282905655\n",
      " - accuracy of 0.7728605935127675\n",
      "Epoch # 433:\n",
      " - loss of 0.39470819007722574\n",
      " - accuracy of 0.7708333333333334\n",
      "Epoch # 434:\n",
      " - loss of 0.3947570572447113\n",
      " - accuracy of 0.7713509316770186\n",
      "Epoch # 435:\n",
      " - loss of 0.3946276632640466\n",
      " - accuracy of 0.7708333333333334\n",
      "Epoch # 436:\n",
      " - loss of 0.39459511007184556\n",
      " - accuracy of 0.773464458247067\n",
      "Epoch # 437:\n",
      " - loss of 0.3946144129837396\n",
      " - accuracy of 0.7716528640441684\n",
      "Epoch # 438:\n",
      " - loss of 0.3943759357831813\n",
      " - accuracy of 0.7716528640441684\n",
      "Epoch # 439:\n",
      " - loss of 0.39447606772581256\n",
      " - accuracy of 0.7725586611456177\n",
      "Epoch # 440:\n",
      " - loss of 0.39439161571946907\n",
      " - accuracy of 0.7698412698412699\n",
      "Epoch # 441:\n",
      " - loss of 0.39421909417930007\n",
      " - accuracy of 0.773464458247067\n",
      "Epoch # 442:\n",
      " - loss of 0.39429920731387474\n",
      " - accuracy of 0.7710489993098689\n",
      "Epoch # 443:\n",
      " - loss of 0.3941488821266927\n",
      " - accuracy of 0.7716528640441684\n",
      "Epoch # 444:\n",
      " - loss of 0.3940616987880148\n",
      " - accuracy of 0.7698412698412699\n",
      "Epoch # 445:\n",
      " - loss of 0.39395349412326663\n",
      " - accuracy of 0.7704451345755694\n",
      "Epoch # 446:\n",
      " - loss of 0.3939159121229054\n",
      " - accuracy of 0.7725586611456177\n",
      "Epoch # 447:\n",
      " - loss of 0.39384116313575834\n",
      " - accuracy of 0.7719547964113181\n",
      "Epoch # 448:\n",
      " - loss of 0.3938038545067605\n",
      " - accuracy of 0.7707470669427191\n",
      "Epoch # 449:\n",
      " - loss of 0.39379234151964326\n",
      " - accuracy of 0.772256728778468\n",
      "Epoch # 450:\n",
      " - loss of 0.3937618736060422\n",
      " - accuracy of 0.7707470669427191\n",
      "Epoch # 451:\n",
      " - loss of 0.3936019722579755\n",
      " - accuracy of 0.772256728778468\n",
      "Epoch # 452:\n",
      " - loss of 0.3936213764562734\n",
      " - accuracy of 0.7707470669427191\n",
      "Epoch # 453:\n",
      " - loss of 0.3933255791068799\n",
      " - accuracy of 0.7719547964113181\n",
      "Epoch # 454:\n",
      " - loss of 0.39352335698776325\n",
      " - accuracy of 0.7725586611456177\n",
      "Epoch # 455:\n",
      " - loss of 0.39336877811438525\n",
      " - accuracy of 0.7707470669427191\n",
      "Epoch # 456:\n",
      " - loss of 0.393227235691455\n",
      " - accuracy of 0.772256728778468\n",
      "Epoch # 457:\n",
      " - loss of 0.3933265255200372\n",
      " - accuracy of 0.7714371980676329\n",
      "Epoch # 458:\n",
      " - loss of 0.39323269390020765\n",
      " - accuracy of 0.7716528640441684\n",
      "Epoch # 459:\n",
      " - loss of 0.39309504916823806\n",
      " - accuracy of 0.7708333333333334\n",
      "Epoch # 460:\n",
      " - loss of 0.39300622227297277\n",
      " - accuracy of 0.7707470669427191\n",
      "Epoch # 461:\n",
      " - loss of 0.3928776855240001\n",
      " - accuracy of 0.7713509316770186\n",
      "Epoch # 462:\n",
      " - loss of 0.3927775563956317\n",
      " - accuracy of 0.7696256038647343\n",
      "Epoch # 463:\n",
      " - loss of 0.3929266652259209\n",
      " - accuracy of 0.7728605935127675\n",
      "Epoch # 464:\n",
      " - loss of 0.39280219449149784\n",
      " - accuracy of 0.7696256038647343\n",
      "Epoch # 465:\n",
      " - loss of 0.39259550610408367\n",
      " - accuracy of 0.7713509316770186\n",
      "Epoch # 466:\n",
      " - loss of 0.3926388823289704\n",
      " - accuracy of 0.7678140096618358\n",
      "Epoch # 467:\n",
      " - loss of 0.3925642134490948\n",
      " - accuracy of 0.7708333333333334\n",
      "Epoch # 468:\n",
      " - loss of 0.39248452534939704\n",
      " - accuracy of 0.7690217391304348\n",
      "Epoch # 469:\n",
      " - loss of 0.3925541717892842\n",
      " - accuracy of 0.7707470669427191\n",
      "Epoch # 470:\n",
      " - loss of 0.3923746356627843\n",
      " - accuracy of 0.7690217391304348\n",
      "Epoch # 471:\n",
      " - loss of 0.39223830364013124\n",
      " - accuracy of 0.7710489993098689\n",
      "Epoch # 472:\n",
      " - loss of 0.39235377869147076\n",
      " - accuracy of 0.769927536231884\n",
      "Epoch # 473:\n",
      " - loss of 0.39212088605285267\n",
      " - accuracy of 0.7725586611456177\n",
      "Epoch # 474:\n",
      " - loss of 0.3922655748487529\n",
      " - accuracy of 0.7711352657004831\n",
      "Epoch # 475:\n",
      " - loss of 0.3922387915990399\n",
      " - accuracy of 0.7710489993098689\n",
      "Epoch # 476:\n",
      " - loss of 0.39215259919660145\n",
      " - accuracy of 0.7731625258799172\n",
      "Epoch # 477:\n",
      " - loss of 0.39190534026909973\n",
      " - accuracy of 0.7717391304347826\n",
      "Epoch # 478:\n",
      " - loss of 0.3918387641719842\n",
      " - accuracy of 0.7719547964113181\n",
      "Epoch # 479:\n",
      " - loss of 0.3919517579093828\n",
      " - accuracy of 0.7702294685990339\n",
      "Epoch # 480:\n",
      " - loss of 0.3917980360963154\n",
      " - accuracy of 0.7704451345755694\n",
      "Epoch # 481:\n",
      " - loss of 0.39184022691218096\n",
      " - accuracy of 0.7720410628019324\n",
      "Epoch # 482:\n",
      " - loss of 0.39173492155157336\n",
      " - accuracy of 0.7693236714975845\n",
      "Epoch # 483:\n",
      " - loss of 0.3916206411458101\n",
      " - accuracy of 0.7716528640441684\n",
      "Epoch # 484:\n",
      " - loss of 0.39155032252103594\n",
      " - accuracy of 0.768719806763285\n",
      "Epoch # 485:\n",
      " - loss of 0.39153577150104985\n",
      " - accuracy of 0.7707470669427191\n",
      "Epoch # 486:\n",
      " - loss of 0.3916425918641593\n",
      " - accuracy of 0.7716528640441684\n",
      "Epoch # 487:\n",
      " - loss of 0.39145431297743294\n",
      " - accuracy of 0.7666062801932367\n",
      "Epoch # 488:\n",
      " - loss of 0.39136632841269847\n",
      " - accuracy of 0.7695393374741201\n",
      "Epoch # 489:\n",
      " - loss of 0.3913258905759302\n",
      " - accuracy of 0.7716528640441684\n",
      "Epoch # 490:\n",
      " - loss of 0.39150987772077106\n",
      " - accuracy of 0.7719547964113181\n",
      "Epoch # 491:\n",
      " - loss of 0.3911038590707877\n",
      " - accuracy of 0.7678140096618358\n",
      "Epoch # 492:\n",
      " - loss of 0.391176719768717\n",
      " - accuracy of 0.7666062801932367\n",
      "Epoch # 493:\n",
      " - loss of 0.3912332215713964\n",
      " - accuracy of 0.7677277432712215\n",
      "Epoch # 494:\n",
      " - loss of 0.3910742806356409\n",
      " - accuracy of 0.7689354727398205\n",
      "Epoch # 495:\n",
      " - loss of 0.390932943699002\n",
      " - accuracy of 0.7684178743961353\n",
      "Epoch # 496:\n",
      " - loss of 0.3908662971911938\n",
      " - accuracy of 0.7702294685990339\n",
      "Epoch # 497:\n",
      " - loss of 0.39094649138014775\n",
      " - accuracy of 0.7704451345755694\n",
      "Epoch # 498:\n",
      " - loss of 0.3908348701371119\n",
      " - accuracy of 0.772256728778468\n",
      "Epoch # 499:\n",
      " - loss of 0.3908933610012687\n",
      " - accuracy of 0.7710489993098689\n",
      "Epoch # 500:\n",
      " - loss of 0.390893715634473\n",
      " - accuracy of 0.769927536231884\n"
     ]
    }
   ],
   "source": [
    "loss_vector = Float64[]\n",
    "accuracy_vector = Float64[]\n",
    "for epoch in 1:500\n",
    "    # Train the model\n",
    "    epoch_loss = Float64[]\n",
    "    for (x, y) in train_loader\n",
    "        (loss, y_pred, st), back = pullback(p -> compute_loss(x, y, model, p, st), ps)\n",
    "        gs = back((one(loss), nothing, nothing))[1]\n",
    "        opt_state, ps = Optimisers.update(opt_state, ps, gs)\n",
    "        push!(epoch_loss, loss)\n",
    "    end\n",
    "    avg_loss = mean(epoch_loss)\n",
    "    println(\"Epoch # $epoch:\\n - loss of $avg_loss\")\n",
    "    push!(loss_vector, avg_loss)\n",
    "\n",
    "    # Validate the model\n",
    "    epoch_accuracy = Float64[]\n",
    "    st_ = Lux.testmode(st)\n",
    "    for (x, y) in val_loader\n",
    "        (loss, y_pred, st_) = compute_loss(x, y, model, ps, st_)\n",
    "        acc = accuracy(y_pred, y)\n",
    "        push!(epoch_accuracy, acc)\n",
    "    end\n",
    "    avg_accuracy = mean(epoch_accuracy)\n",
    "    println(\" - accuracy of $avg_accuracy\")\n",
    "    push!(accuracy_vector, avg_accuracy)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "plot(loss_vector, label=\"loss\", legend=:bottom, color=:red, rightmargin = 1.5Plots.cm, bottommargin = 0.5Plots.cm, box = :on, fmt = :png)\n",
    "plot!(twinx(), accuracy_vector, label=\"accuracy\", legend=:bottomleft, xlabel=\"epoch\", rightmargin = 1.5Plots.cm, bottommargin = 0.5Plots.cm, box = :on)\n",
    "using Dates\n",
    "timestamp = now()\n",
    "savefig(\"result-$timestamp.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JuliaLuxMLUtils 1.7.3",
   "language": "julia",
   "name": "julialuxmlutils-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
