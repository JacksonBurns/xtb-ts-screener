{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `XTBTSScreener.jl` - Screening Likely Transition States with Julia and Machine Learning\n",
    "This Jupyter notebook demonstrates the use of machine learning to predict if a partially-optimized initialization of a transition state, used in the study of chemical kinetics to predict rate constants, is _like to converge\"_ and produze a valid transition state or not after further simulation with expensive Density Functional Theory simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "The input data is saved in a CSV file, load it using `CSV.jl` and then partition the data into training and testing sets using `MLUtils.jl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLUtils, CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_dataloaders (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_dataloaders()\n",
    "    csv_reader = CSV.File(\"data/roo_co2_full_data_augmented.csv\")\n",
    "    n_samples = 16517\n",
    "    x_data = Array{Float32}(undef, 60, 6, n_samples)\n",
    "    labels = Float32[]\n",
    "    iter = 1\n",
    "    println(\"Progress:\")\n",
    "    for row in csv_reader[1:n_samples]\n",
    "        # print some updates as we go\n",
    "        if mod(iter, div(n_samples, 60)) == 0\n",
    "            println(\" - row $iter of $n_samples\")\n",
    "            flush(stdout)\n",
    "        end\n",
    "        \n",
    "        # get if it converged or not\n",
    "        if parse(Bool, \"$(row.converged)\")\n",
    "            push!(labels, 1.0f0)\n",
    "        else\n",
    "            push!(labels, 0.0f0)\n",
    "        end\n",
    "        \n",
    "        # array for descriptors for this transition state\n",
    "        m = Array{Float32}(undef, 60, 6)\n",
    "        \n",
    "        # pull out the augmented descriptors\n",
    "        split_gibbs = split(\"$(row.gibbs)\")\n",
    "        split_steps = split(\"$(row.steps)\")\n",
    "        split_e0_zpe = split(\"$(row.e0_zpe)\")\n",
    "        split_descriptors = [split_gibbs,split_steps,split_e0_zpe]\n",
    "        for i in 1:3\n",
    "            for j in 1:3\n",
    "                temp = String(split_descriptors[i][j])\n",
    "                temp = replace(temp,\"]\"=>\"\")\n",
    "                temp = replace(temp,\"[\"=>\"\")\n",
    "                temp = replace(temp,\",\"=>\"\")\n",
    "                m[i,j] = parse(Float32, temp)\n",
    "            end\n",
    "            m[i,4] = Float32(0.0)\n",
    "            m[i,5] = Float32(0.0)\n",
    "            m[i,6] = Float32(0.0)\n",
    "        end\n",
    "\n",
    "        # get the final coordinates of the atoms\n",
    "        split_array = split(\"$(row.std_xyz)\")\n",
    "        n_atoms = Int(length(split_array)/6)\n",
    "        row_counter = 4\n",
    "        column_counter = 1\n",
    "        for value in split_array\n",
    "            temp = String(value)\n",
    "            temp = replace(temp,\"]\"=>\"\")\n",
    "            temp = replace(temp,\"[\"=>\"\")\n",
    "            temp = replace(temp,\",\"=>\"\")\n",
    "            m[row_counter, column_counter] = parse(Float32, temp)\n",
    "            column_counter += 1\n",
    "            if column_counter > 6\n",
    "                column_counter = 1\n",
    "                row_counter += 1\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # zero-padding\n",
    "        for i in n_atoms+1:60\n",
    "            m[i, 1:6] = [0,0,0,0,0,0]\n",
    "        end\n",
    "        x_data[1:60, 1:6, iter] = m\n",
    "        iter += 1\n",
    "    end\n",
    "    println(\"loading done, partitioning data.\")\n",
    "    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)\n",
    "    return (DataLoader(collect.((x_train, y_train)); batchsize=2^4, shuffle=true),\n",
    "            DataLoader(collect.((x_val, y_val)); batchsize=2^4, shuffle=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of debugging and as a reference, the original tutorial dataloading function is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_tutorial_dataloaders (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_tutorial_dataloaders()\n",
    "    dataset_size=1000\n",
    "    sequence_length=50\n",
    "    data = [MLUtils.Datasets.make_spiral(sequence_length) for _ in 1:dataset_size]\n",
    "    # Get the labels\n",
    "    labels = vcat(repeat([0.0f0], dataset_size ÷ 2), repeat([1.0f0], dataset_size ÷ 2))\n",
    "    clockwise_spirals = [reshape(d[1][:, 1:sequence_length], :, sequence_length, 1)\n",
    "                         for d in data[1:(dataset_size ÷ 2)]]\n",
    "    anticlockwise_spirals = [reshape(d[1][:, (sequence_length + 1):end], :, sequence_length,\n",
    "                                     1) for d in data[((dataset_size ÷ 2) + 1):end]]\n",
    "    x_data = Float32.(cat(clockwise_spirals..., anticlockwise_spirals...; dims=3))\n",
    "    # Split the dataset\n",
    "    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)\n",
    "    return (DataLoader(collect.((x_train, y_train)); batchsize=128, shuffle=true),\n",
    "            DataLoader(collect.((x_val, y_val)); batchsize=128, shuffle=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Neural Network\n",
    "Following from the tutorial in the [Lux documentation](https://lux.csail.mit.edu/stable/examples/generated/beginner/SimpleRNN/main/) we write a series of functions that will create our NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Lux, Random, Optimisers, Zygote, NNlib, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeding\n",
    "rng = Random.default_rng()\n",
    "Random.seed!(rng, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct StateClassifier{L, C} <:\n",
    "       Lux.AbstractExplicitContainerLayer{(:lstm_cell, :classifier)}\n",
    "    lstm_cell::L\n",
    "    classifier::C\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateClassifier"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function StateClassifier(in_dims, hidden_dims, out_dims)\n",
    "    return StateClassifier(LSTMCell(in_dims => hidden_dims),\n",
    "                            Dense(hidden_dims => out_dims, sigmoid))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (s::StateClassifier)(x::AbstractArray{T, 3}, ps::NamedTuple,\n",
    "                               st::NamedTuple) where {T}\n",
    "    x_init, x_rest = Iterators.peel(eachslice(x; dims=2))\n",
    "    (y, carry), st_lstm = s.lstm_cell(x_init, ps.lstm_cell, st.lstm_cell)\n",
    "    for x in x_rest\n",
    "        (y, carry), st_lstm = s.lstm_cell((x, carry), ps.lstm_cell, st_lstm)\n",
    "    end\n",
    "    y, st_classifier = s.classifier(y, ps.classifier, st.classifier)\n",
    "    st = merge(st, (classifier=st_classifier, lstm_cell=st_lstm))\n",
    "    return vec(y), st\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function xlogy(x, y)\n",
    "    result = x * log(y)\n",
    "    return ifelse(iszero(x), zero(result), result)\n",
    "end\n",
    "\n",
    "function binarycrossentropy(y_pred, y_true)\n",
    "    y_pred = y_pred .+ eps(eltype(y_pred))\n",
    "    return mean(@. -xlogy(y_true, y_pred) - xlogy(1 - y_true, 1 - y_pred))\n",
    "end\n",
    "\n",
    "function compute_loss(x, y, model, ps, st)\n",
    "    y_pred, st = model(x, ps, st)\n",
    "    return binarycrossentropy(y_pred, y), y_pred, st\n",
    "end\n",
    "\n",
    "matches(y_pred, y_true) = sum((y_pred .> 0.5) .== y_true)\n",
    "accuracy(y_pred, y_true) = matches(y_pred, y_true) / length(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_optimiser (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_optimiser(ps)\n",
    "    opt = Optimisers.ADAM(0.0001f0)\n",
    "    return Optimisers.setup(opt, ps)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NN\n",
    "Actual training and evaluation steps.\n",
    "\n",
    "Load the data from the file and parition it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:\n",
      " - row 275 of 16517\n",
      " - row 550 of 16517\n",
      " - row 825 of 16517\n",
      " - row 1100 of 16517\n",
      " - row 1375 of 16517\n",
      " - row 1650 of 16517\n",
      " - row 1925 of 16517\n",
      " - row 2200 of 16517\n",
      " - row 2475 of 16517\n",
      " - row 2750 of 16517\n",
      " - row 3025 of 16517\n",
      " - row 3300 of 16517\n",
      " - row 3575 of 16517\n",
      " - row 3850 of 16517\n",
      " - row 4125 of 16517\n",
      " - row 4400 of 16517\n",
      " - row 4675 of 16517\n",
      " - row 4950 of 16517\n",
      " - row 5225 of 16517\n",
      " - row 5500 of 16517\n",
      " - row 5775 of 16517\n",
      " - row 6050 of 16517\n",
      " - row 6325 of 16517\n",
      " - row 6600 of 16517\n",
      " - row 6875 of 16517\n",
      " - row 7150 of 16517\n",
      " - row 7425 of 16517\n",
      " - row 7700 of 16517\n",
      " - row 7975 of 16517\n",
      " - row 8250 of 16517\n",
      " - row 8525 of 16517\n",
      " - row 8800 of 16517\n",
      " - row 9075 of 16517\n",
      " - row 9350 of 16517\n",
      " - row 9625 of 16517\n",
      " - row 9900 of 16517\n",
      " - row 10175 of 16517\n",
      " - row 10450 of 16517\n",
      " - row 10725 of 16517\n",
      " - row 11000 of 16517\n",
      " - row 11275 of 16517\n",
      " - row 11550 of 16517\n",
      " - row 11825 of 16517\n",
      " - row 12100 of 16517\n",
      " - row 12375 of 16517\n",
      " - row 12650 of 16517\n",
      " - row 12925 of 16517\n",
      " - row 13200 of 16517\n",
      " - row 13475 of 16517\n",
      " - row 13750 of 16517\n",
      " - row 14025 of 16517\n",
      " - row 14300 of 16517\n",
      " - row 14575 of 16517\n",
      " - row 14850 of 16517\n",
      " - row 15125 of 16517\n",
      " - row 15400 of 16517\n",
      " - row 15675 of 16517\n",
      " - row 15950 of 16517\n",
      " - row 16225 of 16517\n",
      " - row 16500 of 16517\n",
      "loading done, partitioning data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DataLoader(::Tuple{Array{Float32, 3}, Vector{Float32}}, shuffle=true, batchsize=16), DataLoader(::Tuple{Array{Float32, 3}, Vector{Float32}}, batchsize=16))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_loader, val_loader) = get_dataloaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(lstm_cell = (weight_i = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, weight_h = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0; 0.0; … ; 0.0; 0.0;;], Float32[0.0; 0.0; … ; 0.0; 0.0;;], (0.9, 0.999))\u001b[32m)\u001b[39m), classifier = (weight = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam{Float32}(0.0001, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0;;], Float32[0.0;;], (0.9, 0.999))\u001b[32m)\u001b[39m))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StateClassifier(60, 6, 1)\n",
    "rng = Random.default_rng()\n",
    "Random.seed!(rng, 0)\n",
    "ps, st = Lux.setup(rng, model)\n",
    "opt_state = create_optimiser(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual model training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1:\n",
      " - loss of 0.5355283794405963\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 2:\n",
      " - loss of 0.49769447758324786\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 3:\n",
      " - loss of 0.4852402705978828\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 4:\n",
      " - loss of 0.4809976236186651\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 5:\n",
      " - loss of 0.4787262171759444\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 6:\n",
      " - loss of 0.4771813260116242\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 7:\n",
      " - loss of 0.47593226783500747\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 8:\n",
      " - loss of 0.47485157035597875\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 9:\n",
      " - loss of 0.4740213891243242\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 10:\n",
      " - loss of 0.47327926251631386\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 11:\n",
      " - loss of 0.47255177218602296\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 12:\n",
      " - loss of 0.47185062431250013\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 13:\n",
      " - loss of 0.471256309267828\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 14:\n",
      " - loss of 0.470636542444512\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 15:\n",
      " - loss of 0.4700354128426559\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 16:\n",
      " - loss of 0.4695802480703982\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 17:\n",
      " - loss of 0.4690084339775704\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 18:\n",
      " - loss of 0.4685450110034273\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 19:\n",
      " - loss of 0.46809409899731813\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 20:\n",
      " - loss of 0.46761692003245503\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 21:\n",
      " - loss of 0.4672125529398641\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 22:\n",
      " - loss of 0.46677772848715793\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 23:\n",
      " - loss of 0.4664365946705347\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 24:\n",
      " - loss of 0.46592524106508304\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 25:\n",
      " - loss of 0.46560652140915826\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 26:\n",
      " - loss of 0.46519880869919683\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 27:\n",
      " - loss of 0.4648369038003986\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 28:\n",
      " - loss of 0.4644669310232629\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 29:\n",
      " - loss of 0.4640988708083624\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 30:\n",
      " - loss of 0.46370734103005967\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 31:\n",
      " - loss of 0.4633061714452346\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 32:\n",
      " - loss of 0.4629520065631474\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 33:\n",
      " - loss of 0.4626264226674745\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 34:\n",
      " - loss of 0.46229801568728096\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 35:\n",
      " - loss of 0.4618940908308468\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 36:\n",
      " - loss of 0.46159667263741067\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 37:\n",
      " - loss of 0.46125411449708315\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 38:\n",
      " - loss of 0.4608793515739083\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 39:\n",
      " - loss of 0.46054234402592475\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 40:\n",
      " - loss of 0.4601621615359916\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 41:\n",
      " - loss of 0.4597884981777997\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 42:\n",
      " - loss of 0.4594749330788779\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 43:\n",
      " - loss of 0.45905404705689545\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 44:\n",
      " - loss of 0.45872648083774\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 45:\n",
      " - loss of 0.458386570431707\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 46:\n",
      " - loss of 0.4580486428362405\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 47:\n",
      " - loss of 0.45763093364801594\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 48:\n",
      " - loss of 0.4573478340633556\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 49:\n",
      " - loss of 0.45695418559610124\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 50:\n",
      " - loss of 0.4566487633684068\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 51:\n",
      " - loss of 0.45622581144294205\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 52:\n",
      " - loss of 0.45588825103662206\n",
      " - accuracy of 0.8063750862663907\n",
      "Epoch # 53:\n",
      " - loss of 0.4555119399260955\n",
      " - accuracy of 0.8060731538992408\n",
      "Epoch # 54:\n",
      " - loss of 0.4551967761995717\n",
      " - accuracy of 0.8060731538992408\n",
      "Epoch # 55:\n",
      " - loss of 0.454752380150138\n",
      " - accuracy of 0.8060731538992408\n",
      "Epoch # 56:\n",
      " - loss of 0.45439199884997156\n",
      " - accuracy of 0.8060731538992408\n",
      "Epoch # 57:\n",
      " - loss of 0.454084627799347\n",
      " - accuracy of 0.8060731538992408\n",
      "Epoch # 58:\n",
      " - loss of 0.45369752207838593\n",
      " - accuracy of 0.8057712215320911\n",
      "Epoch # 59:\n",
      " - loss of 0.4533675739645381\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 60:\n",
      " - loss of 0.4529637189415119\n",
      " - accuracy of 0.8057712215320911\n",
      "Epoch # 61:\n",
      " - loss of 0.4527416086009282\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 62:\n",
      " - loss of 0.45228025098906305\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 63:\n",
      " - loss of 0.45198392056235387\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 64:\n",
      " - loss of 0.45162810363579026\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 65:\n",
      " - loss of 0.4512721415221258\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 66:\n",
      " - loss of 0.4509789115471932\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 67:\n",
      " - loss of 0.4506401786576172\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 68:\n",
      " - loss of 0.45030854544974414\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 69:\n",
      " - loss of 0.4499548387873837\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 70:\n",
      " - loss of 0.4496899681215425\n",
      " - accuracy of 0.8048654244306418\n",
      "Epoch # 71:\n",
      " - loss of 0.44928447701956975\n",
      " - accuracy of 0.8045634920634921\n",
      "Epoch # 72:\n",
      " - loss of 0.4490153980565417\n",
      " - accuracy of 0.8048654244306418\n",
      "Epoch # 73:\n",
      " - loss of 0.44870532491666065\n",
      " - accuracy of 0.8048654244306418\n",
      "Epoch # 74:\n",
      " - loss of 0.4483674173457571\n",
      " - accuracy of 0.8048654244306418\n",
      "Epoch # 75:\n",
      " - loss of 0.4480481657219857\n",
      " - accuracy of 0.8048654244306418\n",
      "Epoch # 76:\n",
      " - loss of 0.44772198406605107\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 77:\n",
      " - loss of 0.4474677459199261\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 78:\n",
      " - loss of 0.4470989646944815\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 79:\n",
      " - loss of 0.44686047418931496\n",
      " - accuracy of 0.8054692891649413\n",
      "Epoch # 80:\n",
      " - loss of 0.4465484625635078\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 81:\n",
      " - loss of 0.4462540311508837\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 82:\n",
      " - loss of 0.44594024783834707\n",
      " - accuracy of 0.8048654244306418\n",
      "Epoch # 83:\n",
      " - loss of 0.44567079811422355\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 84:\n",
      " - loss of 0.4453200609321744\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 85:\n",
      " - loss of 0.4450833560407306\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 86:\n",
      " - loss of 0.44475547866512444\n",
      " - accuracy of 0.8048654244306418\n",
      "Epoch # 87:\n",
      " - loss of 0.4445481102633996\n",
      " - accuracy of 0.8048654244306418\n",
      "Epoch # 88:\n",
      " - loss of 0.44420666168229633\n",
      " - accuracy of 0.8045634920634921\n",
      "Epoch # 89:\n",
      " - loss of 0.4439613505223761\n",
      " - accuracy of 0.8045634920634921\n",
      "Epoch # 90:\n",
      " - loss of 0.4436442907764317\n",
      " - accuracy of 0.8045634920634921\n",
      "Epoch # 91:\n",
      " - loss of 0.44343311888037235\n",
      " - accuracy of 0.8051673567977916\n",
      "Epoch # 92:\n",
      " - loss of 0.4430655385333747\n",
      " - accuracy of 0.8042615596963423\n",
      "Epoch # 93:\n",
      " - loss of 0.4428595764152074\n",
      " - accuracy of 0.8045634920634921\n",
      "Epoch # 94:\n",
      " - loss of 0.4426264716154438\n",
      " - accuracy of 0.8045634920634921\n",
      "Epoch # 95:\n",
      " - loss of 0.44232891786834516\n",
      " - accuracy of 0.8045634920634921\n",
      "Epoch # 96:\n",
      " - loss of 0.4420229062510172\n",
      " - accuracy of 0.803355762594893\n",
      "Epoch # 97:\n",
      " - loss of 0.4418171012444877\n",
      " - accuracy of 0.8042615596963423\n",
      "Epoch # 98:\n",
      " - loss of 0.44150374037806694\n",
      " - accuracy of 0.8036576949620428\n",
      "Epoch # 99:\n",
      " - loss of 0.44132077035473855\n",
      " - accuracy of 0.8045634920634921\n",
      "Epoch # 100:\n",
      " - loss of 0.440982910373742\n",
      " - accuracy of 0.8048654244306418\n",
      "Epoch # 101:\n",
      " - loss of 0.4407707804376507\n",
      " - accuracy of 0.8018461007591443\n",
      "Epoch # 102:\n",
      " - loss of 0.440494994418673\n",
      " - accuracy of 0.802148033126294\n",
      "Epoch # 103:\n",
      " - loss of 0.4403407958676682\n",
      " - accuracy of 0.8018461007591443\n",
      "Epoch # 104:\n",
      " - loss of 0.44008031772499223\n",
      " - accuracy of 0.8015441683919945\n",
      "Epoch # 105:\n",
      " - loss of 0.4398328445256478\n",
      " - accuracy of 0.8018461007591443\n",
      "Epoch # 106:\n",
      " - loss of 0.4395745267807427\n",
      " - accuracy of 0.8018461007591443\n",
      "Epoch # 107:\n",
      " - loss of 0.4393689026357042\n",
      " - accuracy of 0.8015441683919945\n",
      "Epoch # 108:\n",
      " - loss of 0.4391419715439725\n",
      " - accuracy of 0.8015441683919945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 109:\n",
      " - loss of 0.43890100551575206\n",
      " - accuracy of 0.8012422360248448\n",
      "Epoch # 110:\n",
      " - loss of 0.4387239759864588\n",
      " - accuracy of 0.8018461007591443\n",
      "Epoch # 111:\n",
      " - loss of 0.4384171469520426\n",
      " - accuracy of 0.8015441683919945\n",
      "Epoch # 112:\n",
      " - loss of 0.43826299876912744\n",
      " - accuracy of 0.8015441683919945\n",
      "Epoch # 113:\n",
      " - loss of 0.4380062814017185\n",
      " - accuracy of 0.802148033126294\n",
      "Epoch # 114:\n",
      " - loss of 0.4377482482942484\n",
      " - accuracy of 0.8015441683919945\n",
      "Epoch # 115:\n",
      " - loss of 0.43752987230011686\n",
      " - accuracy of 0.8018461007591443\n",
      "Epoch # 116:\n",
      " - loss of 0.4372815247670213\n",
      " - accuracy of 0.8015441683919945\n",
      "Epoch # 117:\n",
      " - loss of 0.4371494181075339\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 118:\n",
      " - loss of 0.4369227043364296\n",
      " - accuracy of 0.8012422360248448\n",
      "Epoch # 119:\n",
      " - loss of 0.43664717344120685\n",
      " - accuracy of 0.8012422360248448\n",
      "Epoch # 120:\n",
      " - loss of 0.4364677699729259\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 121:\n",
      " - loss of 0.4362483411377914\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 122:\n",
      " - loss of 0.43608740726192696\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 123:\n",
      " - loss of 0.4358711614844008\n",
      " - accuracy of 0.7997325741890959\n",
      "Epoch # 124:\n",
      " - loss of 0.43563900384646065\n",
      " - accuracy of 0.7997325741890959\n",
      "Epoch # 125:\n",
      " - loss of 0.4354881046759303\n",
      " - accuracy of 0.7997325741890959\n",
      "Epoch # 126:\n",
      " - loss of 0.4352670173199067\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 127:\n",
      " - loss of 0.4350673412728252\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 128:\n",
      " - loss of 0.43487294103959284\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 129:\n",
      " - loss of 0.43464824739509866\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 130:\n",
      " - loss of 0.43443256154764653\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 131:\n",
      " - loss of 0.43432705540922595\n",
      " - accuracy of 0.7997325741890959\n",
      "Epoch # 132:\n",
      " - loss of 0.43410177532466215\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 133:\n",
      " - loss of 0.4339264183154118\n",
      " - accuracy of 0.8012422360248448\n",
      "Epoch # 134:\n",
      " - loss of 0.4337032097628561\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 135:\n",
      " - loss of 0.43352125752852555\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 136:\n",
      " - loss of 0.4333331673327139\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 137:\n",
      " - loss of 0.43314173316118504\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 138:\n",
      " - loss of 0.43304457755412085\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 139:\n",
      " - loss of 0.43286595939146694\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 140:\n",
      " - loss of 0.43265956508550457\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 141:\n",
      " - loss of 0.4324344415352939\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 142:\n",
      " - loss of 0.4323318071537099\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 143:\n",
      " - loss of 0.432158647993575\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 144:\n",
      " - loss of 0.4319861629215626\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 145:\n",
      " - loss of 0.4318270785937009\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 146:\n",
      " - loss of 0.4315655243382327\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 147:\n",
      " - loss of 0.4312540559192835\n",
      " - accuracy of 0.7996463077984818\n",
      "Epoch # 148:\n",
      " - loss of 0.43131457413512914\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 149:\n",
      " - loss of 0.4311979383807494\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 150:\n",
      " - loss of 0.43097785669074506\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 151:\n",
      " - loss of 0.43085909394894617\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 152:\n",
      " - loss of 0.43069013015121294\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 153:\n",
      " - loss of 0.43048501776003667\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 154:\n",
      " - loss of 0.4303614543728332\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 155:\n",
      " - loss of 0.4301570861467293\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 156:\n",
      " - loss of 0.43000304251548455\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 157:\n",
      " - loss of 0.42990020005884816\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 158:\n",
      " - loss of 0.42970107335227453\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 159:\n",
      " - loss of 0.42958430691507193\n",
      " - accuracy of 0.800940303657695\n",
      "Epoch # 160:\n",
      " - loss of 0.42945525369473864\n",
      " - accuracy of 0.8006383712905453\n",
      "Epoch # 161:\n",
      " - loss of 0.42930255851034105\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 162:\n",
      " - loss of 0.4291089005028653\n",
      " - accuracy of 0.8000345065562458\n",
      "Epoch # 163:\n",
      " - loss of 0.42883865082451567\n",
      " - accuracy of 0.7987405106970324\n",
      "Epoch # 164:\n",
      " - loss of 0.42883105140368816\n",
      " - accuracy of 0.8003364389233955\n",
      "Epoch # 165:\n",
      " - loss of 0.42869252137857833\n",
      " - accuracy of 0.7988267770876467\n",
      "Epoch # 166:\n",
      " - loss of 0.4284933414896522\n",
      " - accuracy of 0.7997325741890959\n",
      "Epoch # 167:\n",
      " - loss of 0.4283090126644324\n",
      " - accuracy of 0.7991287094547964\n",
      "Epoch # 168:\n",
      " - loss of 0.42822178602940236\n",
      " - accuracy of 0.7988267770876467\n",
      "Epoch # 169:\n",
      " - loss of 0.42807195799258374\n",
      " - accuracy of 0.7988267770876467\n",
      "Epoch # 170:\n",
      " - loss of 0.4279429256266601\n",
      " - accuracy of 0.7994306418219462\n",
      "Epoch # 171:\n",
      " - loss of 0.4278192237813305\n",
      " - accuracy of 0.7988267770876467\n",
      "Epoch # 172:\n",
      " - loss of 0.427592729811374\n",
      " - accuracy of 0.7994306418219462\n",
      "Epoch # 173:\n",
      " - loss of 0.42753633064810936\n",
      " - accuracy of 0.7982229123533472\n",
      "Epoch # 174:\n",
      " - loss of 0.4273628497509777\n",
      " - accuracy of 0.7985248447204969\n",
      "Epoch # 175:\n",
      " - loss of 0.4271659360562629\n",
      " - accuracy of 0.7985248447204969\n",
      "Epoch # 176:\n",
      " - loss of 0.42709588488568406\n",
      " - accuracy of 0.7982229123533472\n",
      "Epoch # 177:\n",
      " - loss of 0.4269363426086978\n",
      " - accuracy of 0.7985248447204969\n",
      "Epoch # 178:\n",
      " - loss of 0.4268137990490288\n",
      " - accuracy of 0.7988267770876467\n",
      "Epoch # 179:\n",
      " - loss of 0.42669305548107944\n",
      " - accuracy of 0.7991287094547964\n",
      "Epoch # 180:\n",
      " - loss of 0.426533263961426\n",
      " - accuracy of 0.7985248447204969\n",
      "Epoch # 181:\n",
      " - loss of 0.4263880265466237\n",
      " - accuracy of 0.7979209799861974\n",
      "Epoch # 182:\n",
      " - loss of 0.42634576839591054\n",
      " - accuracy of 0.7973171152518979\n",
      "Epoch # 183:\n",
      " - loss of 0.4260836237676207\n",
      " - accuracy of 0.7976190476190477\n",
      "Epoch # 184:\n",
      " - loss of 0.42592816772818853\n",
      " - accuracy of 0.7976190476190477\n",
      "Epoch # 185:\n",
      " - loss of 0.4258194600770895\n",
      " - accuracy of 0.7979209799861974\n",
      "Epoch # 186:\n",
      " - loss of 0.42575728420628184\n",
      " - accuracy of 0.7976190476190477\n",
      "Epoch # 187:\n",
      " - loss of 0.4255677583395136\n",
      " - accuracy of 0.7970151828847482\n",
      "Epoch # 188:\n",
      " - loss of 0.4254398464290628\n",
      " - accuracy of 0.7961093857832988\n",
      "Epoch # 189:\n",
      " - loss of 0.4252067273324829\n",
      " - accuracy of 0.7964113181504486\n",
      "Epoch # 190:\n",
      " - loss of 0.42523980750442997\n",
      " - accuracy of 0.7961093857832988\n",
      "Epoch # 191:\n",
      " - loss of 0.42498553374705533\n",
      " - accuracy of 0.7955055210489993\n",
      "Epoch # 192:\n",
      " - loss of 0.42494608582725824\n",
      " - accuracy of 0.7970151828847482\n",
      "Epoch # 193:\n",
      " - loss of 0.4247976686832547\n",
      " - accuracy of 0.7964113181504486\n",
      "Epoch # 194:\n",
      " - loss of 0.42465454747688397\n",
      " - accuracy of 0.7964113181504486\n",
      "Epoch # 195:\n",
      " - loss of 0.4245767506069479\n",
      " - accuracy of 0.7945997239475501\n",
      "Epoch # 196:\n",
      " - loss of 0.4244342128910828\n",
      " - accuracy of 0.7958074534161491\n",
      "Epoch # 197:\n",
      " - loss of 0.42430533662654873\n",
      " - accuracy of 0.7961093857832988\n",
      "Epoch # 198:\n",
      " - loss of 0.4241249587468027\n",
      " - accuracy of 0.7955055210489993\n",
      "Epoch # 199:\n",
      " - loss of 0.42390192859325804\n",
      " - accuracy of 0.7964113181504486\n",
      "Epoch # 200:\n",
      " - loss of 0.42384667431182493\n",
      " - accuracy of 0.7952035886818496\n",
      "Epoch # 201:\n",
      " - loss of 0.42373398993588246\n",
      " - accuracy of 0.7949016563146998\n",
      "Epoch # 202:\n",
      " - loss of 0.42356542515011447\n",
      " - accuracy of 0.7945997239475501\n",
      "Epoch # 203:\n",
      " - loss of 0.42346825250413167\n",
      " - accuracy of 0.7949016563146998\n",
      "Epoch # 204:\n",
      " - loss of 0.4234001395488767\n",
      " - accuracy of 0.7942977915804003\n",
      "Epoch # 205:\n",
      " - loss of 0.42330935012918985\n",
      " - accuracy of 0.7942977915804003\n",
      "Epoch # 206:\n",
      " - loss of 0.42316619280644535\n",
      " - accuracy of 0.7945997239475501\n",
      "Epoch # 207:\n",
      " - loss of 0.42303998343484167\n",
      " - accuracy of 0.7945997239475501\n",
      "Epoch # 208:\n",
      " - loss of 0.42291714561331933\n",
      " - accuracy of 0.7949016563146998\n",
      "Epoch # 209:\n",
      " - loss of 0.4227908298679905\n",
      " - accuracy of 0.7942977915804003\n",
      "Epoch # 210:\n",
      " - loss of 0.42267824206095345\n",
      " - accuracy of 0.7936939268461007\n",
      "Epoch # 211:\n",
      " - loss of 0.4225050064917771\n",
      " - accuracy of 0.7927881297446515\n",
      "Epoch # 212:\n",
      " - loss of 0.4224455088160517\n",
      " - accuracy of 0.7936939268461007\n",
      "Epoch # 213:\n",
      " - loss of 0.4222322035283211\n",
      " - accuracy of 0.7936939268461007\n",
      "Epoch # 214:\n",
      " - loss of 0.4222089925253218\n",
      " - accuracy of 0.7945997239475501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 215:\n",
      " - loss of 0.42200955520350186\n",
      " - accuracy of 0.7936939268461007\n",
      "Epoch # 216:\n",
      " - loss of 0.4219149679901669\n",
      " - accuracy of 0.793391994478951\n",
      "Epoch # 217:\n",
      " - loss of 0.421816881538592\n",
      " - accuracy of 0.7936939268461007\n",
      "Epoch # 218:\n",
      " - loss of 0.4216969364906772\n",
      " - accuracy of 0.7942977915804003\n",
      "Epoch # 219:\n",
      " - loss of 0.42151981192589094\n",
      " - accuracy of 0.7939958592132506\n",
      "Epoch # 220:\n",
      " - loss of 0.42146280635211425\n",
      " - accuracy of 0.7936939268461007\n",
      "Epoch # 221:\n",
      " - loss of 0.42128632823794576\n",
      " - accuracy of 0.793391994478951\n",
      "Epoch # 222:\n",
      " - loss of 0.42116200653317476\n",
      " - accuracy of 0.7930900621118012\n",
      "Epoch # 223:\n",
      " - loss of 0.4211178751387261\n",
      " - accuracy of 0.7927881297446515\n",
      "Epoch # 224:\n",
      " - loss of 0.4208431341313277\n",
      " - accuracy of 0.7952035886818496\n",
      "Epoch # 225:\n",
      " - loss of 0.4208107980162122\n",
      " - accuracy of 0.7936939268461007\n",
      "Epoch # 226:\n",
      " - loss of 0.4206660367710827\n",
      " - accuracy of 0.7945997239475501\n",
      "Epoch # 227:\n",
      " - loss of 0.42048448722890736\n",
      " - accuracy of 0.7930900621118012\n",
      "Epoch # 228:\n",
      " - loss of 0.4204098277569683\n",
      " - accuracy of 0.7936939268461007\n",
      "Epoch # 229:\n",
      " - loss of 0.4203235274293521\n",
      " - accuracy of 0.7952035886818496\n",
      "Epoch # 230:\n",
      " - loss of 0.4201889228589887\n",
      " - accuracy of 0.7955055210489993\n",
      "Epoch # 231:\n",
      " - loss of 0.4200694843152533\n",
      " - accuracy of 0.7952035886818496\n",
      "Epoch # 232:\n",
      " - loss of 0.4199726908460945\n",
      " - accuracy of 0.7952035886818496\n",
      "Epoch # 233:\n",
      " - loss of 0.41979618040398303\n",
      " - accuracy of 0.7952035886818496\n",
      "Epoch # 234:\n",
      " - loss of 0.41971573024338726\n",
      " - accuracy of 0.7952035886818496\n",
      "Epoch # 235:\n",
      " - loss of 0.41959090232307916\n",
      " - accuracy of 0.7955055210489993\n",
      "Epoch # 236:\n",
      " - loss of 0.4194662189765069\n",
      " - accuracy of 0.7949016563146998\n",
      "Epoch # 237:\n",
      " - loss of 0.41934999669326994\n",
      " - accuracy of 0.7952035886818496\n",
      "Epoch # 238:\n",
      " - loss of 0.41924645652493897\n",
      " - accuracy of 0.7955055210489993\n",
      "Epoch # 239:\n",
      " - loss of 0.4191206356839753\n",
      " - accuracy of 0.7955055210489993\n",
      "Epoch # 240:\n",
      " - loss of 0.4189819571884579\n",
      " - accuracy of 0.7949016563146998\n",
      "Epoch # 241:\n",
      " - loss of 0.4187316600296457\n",
      " - accuracy of 0.7958074534161491\n",
      "Epoch # 242:\n",
      " - loss of 0.4187273232956342\n",
      " - accuracy of 0.7958074534161491\n",
      "Epoch # 243:\n",
      " - loss of 0.4186422931567087\n",
      " - accuracy of 0.7958074534161491\n",
      "Epoch # 244:\n",
      " - loss of 0.4184552524013323\n",
      " - accuracy of 0.7949016563146998\n",
      "Epoch # 245:\n",
      " - loss of 0.41830418180430773\n",
      " - accuracy of 0.792184265010352\n",
      "Epoch # 246:\n",
      " - loss of 0.4183128482096132\n",
      " - accuracy of 0.7945997239475501\n",
      "Epoch # 247:\n",
      " - loss of 0.4181890665546745\n",
      " - accuracy of 0.7949016563146998\n",
      "Epoch # 248:\n",
      " - loss of 0.4180261947521286\n",
      " - accuracy of 0.7952035886818496\n",
      "Epoch # 249:\n",
      " - loss of 0.4178572085395131\n",
      " - accuracy of 0.7955055210489993\n",
      "Epoch # 250:\n",
      " - loss of 0.4178151697389439\n",
      " - accuracy of 0.7955055210489993\n",
      "Epoch # 251:\n",
      " - loss of 0.4176775531676433\n",
      " - accuracy of 0.7930900621118012\n",
      "Epoch # 252:\n",
      " - loss of 0.41757789839591297\n",
      " - accuracy of 0.7936939268461007\n",
      "Epoch # 253:\n",
      " - loss of 0.4173637168080553\n",
      " - accuracy of 0.7939958592132506\n",
      "Epoch # 254:\n",
      " - loss of 0.41734509184487506\n",
      " - accuracy of 0.7936939268461007\n",
      "Epoch # 255:\n",
      " - loss of 0.417197591618389\n",
      " - accuracy of 0.7912784679089027\n",
      "Epoch # 256:\n",
      " - loss of 0.41701683840437026\n",
      " - accuracy of 0.792184265010352\n",
      "Epoch # 257:\n",
      " - loss of 0.4171008305222734\n",
      " - accuracy of 0.7915804002760525\n",
      "Epoch # 258:\n",
      " - loss of 0.41681039815015425\n",
      " - accuracy of 0.7930900621118012\n",
      "Epoch # 259:\n",
      " - loss of 0.41678855470753756\n",
      " - accuracy of 0.7927881297446515\n",
      "Epoch # 260:\n",
      " - loss of 0.4166866460269358\n",
      " - accuracy of 0.7927881297446515\n",
      "Epoch # 261:\n",
      " - loss of 0.4165568948152856\n",
      " - accuracy of 0.790976535541753\n",
      "Epoch # 262:\n",
      " - loss of 0.41643715616468946\n",
      " - accuracy of 0.7915804002760525\n",
      "Epoch # 263:\n",
      " - loss of 0.4162300296362318\n",
      " - accuracy of 0.7924861973775017\n",
      "Epoch # 264:\n",
      " - loss of 0.4163612642440467\n",
      " - accuracy of 0.790976535541753\n",
      "Epoch # 265:\n",
      " - loss of 0.4160759545519912\n",
      " - accuracy of 0.790976535541753\n",
      "Epoch # 266:\n",
      " - loss of 0.4159502070171637\n",
      " - accuracy of 0.790976535541753\n",
      "Epoch # 267:\n",
      " - loss of 0.4159786490313077\n",
      " - accuracy of 0.7918823326432022\n",
      "Epoch # 268:\n",
      " - loss of 0.41593845483574104\n",
      " - accuracy of 0.7918823326432022\n",
      "Epoch # 269:\n",
      " - loss of 0.4156999047349498\n",
      " - accuracy of 0.7891649413388544\n",
      "Epoch # 270:\n",
      " - loss of 0.41557870786321366\n",
      " - accuracy of 0.7897688060731539\n",
      "Epoch # 271:\n",
      " - loss of 0.4154649564667129\n",
      " - accuracy of 0.7888630089717047\n",
      "Epoch # 272:\n",
      " - loss of 0.4153813135519299\n",
      " - accuracy of 0.7894668737060042\n",
      "Epoch # 273:\n",
      " - loss of 0.4152079481387975\n",
      " - accuracy of 0.7912784679089027\n",
      "Epoch # 274:\n",
      " - loss of 0.4152142542885666\n",
      " - accuracy of 0.7888630089717047\n",
      "Epoch # 275:\n",
      " - loss of 0.4150694962365431\n",
      " - accuracy of 0.7897688060731539\n",
      "Epoch # 276:\n",
      " - loss of 0.41491401097207325\n",
      " - accuracy of 0.7888630089717047\n",
      "Epoch # 277:\n",
      " - loss of 0.41481523554023475\n",
      " - accuracy of 0.7867494824016563\n",
      "Epoch # 278:\n",
      " - loss of 0.4146423391889573\n",
      " - accuracy of 0.7897688060731539\n",
      "Epoch # 279:\n",
      " - loss of 0.4145244629489885\n",
      " - accuracy of 0.7867494824016563\n",
      "Epoch # 280:\n",
      " - loss of 0.4144579931804978\n",
      " - accuracy of 0.7885610766045549\n",
      "Epoch # 281:\n",
      " - loss of 0.4144282426694115\n",
      " - accuracy of 0.7891649413388544\n",
      "Epoch # 282:\n",
      " - loss of 0.4143580276492\n",
      " - accuracy of 0.7888630089717047\n",
      "Epoch # 283:\n",
      " - loss of 0.41412787651755906\n",
      " - accuracy of 0.7861456176673568\n",
      "Epoch # 284:\n",
      " - loss of 0.4141885962418436\n",
      " - accuracy of 0.7885610766045549\n",
      "Epoch # 285:\n",
      " - loss of 0.4139432934074512\n",
      " - accuracy of 0.7891649413388544\n",
      "Epoch # 286:\n",
      " - loss of 0.4138733022654605\n",
      " - accuracy of 0.7873533471359558\n",
      "Epoch # 287:\n",
      " - loss of 0.41365388573370604\n",
      " - accuracy of 0.7885610766045549\n",
      "Epoch # 288:\n",
      " - loss of 0.4137082507261064\n",
      " - accuracy of 0.7861456176673568\n",
      "Epoch # 289:\n",
      " - loss of 0.4135968052121398\n",
      " - accuracy of 0.7882591442374052\n",
      "Epoch # 290:\n",
      " - loss of 0.41353849276503407\n",
      " - accuracy of 0.7876552795031057\n",
      "Epoch # 291:\n",
      " - loss of 0.41331947324278856\n",
      " - accuracy of 0.7858436853002071\n",
      "Epoch # 292:\n",
      " - loss of 0.4132539230797972\n",
      " - accuracy of 0.7867494824016563\n",
      "Epoch # 293:\n",
      " - loss of 0.4132275994659625\n",
      " - accuracy of 0.7837301587301587\n",
      "Epoch # 294:\n",
      " - loss of 0.4131604445958397\n",
      " - accuracy of 0.7852398205659076\n",
      "Epoch # 295:\n",
      " - loss of 0.4130220673346924\n",
      " - accuracy of 0.7837301587301587\n",
      "Epoch # 296:\n",
      " - loss of 0.4128965254485174\n",
      " - accuracy of 0.7858436853002071\n",
      "Epoch # 297:\n",
      " - loss of 0.41287800404479946\n",
      " - accuracy of 0.7840320910973085\n",
      "Epoch # 298:\n",
      " - loss of 0.41266629708700836\n",
      " - accuracy of 0.78222049689441\n",
      "Epoch # 299:\n",
      " - loss of 0.4126336824230074\n",
      " - accuracy of 0.7825224292615597\n",
      "Epoch # 300:\n",
      " - loss of 0.4125401262130778\n",
      " - accuracy of 0.7849378881987578\n",
      "Epoch # 301:\n",
      " - loss of 0.41246282431064735\n",
      " - accuracy of 0.783428226363009\n",
      "Epoch # 302:\n",
      " - loss of 0.41223901471452334\n",
      " - accuracy of 0.7867494824016563\n",
      "Epoch # 303:\n",
      " - loss of 0.41226991132515106\n",
      " - accuracy of 0.7852398205659076\n",
      "Epoch # 304:\n",
      " - loss of 0.41195227609852614\n",
      " - accuracy of 0.7840320910973085\n",
      "Epoch # 305:\n",
      " - loss of 0.4118697169455576\n",
      " - accuracy of 0.7843340234644582\n",
      "Epoch # 306:\n",
      " - loss of 0.4119994367853926\n",
      " - accuracy of 0.7849378881987578\n",
      "Epoch # 307:\n",
      " - loss of 0.41175532193074216\n",
      " - accuracy of 0.7819185645272602\n",
      "Epoch # 308:\n",
      " - loss of 0.4114643220697275\n",
      " - accuracy of 0.7864475500345066\n",
      "Epoch # 309:\n",
      " - loss of 0.4114697039055189\n",
      " - accuracy of 0.7813146997929606\n",
      "Epoch # 310:\n",
      " - loss of 0.41142014455564374\n",
      " - accuracy of 0.7837301587301587\n",
      "Epoch # 311:\n",
      " - loss of 0.4112278477313588\n",
      " - accuracy of 0.7837301587301587\n",
      "Epoch # 312:\n",
      " - loss of 0.4111968137630539\n",
      " - accuracy of 0.7849378881987578\n",
      "Epoch # 313:\n",
      " - loss of 0.41107868180400525\n",
      " - accuracy of 0.7828243616287095\n",
      "Epoch # 314:\n",
      " - loss of 0.4109993722858065\n",
      " - accuracy of 0.7840320910973085\n",
      "Epoch # 315:\n",
      " - loss of 0.4109307124254634\n",
      " - accuracy of 0.7831262939958592\n",
      "Epoch # 316:\n",
      " - loss of 0.4107050844186299\n",
      " - accuracy of 0.7835144927536232\n",
      "Epoch # 317:\n",
      " - loss of 0.41070060722403606\n",
      " - accuracy of 0.783816425120773\n",
      "Epoch # 318:\n",
      " - loss of 0.4106942853252189\n",
      " - accuracy of 0.7844202898550725\n",
      "Epoch # 319:\n",
      " - loss of 0.41051548723916165\n",
      " - accuracy of 0.7846359558316081\n",
      "Epoch # 320:\n",
      " - loss of 0.41045072203903454\n",
      " - accuracy of 0.7846359558316081\n",
      "Epoch # 321:\n",
      " - loss of 0.4103409295978327\n",
      " - accuracy of 0.7837301587301587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 322:\n",
      " - loss of 0.4101717824580883\n",
      " - accuracy of 0.7820048309178744\n",
      "Epoch # 323:\n",
      " - loss of 0.4100589167245508\n",
      " - accuracy of 0.7817028985507246\n",
      "Epoch # 324:\n",
      " - loss of 0.4099903860136181\n",
      " - accuracy of 0.7844202898550725\n",
      "Epoch # 325:\n",
      " - loss of 0.4099628142741921\n",
      " - accuracy of 0.7831262939958592\n",
      "Epoch # 326:\n",
      " - loss of 0.40983789353732913\n",
      " - accuracy of 0.7832125603864735\n",
      "Epoch # 327:\n",
      " - loss of 0.4097617305183815\n",
      " - accuracy of 0.7832125603864735\n",
      "Epoch # 328:\n",
      " - loss of 0.40975075546137935\n",
      " - accuracy of 0.7829106280193237\n",
      "Epoch # 329:\n",
      " - loss of 0.4093991652419723\n",
      " - accuracy of 0.7846359558316081\n",
      "Epoch # 330:\n",
      " - loss of 0.40950446021145537\n",
      " - accuracy of 0.7835144927536232\n",
      "Epoch # 331:\n",
      " - loss of 0.4092808796079338\n",
      " - accuracy of 0.783816425120773\n",
      "Epoch # 332:\n",
      " - loss of 0.4091763100237304\n",
      " - accuracy of 0.7852398205659076\n",
      "Epoch # 333:\n",
      " - loss of 0.4091917511445558\n",
      " - accuracy of 0.7844202898550725\n",
      "Epoch # 334:\n",
      " - loss of 0.4090565484080274\n",
      " - accuracy of 0.783816425120773\n",
      "Epoch # 335:\n",
      " - loss of 0.40896162755119886\n",
      " - accuracy of 0.7853260869565217\n",
      "Epoch # 336:\n",
      " - loss of 0.40881802819975926\n",
      " - accuracy of 0.782608695652174\n",
      "Epoch # 337:\n",
      " - loss of 0.40885080903155174\n",
      " - accuracy of 0.782608695652174\n",
      "Epoch # 338:\n",
      " - loss of 0.4086438085766595\n",
      " - accuracy of 0.783816425120773\n",
      "Epoch # 339:\n",
      " - loss of 0.40867678309648725\n",
      " - accuracy of 0.783816425120773\n",
      "Epoch # 340:\n",
      " - loss of 0.40843028055625735\n",
      " - accuracy of 0.7847222222222222\n",
      "Epoch # 341:\n",
      " - loss of 0.40837746965033667\n",
      " - accuracy of 0.7817028985507246\n",
      "Epoch # 342:\n",
      " - loss of 0.4083209509711\n",
      " - accuracy of 0.7835144927536232\n",
      "Epoch # 343:\n",
      " - loss of 0.40831722780051877\n",
      " - accuracy of 0.7829106280193237\n",
      "Epoch # 344:\n",
      " - loss of 0.40815911188577336\n",
      " - accuracy of 0.7841183574879227\n",
      "Epoch # 345:\n",
      " - loss of 0.4082215580701395\n",
      " - accuracy of 0.7841183574879227\n",
      "Epoch # 346:\n",
      " - loss of 0.4079358827854906\n",
      " - accuracy of 0.7856280193236715\n",
      "Epoch # 347:\n",
      " - loss of 0.407893540242971\n",
      " - accuracy of 0.783816425120773\n",
      "Epoch # 348:\n",
      " - loss of 0.40786989501364007\n",
      " - accuracy of 0.7832125603864735\n",
      "Epoch # 349:\n",
      " - loss of 0.4077312738767692\n",
      " - accuracy of 0.7844202898550725\n",
      "Epoch # 350:\n",
      " - loss of 0.40763917320901777\n",
      " - accuracy of 0.7832125603864735\n",
      "Epoch # 351:\n",
      " - loss of 0.40754292624806376\n",
      " - accuracy of 0.7817028985507246\n",
      "Epoch # 352:\n",
      " - loss of 0.4075223919067342\n",
      " - accuracy of 0.7829106280193237\n",
      "Epoch # 353:\n",
      " - loss of 0.4073611602060876\n",
      " - accuracy of 0.7817028985507246\n",
      "Epoch # 354:\n",
      " - loss of 0.4072189162289115\n",
      " - accuracy of 0.7835144927536232\n",
      "Epoch # 355:\n",
      " - loss of 0.4072224216729619\n",
      " - accuracy of 0.7820048309178744\n",
      "Epoch # 356:\n",
      " - loss of 0.4070150970727133\n",
      " - accuracy of 0.7817028985507246\n",
      "Epoch # 357:\n",
      " - loss of 0.4071253803863075\n",
      " - accuracy of 0.782608695652174\n",
      "Epoch # 358:\n",
      " - loss of 0.4069096427004938\n",
      " - accuracy of 0.7832125603864735\n",
      "Epoch # 359:\n",
      " - loss of 0.40681765811206644\n",
      " - accuracy of 0.7823067632850241\n",
      "Epoch # 360:\n",
      " - loss of 0.40674845428717915\n",
      " - accuracy of 0.7835144927536232\n",
      "Epoch # 361:\n",
      " - loss of 0.40656221239460005\n",
      " - accuracy of 0.7862318840579711\n",
      "Epoch # 362:\n",
      " - loss of 0.40658969648597315\n",
      " - accuracy of 0.7823067632850241\n",
      "Epoch # 363:\n",
      " - loss of 0.40649514271005016\n",
      " - accuracy of 0.782608695652174\n",
      "Epoch # 364:\n",
      " - loss of 0.40638154000945875\n",
      " - accuracy of 0.7829106280193237\n",
      "Epoch # 365:\n",
      " - loss of 0.40632895714903283\n",
      " - accuracy of 0.783816425120773\n",
      "Epoch # 366:\n",
      " - loss of 0.40600480080625045\n",
      " - accuracy of 0.7804951690821256\n",
      "Epoch # 367:\n",
      " - loss of 0.4061128760058857\n",
      " - accuracy of 0.7817028985507246\n",
      "Epoch # 368:\n",
      " - loss of 0.4059938074294793\n",
      " - accuracy of 0.7835144927536232\n",
      "Epoch # 369:\n",
      " - loss of 0.40593169574551374\n",
      " - accuracy of 0.779891304347826\n",
      "Epoch # 370:\n",
      " - loss of 0.40594756020544226\n",
      " - accuracy of 0.7829106280193237\n",
      "Epoch # 371:\n",
      " - loss of 0.4057446036659199\n",
      " - accuracy of 0.782608695652174\n",
      "Epoch # 372:\n",
      " - loss of 0.40572023155397713\n",
      " - accuracy of 0.782608695652174\n",
      "Epoch # 373:\n",
      " - loss of 0.40564335902507886\n",
      " - accuracy of 0.778683574879227\n",
      "Epoch # 374:\n",
      " - loss of 0.4055011913306632\n",
      " - accuracy of 0.7817028985507246\n",
      "Epoch # 375:\n",
      " - loss of 0.40539343571222725\n",
      " - accuracy of 0.7829106280193237\n",
      "Epoch # 376:\n",
      " - loss of 0.40532464514200106\n",
      " - accuracy of 0.7789855072463768\n",
      "Epoch # 377:\n",
      " - loss of 0.4052329638806007\n",
      " - accuracy of 0.7807971014492754\n",
      "Epoch # 378:\n",
      " - loss of 0.4051658257697743\n",
      " - accuracy of 0.7783816425120773\n",
      "Epoch # 379:\n",
      " - loss of 0.4051011824849587\n",
      " - accuracy of 0.7780797101449275\n",
      "Epoch # 380:\n",
      " - loss of 0.4050600873554446\n",
      " - accuracy of 0.7783816425120773\n",
      "Epoch # 381:\n",
      " - loss of 0.40489069530266825\n",
      " - accuracy of 0.7817028985507246\n",
      "Epoch # 382:\n",
      " - loss of 0.4048775933484477\n",
      " - accuracy of 0.7823067632850241\n",
      "Epoch # 383:\n",
      " - loss of 0.40469996787192747\n",
      " - accuracy of 0.7810990338164251\n",
      "Epoch # 384:\n",
      " - loss of 0.40467064260317975\n",
      " - accuracy of 0.7814009661835749\n",
      "Epoch # 385:\n",
      " - loss of 0.4045408294597059\n",
      " - accuracy of 0.7807971014492754\n",
      "Epoch # 386:\n",
      " - loss of 0.4044134704707321\n",
      " - accuracy of 0.7829106280193237\n",
      "Epoch # 387:\n",
      " - loss of 0.4043530797806837\n",
      " - accuracy of 0.7789855072463768\n",
      "Epoch # 388:\n",
      " - loss of 0.40430357824947877\n",
      " - accuracy of 0.7771739130434783\n",
      "Epoch # 389:\n",
      " - loss of 0.4042050602054336\n",
      " - accuracy of 0.7804951690821256\n",
      "Epoch # 390:\n",
      " - loss of 0.4041498344003721\n",
      " - accuracy of 0.779891304347826\n",
      "Epoch # 391:\n",
      " - loss of 0.40404520774616454\n",
      " - accuracy of 0.7807971014492754\n",
      "Epoch # 392:\n",
      " - loss of 0.4039494264104176\n",
      " - accuracy of 0.779891304347826\n",
      "Epoch # 393:\n",
      " - loss of 0.40397456326222014\n",
      " - accuracy of 0.7801932367149759\n",
      "Epoch # 394:\n",
      " - loss of 0.4038820268617848\n",
      " - accuracy of 0.7765700483091788\n",
      "Epoch # 395:\n",
      " - loss of 0.4037909355402426\n",
      " - accuracy of 0.778683574879227\n",
      "Epoch # 396:\n",
      " - loss of 0.4035042104904357\n",
      " - accuracy of 0.7756642512077294\n",
      "Epoch # 397:\n",
      " - loss of 0.4034217776455544\n",
      " - accuracy of 0.7762681159420289\n",
      "Epoch # 398:\n",
      " - loss of 0.40352269861008294\n",
      " - accuracy of 0.7771739130434783\n",
      "Epoch # 399:\n",
      " - loss of 0.40336947486742647\n",
      " - accuracy of 0.7756642512077294\n",
      "Epoch # 400:\n",
      " - loss of 0.4033007145234661\n",
      " - accuracy of 0.7801932367149759\n",
      "Epoch # 401:\n",
      " - loss of 0.40311785684515145\n",
      " - accuracy of 0.7759661835748792\n",
      "Epoch # 402:\n",
      " - loss of 0.40306323897499435\n",
      " - accuracy of 0.777475845410628\n",
      "Epoch # 403:\n",
      " - loss of 0.4029360089279693\n",
      " - accuracy of 0.7759661835748792\n",
      "Epoch # 404:\n",
      " - loss of 0.40294399996430186\n",
      " - accuracy of 0.777475845410628\n",
      "Epoch # 405:\n",
      " - loss of 0.40287143128222763\n",
      " - accuracy of 0.7789855072463768\n",
      "Epoch # 406:\n",
      " - loss of 0.40264215502554224\n",
      " - accuracy of 0.7795893719806763\n",
      "Epoch # 407:\n",
      " - loss of 0.40263501736031027\n",
      " - accuracy of 0.7792874396135265\n",
      "Epoch # 408:\n",
      " - loss of 0.4026678677458884\n",
      " - accuracy of 0.7756642512077294\n",
      "Epoch # 409:\n",
      " - loss of 0.40251641440911096\n",
      " - accuracy of 0.778683574879227\n",
      "Epoch # 410:\n",
      " - loss of 0.402401238571645\n",
      " - accuracy of 0.7801932367149759\n",
      "Epoch # 411:\n",
      " - loss of 0.402444971269831\n",
      " - accuracy of 0.777475845410628\n",
      "Epoch # 412:\n",
      " - loss of 0.4023278581641488\n",
      " - accuracy of 0.7783816425120773\n",
      "Epoch # 413:\n",
      " - loss of 0.40220899234095153\n",
      " - accuracy of 0.7765700483091788\n",
      "Epoch # 414:\n",
      " - loss of 0.40212875166253953\n",
      " - accuracy of 0.777475845410628\n",
      "Epoch # 415:\n",
      " - loss of 0.40191592239114043\n",
      " - accuracy of 0.7756642512077294\n",
      "Epoch # 416:\n",
      " - loss of 0.40197405469836106\n",
      " - accuracy of 0.777475845410628\n",
      "Epoch # 417:\n",
      " - loss of 0.40182566411847354\n",
      " - accuracy of 0.7771739130434783\n",
      "Epoch # 418:\n",
      " - loss of 0.40172810203984344\n",
      " - accuracy of 0.7783816425120773\n",
      "Epoch # 419:\n",
      " - loss of 0.40166093076220727\n",
      " - accuracy of 0.7747584541062802\n",
      "Epoch # 420:\n",
      " - loss of 0.40171976537233983\n",
      " - accuracy of 0.777475845410628\n",
      "Epoch # 421:\n",
      " - loss of 0.4015389267923468\n",
      " - accuracy of 0.777475845410628\n",
      "Epoch # 422:\n",
      " - loss of 0.40156779053100083\n",
      " - accuracy of 0.7777777777777778\n",
      "Epoch # 423:\n",
      " - loss of 0.4013265847943308\n",
      " - accuracy of 0.7735507246376812\n",
      "Epoch # 424:\n",
      " - loss of 0.4012757194190135\n",
      " - accuracy of 0.7804951690821256\n",
      "Epoch # 425:\n",
      " - loss of 0.40124769656767856\n",
      " - accuracy of 0.7783816425120773\n",
      "Epoch # 426:\n",
      " - loss of 0.4011671963366556\n",
      " - accuracy of 0.7783816425120773\n",
      "Epoch # 427:\n",
      " - loss of 0.4010007779314645\n",
      " - accuracy of 0.7744565217391305\n",
      "Epoch # 428:\n",
      " - loss of 0.40109960052024657\n",
      " - accuracy of 0.7801932367149759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 429:\n",
      " - loss of 0.40098126804496703\n",
      " - accuracy of 0.7756642512077294\n",
      "Epoch # 430:\n",
      " - loss of 0.40081194072925724\n",
      " - accuracy of 0.779891304347826\n",
      "Epoch # 431:\n",
      " - loss of 0.40070543972184525\n",
      " - accuracy of 0.7756642512077294\n",
      "Epoch # 432:\n",
      " - loss of 0.40061917698087474\n",
      " - accuracy of 0.777475845410628\n",
      "Epoch # 433:\n",
      " - loss of 0.4005830048721004\n",
      " - accuracy of 0.777475845410628\n",
      "Epoch # 434:\n",
      " - loss of 0.40054120255079456\n",
      " - accuracy of 0.7747584541062802\n",
      "Epoch # 435:\n",
      " - loss of 0.4003960821263438\n",
      " - accuracy of 0.7771739130434783\n",
      "Epoch # 436:\n",
      " - loss of 0.40034654958412663\n",
      " - accuracy of 0.7768719806763285\n",
      "Epoch # 437:\n",
      " - loss of 0.4002171857846274\n",
      " - accuracy of 0.7762681159420289\n",
      "Epoch # 438:\n",
      " - loss of 0.40016849570824214\n",
      " - accuracy of 0.7753623188405797\n",
      "Epoch # 439:\n",
      " - loss of 0.4001307138410954\n",
      " - accuracy of 0.7762681159420289\n",
      "Epoch # 440:\n",
      " - loss of 0.40010201387089334\n",
      " - accuracy of 0.7768719806763285\n",
      "Epoch # 441:\n",
      " - loss of 0.39989795368931486\n",
      " - accuracy of 0.7723429951690821\n",
      "Epoch # 442:\n",
      " - loss of 0.39992766411519515\n",
      " - accuracy of 0.7768719806763285\n",
      "Epoch # 443:\n",
      " - loss of 0.39981236918570057\n",
      " - accuracy of 0.7756642512077294\n",
      "Epoch # 444:\n",
      " - loss of 0.3997962724318227\n",
      " - accuracy of 0.7759661835748792\n",
      "Epoch # 445:\n",
      " - loss of 0.3996955007134281\n",
      " - accuracy of 0.7768719806763285\n",
      "Epoch # 446:\n",
      " - loss of 0.3995816880616091\n",
      " - accuracy of 0.7759661835748792\n",
      "Epoch # 447:\n",
      " - loss of 0.39945094677964654\n",
      " - accuracy of 0.7795893719806763\n",
      "Epoch # 448:\n",
      " - loss of 0.3994433272079752\n",
      " - accuracy of 0.7750603864734299\n",
      "Epoch # 449:\n",
      " - loss of 0.39940740104052114\n",
      " - accuracy of 0.7780797101449275\n",
      "Epoch # 450:\n",
      " - loss of 0.39922846753610247\n",
      " - accuracy of 0.7780797101449275\n",
      "Epoch # 451:\n",
      " - loss of 0.3991546612278024\n",
      " - accuracy of 0.7735507246376812\n",
      "Epoch # 452:\n",
      " - loss of 0.3990716441888498\n",
      " - accuracy of 0.7777777777777778\n",
      "Epoch # 453:\n",
      " - loss of 0.39913116039180585\n",
      " - accuracy of 0.7750603864734299\n",
      "Epoch # 454:\n",
      " - loss of 0.39904846569419483\n",
      " - accuracy of 0.7765700483091788\n",
      "Epoch # 455:\n",
      " - loss of 0.3988758611332706\n",
      " - accuracy of 0.7762681159420289\n",
      "Epoch # 456:\n",
      " - loss of 0.3987280211567013\n",
      " - accuracy of 0.777475845410628\n",
      "Epoch # 457:\n",
      " - loss of 0.3987105733672152\n",
      " - accuracy of 0.7750603864734299\n",
      "Epoch # 458:\n",
      " - loss of 0.39861960979697203\n",
      " - accuracy of 0.7747584541062802\n",
      "Epoch # 459:\n",
      " - loss of 0.39871266854083565\n",
      " - accuracy of 0.7741545893719807\n",
      "Epoch # 460:\n",
      " - loss of 0.39846862817395107\n",
      " - accuracy of 0.7729468599033816\n",
      "Epoch # 461:\n",
      " - loss of 0.3984872742982234\n",
      " - accuracy of 0.7747584541062802\n",
      "Epoch # 462:\n",
      " - loss of 0.3983600250023618\n",
      " - accuracy of 0.7756642512077294\n",
      "Epoch # 463:\n",
      " - loss of 0.39835182626982\n",
      " - accuracy of 0.773852657004831\n",
      "Epoch # 464:\n",
      " - loss of 0.3981516830370588\n",
      " - accuracy of 0.7762681159420289\n",
      "Epoch # 465:\n",
      " - loss of 0.3981718601744631\n",
      " - accuracy of 0.7723429951690821\n",
      "Epoch # 466:\n",
      " - loss of 0.39797730358727906\n",
      " - accuracy of 0.7780797101449275\n",
      "Epoch # 467:\n",
      " - loss of 0.3978485030282208\n",
      " - accuracy of 0.7702294685990339\n",
      "Epoch # 468:\n",
      " - loss of 0.39797343427346926\n",
      " - accuracy of 0.7723429951690821\n",
      "Epoch # 469:\n",
      " - loss of 0.39788403570399444\n",
      " - accuracy of 0.7744565217391305\n",
      "Epoch # 470:\n",
      " - loss of 0.3977323453016489\n",
      " - accuracy of 0.7768719806763285\n",
      "Epoch # 471:\n",
      " - loss of 0.397710026492146\n",
      " - accuracy of 0.773852657004831\n",
      "Epoch # 472:\n",
      " - loss of 0.3976416895143489\n",
      " - accuracy of 0.773852657004831\n",
      "Epoch # 473:\n",
      " - loss of 0.39750630192043707\n",
      " - accuracy of 0.7741545893719807\n",
      "Epoch # 474:\n",
      " - loss of 0.3976152032595714\n",
      " - accuracy of 0.773852657004831\n",
      "Epoch # 475:\n",
      " - loss of 0.39742883732294343\n",
      " - accuracy of 0.7735507246376812\n",
      "Epoch # 476:\n",
      " - loss of 0.3973448206794608\n",
      " - accuracy of 0.7747584541062802\n",
      "Epoch # 477:\n",
      " - loss of 0.3973205391200345\n",
      " - accuracy of 0.7747584541062802\n",
      "Epoch # 478:\n",
      " - loss of 0.3970669979910585\n",
      " - accuracy of 0.7765700483091788\n",
      "Epoch # 479:\n",
      " - loss of 0.397088994856103\n",
      " - accuracy of 0.7741545893719807\n",
      "Epoch # 480:\n",
      " - loss of 0.3971632181533745\n",
      " - accuracy of 0.7723429951690821\n",
      "Epoch # 481:\n",
      " - loss of 0.3970025161024156\n",
      " - accuracy of 0.7762681159420289\n",
      "Epoch # 482:\n",
      " - loss of 0.39699455255024657\n",
      " - accuracy of 0.7756642512077294\n",
      "Epoch # 483:\n",
      " - loss of 0.39680558827324586\n",
      " - accuracy of 0.7729468599033816\n",
      "Epoch # 484:\n",
      " - loss of 0.39681372431627776\n",
      " - accuracy of 0.7756642512077294\n",
      "Epoch # 485:\n",
      " - loss of 0.3966937103099021\n",
      " - accuracy of 0.7702294685990339\n",
      "Epoch # 486:\n",
      " - loss of 0.3966867167132819\n",
      " - accuracy of 0.7744565217391305\n",
      "Epoch # 487:\n",
      " - loss of 0.396656509849624\n",
      " - accuracy of 0.7726449275362319\n",
      "Epoch # 488:\n",
      " - loss of 0.3964094226733391\n",
      " - accuracy of 0.7693236714975845\n",
      "Epoch # 489:\n",
      " - loss of 0.3962655049854705\n",
      " - accuracy of 0.7717391304347826\n",
      "Epoch # 490:\n",
      " - loss of 0.3964284411191796\n",
      " - accuracy of 0.7732487922705314\n",
      "Epoch # 491:\n",
      " - loss of 0.39634611262752706\n",
      " - accuracy of 0.7753623188405797\n",
      "Epoch # 492:\n",
      " - loss of 0.3962002011065622\n",
      " - accuracy of 0.7693236714975845\n",
      "Epoch # 493:\n",
      " - loss of 0.39621872937455593\n",
      " - accuracy of 0.7690217391304348\n",
      "Epoch # 494:\n",
      " - loss of 0.3961782512000196\n",
      " - accuracy of 0.7720410628019324\n",
      "Epoch # 495:\n",
      " - loss of 0.39604700915064417\n",
      " - accuracy of 0.7744565217391305\n",
      "Epoch # 496:\n",
      " - loss of 0.39608007592778227\n",
      " - accuracy of 0.773852657004831\n",
      "Epoch # 497:\n",
      " - loss of 0.395942951942688\n",
      " - accuracy of 0.7753623188405797\n",
      "Epoch # 498:\n",
      " - loss of 0.39583848157929163\n",
      " - accuracy of 0.7729468599033816\n",
      "Epoch # 499:\n",
      " - loss of 0.395780140493453\n",
      " - accuracy of 0.7729468599033816\n",
      "Epoch # 500:\n",
      " - loss of 0.3958088306317751\n",
      " - accuracy of 0.7732487922705314\n"
     ]
    }
   ],
   "source": [
    "loss_vector = Float64[]\n",
    "accuracy_vector = Float64[]\n",
    "for epoch in 1:500\n",
    "    # Train the model\n",
    "    epoch_loss = Float64[]\n",
    "    for (x, y) in train_loader\n",
    "        (loss, y_pred, st), back = pullback(p -> compute_loss(x, y, model, p, st), ps)\n",
    "        gs = back((one(loss), nothing, nothing))[1]\n",
    "        opt_state, ps = Optimisers.update(opt_state, ps, gs)\n",
    "        push!(epoch_loss, loss)\n",
    "    end\n",
    "    avg_loss = mean(epoch_loss)\n",
    "    println(\"Epoch # $epoch:\\n - loss of $avg_loss\")\n",
    "    push!(loss_vector, avg_loss)\n",
    "\n",
    "    # Validate the model\n",
    "    epoch_accuracy = Float64[]\n",
    "    st_ = Lux.testmode(st)\n",
    "    for (x, y) in val_loader\n",
    "        (loss, y_pred, st_) = compute_loss(x, y, model, ps, st_)\n",
    "        acc = accuracy(y_pred, y)\n",
    "        push!(epoch_accuracy, acc)\n",
    "    end\n",
    "    avg_accuracy = mean(epoch_accuracy)\n",
    "    println(\" - accuracy of $avg_accuracy\")\n",
    "    push!(accuracy_vector, avg_accuracy)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "plot(loss_vector, label=\"loss\", legend=:bottom, color=:red, rightmargin = 1.5Plots.cm, bottommargin = 0.5Plots.cm, box = :on, fmt = :png)\n",
    "plot!(twinx(), accuracy_vector, label=\"accuracy\", legend=:bottomleft, xlabel=\"epoch\", rightmargin = 1.5Plots.cm, bottommargin = 0.5Plots.cm, box = :on)\n",
    "using Dates\n",
    "timestamp = now()\n",
    "savefig(\"result-$timestamp.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JuliaLuxMLUtils 1.7.3",
   "language": "julia",
   "name": "julialuxmlutils-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
