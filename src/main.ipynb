{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `XTBTSScreener.jl` - Screening Likely Transition States with Julia and Machine Learning\n",
    "This Jupyter notebook demonstrates the use of machine learning to predict if a partially-optimized initialization of a transition state, used in the study of chemical kinetics to predict rate constants, is _like to converge\"_ and produze a valid transition state or not after further simulation with expensive Density Functional Theory simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "The input data is saved in a CSV file, load it using `CSV.jl` and then partition the data into training and testing sets using `MLUtils.jl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLUtils, CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_dataloaders (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_dataloaders()\n",
    "    csv_reader = CSV.File(\"data/co2_data.csv\")\n",
    "    n_samples = 313\n",
    "    x_data = Array{Float32}(undef, 55, 6, n_samples)\n",
    "    labels = Float32[]\n",
    "    iter = 1\n",
    "    for row in csv_reader[1:n_samples]\n",
    "        # get if it converged or not\n",
    "        if parse(Bool, \"$(row.converged)\")\n",
    "            push!(labels, 1.0f0)\n",
    "        else\n",
    "            push!(labels, 0.0f0)\n",
    "        end\n",
    "\n",
    "        # get the final coordinates of the atoms\n",
    "        split_array = split(\"$(row.std_xyz)\")\n",
    "        n_atoms = Int(length(split_array)/6)\n",
    "        m = Array{Float32}(undef, 55, 6)\n",
    "        row_counter = 1\n",
    "        column_counter = 1\n",
    "        for value in split_array\n",
    "            temp = String(value)\n",
    "            temp = replace(temp,\"]\"=>\"\")\n",
    "            temp = replace(temp,\"[\"=>\"\")\n",
    "            temp = replace(temp,\",\"=>\"\")\n",
    "            m[row_counter, column_counter] = parse(Float32, temp)\n",
    "            column_counter += 1\n",
    "            if column_counter > 6\n",
    "                column_counter = 1\n",
    "                row_counter += 1\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # zero-padding\n",
    "        for i in n_atoms+1:55\n",
    "            m[i, 1:6] = [0,0,0,0,0,0]\n",
    "        end\n",
    "        x_data[1:55, 1:6, iter] = m\n",
    "        iter += 1\n",
    "    end\n",
    "    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)\n",
    "    return (DataLoader(collect.((x_train, y_train)); batchsize=2^6, shuffle=true),\n",
    "            DataLoader(collect.((x_val, y_val)); batchsize=2^6, shuffle=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_tutorial_dataloaders (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_tutorial_dataloaders()\n",
    "    dataset_size=1000\n",
    "    sequence_length=50\n",
    "    data = [MLUtils.Datasets.make_spiral(sequence_length) for _ in 1:dataset_size]\n",
    "    # Get the labels\n",
    "    labels = vcat(repeat([0.0f0], dataset_size ÷ 2), repeat([1.0f0], dataset_size ÷ 2))\n",
    "    clockwise_spirals = [reshape(d[1][:, 1:sequence_length], :, sequence_length, 1)\n",
    "                         for d in data[1:(dataset_size ÷ 2)]]\n",
    "    anticlockwise_spirals = [reshape(d[1][:, (sequence_length + 1):end], :, sequence_length,\n",
    "                                     1) for d in data[((dataset_size ÷ 2) + 1):end]]\n",
    "    x_data = Float32.(cat(clockwise_spirals..., anticlockwise_spirals...; dims=3))\n",
    "    # Split the dataset\n",
    "    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)\n",
    "    return (DataLoader(collect.((x_train, y_train)); batchsize=128, shuffle=true),\n",
    "            DataLoader(collect.((x_val, y_val)); batchsize=128, shuffle=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Neural Network\n",
    "Following from the tutorial in the [Lux documentation](https://lux.csail.mit.edu/stable/examples/generated/beginner/SimpleRNN/main/) we write a series of functions that will create our NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Lux, Random, Optimisers, Zygote, NNlib, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeding\n",
    "rng = Random.default_rng()\n",
    "Random.seed!(rng, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct StateClassifier{L, C} <:\n",
    "       Lux.AbstractExplicitContainerLayer{(:lstm_cell, :classifier)}\n",
    "    lstm_cell::L\n",
    "    classifier::C\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateClassifier"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function StateClassifier(in_dims, hidden_dims, out_dims)\n",
    "    return StateClassifier(LSTMCell(in_dims => hidden_dims),\n",
    "                            Dense(hidden_dims => out_dims, sigmoid))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (s::StateClassifier)(x::AbstractArray{T, 3}, ps::NamedTuple,\n",
    "                               st::NamedTuple) where {T}\n",
    "    x_init, x_rest = Iterators.peel(eachslice(x; dims=2))\n",
    "    (y, carry), st_lstm = s.lstm_cell(x_init, ps.lstm_cell, st.lstm_cell)\n",
    "    for x in x_rest\n",
    "        (y, carry), st_lstm = s.lstm_cell((x, carry), ps.lstm_cell, st_lstm)\n",
    "    end\n",
    "    y, st_classifier = s.classifier(y, ps.classifier, st.classifier)\n",
    "    st = merge(st, (classifier=st_classifier, lstm_cell=st_lstm))\n",
    "    return vec(y), st\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function xlogy(x, y)\n",
    "    result = x * log(y)\n",
    "    return ifelse(iszero(x), zero(result), result)\n",
    "end\n",
    "\n",
    "function binarycrossentropy(y_pred, y_true)\n",
    "    y_pred = y_pred .+ eps(eltype(y_pred))\n",
    "    return mean(@. -xlogy(y_true, y_pred) - xlogy(1 - y_true, 1 - y_pred))\n",
    "end\n",
    "\n",
    "function compute_loss(x, y, model, ps, st)\n",
    "    y_pred, st = model(x, ps, st)\n",
    "    return binarycrossentropy(y_pred, y), y_pred, st\n",
    "end\n",
    "\n",
    "matches(y_pred, y_true) = sum((y_pred .> 0.5) .== y_true)\n",
    "accuracy(y_pred, y_true) = matches(y_pred, y_true) / length(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_optimiser (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_optimiser(ps)\n",
    "    opt = Optimisers.ADAM(0.01f0)\n",
    "    return Optimisers.setup(opt, ps)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NN\n",
    "Actual training and evaluation steps.\n",
    "\n",
    "Load the data from the file and parition it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataLoader(::Tuple{Array{Float32, 3}, Vector{Float32}}, shuffle=true, batchsize=64), DataLoader(::Tuple{Array{Float32, 3}, Vector{Float32}}, batchsize=64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_loader, val_loader) = get_dataloaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(lstm_cell = (weight_i = \u001b[32mLeaf(Adam{Float32}(0.01, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, weight_h = \u001b[32mLeaf(Adam{Float32}(0.01, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam{Float32}(0.01, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0; 0.0; … ; 0.0; 0.0;;], Float32[0.0; 0.0; … ; 0.0; 0.0;;], (0.9, 0.999))\u001b[32m)\u001b[39m), classifier = (weight = \u001b[32mLeaf(Adam{Float32}(0.01, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam{Float32}(0.01, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0;;], Float32[0.0;;], (0.9, 0.999))\u001b[32m)\u001b[39m))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StateClassifier(55, 6, 1)\n",
    "rng = Random.default_rng()\n",
    "Random.seed!(rng, 0)\n",
    "ps, st = Lux.setup(rng, model)\n",
    "opt_state = create_optimiser(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual model training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]: Loss 0.6524439\n",
      "Epoch [1]: Loss 0.61227083\n",
      "Epoch [1]: Loss 0.5928215\n",
      "Epoch [1]: Loss 0.63041013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Loss 0.58518714 Accuracy 0.746031746031746\n",
      "Epoch [2]: Loss 0.5785568\n",
      "Epoch [2]: Loss 0.54000825\n",
      "Epoch [2]: Loss 0.5151477\n",
      "Epoch [2]: Loss 0.5354495\n",
      "Validation: Loss 0.53631335 Accuracy 0.7777777777777778\n",
      "Epoch [3]: Loss 0.4995964\n",
      "Epoch [3]: Loss 0.4791006\n",
      "Epoch [3]: Loss 0.51736456\n",
      "Epoch [3]: Loss 0.4588107\n",
      "Validation: Loss 0.51076627 Accuracy 0.8253968253968254\n",
      "Epoch [4]: Loss 0.505168\n",
      "Epoch [4]: Loss 0.4478941\n",
      "Epoch [4]: Loss 0.39267457\n",
      "Epoch [4]: Loss 0.46822146\n",
      "Validation: Loss 0.4976453 Accuracy 0.8095238095238095\n",
      "Epoch [5]: Loss 0.46869418\n",
      "Epoch [5]: Loss 0.40886283\n",
      "Epoch [5]: Loss 0.38438013\n",
      "Epoch [5]: Loss 0.41981223\n",
      "Validation: Loss 0.49107847 Accuracy 0.8095238095238095\n",
      "Epoch [6]: Loss 0.4774009\n",
      "Epoch [6]: Loss 0.353578\n",
      "Epoch [6]: Loss 0.45846266\n",
      "Epoch [6]: Loss 0.26619083\n",
      "Validation: Loss 0.49064398 Accuracy 0.8095238095238095\n",
      "Epoch [7]: Loss 0.33987826\n",
      "Epoch [7]: Loss 0.40042466\n",
      "Epoch [7]: Loss 0.3608108\n",
      "Epoch [7]: Loss 0.3529117\n",
      "Validation: Loss 0.49372783 Accuracy 0.7936507936507936\n",
      "Epoch [8]: Loss 0.38067216\n",
      "Epoch [8]: Loss 0.33486366\n",
      "Epoch [8]: Loss 0.287317\n",
      "Epoch [8]: Loss 0.34737024\n",
      "Validation: Loss 0.5022535 Accuracy 0.7777777777777778\n",
      "Epoch [9]: Loss 0.279208\n",
      "Epoch [9]: Loss 0.26160002\n",
      "Epoch [9]: Loss 0.33024824\n",
      "Epoch [9]: Loss 0.37826842\n",
      "Validation: Loss 0.5088402 Accuracy 0.7777777777777778\n",
      "Epoch [10]: Loss 0.25102934\n",
      "Epoch [10]: Loss 0.3361893\n",
      "Epoch [10]: Loss 0.28869295\n",
      "Epoch [10]: Loss 0.26671135\n",
      "Validation: Loss 0.5213975 Accuracy 0.7777777777777778\n",
      "Epoch [11]: Loss 0.28297162\n",
      "Epoch [11]: Loss 0.24939798\n",
      "Epoch [11]: Loss 0.2532794\n",
      "Epoch [11]: Loss 0.26422772\n",
      "Validation: Loss 0.53248256 Accuracy 0.7777777777777778\n",
      "Epoch [12]: Loss 0.2659748\n",
      "Epoch [12]: Loss 0.22303668\n",
      "Epoch [12]: Loss 0.21079458\n",
      "Epoch [12]: Loss 0.2673818\n",
      "Validation: Loss 0.5449471 Accuracy 0.7777777777777778\n",
      "Epoch [13]: Loss 0.25097886\n",
      "Epoch [13]: Loss 0.2458579\n",
      "Epoch [13]: Loss 0.15375029\n",
      "Epoch [13]: Loss 0.2320912\n",
      "Validation: Loss 0.55855197 Accuracy 0.7936507936507936\n",
      "Epoch [14]: Loss 0.18300608\n",
      "Epoch [14]: Loss 0.19667101\n",
      "Epoch [14]: Loss 0.19590437\n",
      "Epoch [14]: Loss 0.23289295\n",
      "Validation: Loss 0.5706096 Accuracy 0.7936507936507936\n",
      "Epoch [15]: Loss 0.21575539\n",
      "Epoch [15]: Loss 0.15177155\n",
      "Epoch [15]: Loss 0.17199588\n",
      "Epoch [15]: Loss 0.19332294\n",
      "Validation: Loss 0.57383764 Accuracy 0.7936507936507936\n",
      "Epoch [16]: Loss 0.13279574\n",
      "Epoch [16]: Loss 0.190846\n",
      "Epoch [16]: Loss 0.18561266\n",
      "Epoch [16]: Loss 0.1620351\n",
      "Validation: Loss 0.5773596 Accuracy 0.7936507936507936\n",
      "Epoch [17]: Loss 0.12578301\n",
      "Epoch [17]: Loss 0.18481734\n",
      "Epoch [17]: Loss 0.16398883\n",
      "Epoch [17]: Loss 0.1334446\n",
      "Validation: Loss 0.5883138 Accuracy 0.7777777777777778\n",
      "Epoch [18]: Loss 0.12611312\n",
      "Epoch [18]: Loss 0.12123223\n",
      "Epoch [18]: Loss 0.1345788\n",
      "Epoch [18]: Loss 0.17223673\n",
      "Validation: Loss 0.5990078 Accuracy 0.7936507936507936\n",
      "Epoch [19]: Loss 0.0816572\n",
      "Epoch [19]: Loss 0.14040093\n",
      "Epoch [19]: Loss 0.14123726\n",
      "Epoch [19]: Loss 0.14115274\n",
      "Validation: Loss 0.6123406 Accuracy 0.7777777777777778\n",
      "Epoch [20]: Loss 0.08508359\n",
      "Epoch [20]: Loss 0.14538863\n",
      "Epoch [20]: Loss 0.13165955\n",
      "Epoch [20]: Loss 0.0905045\n",
      "Validation: Loss 0.61850226 Accuracy 0.7777777777777778\n",
      "Epoch [21]: Loss 0.0964982\n",
      "Epoch [21]: Loss 0.110898145\n",
      "Epoch [21]: Loss 0.12523453\n",
      "Epoch [21]: Loss 0.07832697\n",
      "Validation: Loss 0.6281762 Accuracy 0.7619047619047619\n",
      "Epoch [22]: Loss 0.079134524\n",
      "Epoch [22]: Loss 0.11314056\n",
      "Epoch [22]: Loss 0.09883132\n",
      "Epoch [22]: Loss 0.07835377\n",
      "Validation: Loss 0.6375932 Accuracy 0.7619047619047619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23]: Loss 0.08593038\n",
      "Epoch [23]: Loss 0.09949831\n",
      "Epoch [23]: Loss 0.070257984\n",
      "Epoch [23]: Loss 0.07792865\n",
      "Validation: Loss 0.6534936 Accuracy 0.7619047619047619\n",
      "Epoch [24]: Loss 0.093091264\n",
      "Epoch [24]: Loss 0.066608526\n",
      "Epoch [24]: Loss 0.0808644\n",
      "Epoch [24]: Loss 0.065077774\n",
      "Validation: Loss 0.6633488 Accuracy 0.7619047619047619\n",
      "Epoch [25]: Loss 0.10261936\n",
      "Epoch [25]: Loss 0.05617659\n",
      "Epoch [25]: Loss 0.05867143\n",
      "Epoch [25]: Loss 0.055194292\n",
      "Validation: Loss 0.6653733 Accuracy 0.7619047619047619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNumber of observations less than batch-size, decreasing the batch-size to 63\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLUtils ~/.julia/packages/MLUtils/R44Zf/src/batchview.jl:95\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "loss_vector = Float64[]\n",
    "accuracy_vector = Float64[]\n",
    "for epoch in 1:25\n",
    "    # Train the model\n",
    "    epoch_loss = Float64[]\n",
    "    for (x, y) in train_loader\n",
    "        (loss, y_pred, st), back = pullback(p -> compute_loss(x, y, model, p, st), ps)\n",
    "        gs = back((one(loss), nothing, nothing))[1]\n",
    "        opt_state, ps = Optimisers.update(opt_state, ps, gs)\n",
    "\n",
    "        println(\"Epoch [$epoch]: Loss $loss\")\n",
    "        push!(epoch_loss, loss)\n",
    "    end\n",
    "    push!(loss_vector, mean(epoch_loss))\n",
    "\n",
    "    # Validate the model\n",
    "    st_ = Lux.testmode(st)\n",
    "    for (x, y) in val_loader\n",
    "        (loss, y_pred, st_) = compute_loss(x, y, model, ps, st_)\n",
    "        acc = accuracy(y_pred, y)\n",
    "        println(\"Validation: Loss $loss Accuracy $acc\")\n",
    "        push!(accuracy_vector, acc)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip580\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip580)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip581\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip580)\" d=\"\n",
       "M156.598 1423.46 L2132.28 1423.46 L2132.28 47.2441 L156.598 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip582\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"1977\" height=\"1377\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  523.156,1423.46 523.156,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  911.459,1423.46 911.459,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1299.76,1423.46 1299.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1688.06,1423.46 1688.06,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2076.37,1423.46 2076.37,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1423.46 2132.28,1423.46 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,47.2441 2132.28,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  523.156,1423.46 523.156,1404.56 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  911.459,1423.46 911.459,1404.56 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1299.76,1423.46 1299.76,1404.56 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1688.06,1423.46 1688.06,1404.56 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2076.37,1423.46 2076.37,1404.56 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"M513.434 1451.3 L531.79 1451.3 L531.79 1455.23 L517.716 1455.23 L517.716 1463.7 Q518.735 1463.36 519.753 1463.19 Q520.772 1463.01 521.79 1463.01 Q527.577 1463.01 530.957 1466.18 Q534.337 1469.35 534.337 1474.77 Q534.337 1480.35 530.864 1483.45 Q527.392 1486.53 521.073 1486.53 Q518.897 1486.53 516.628 1486.16 Q514.383 1485.79 511.976 1485.05 L511.976 1480.35 Q514.059 1481.48 516.281 1482.04 Q518.503 1482.59 520.98 1482.59 Q524.985 1482.59 527.323 1480.49 Q529.661 1478.38 529.661 1474.77 Q529.661 1471.16 527.323 1469.05 Q524.985 1466.94 520.98 1466.94 Q519.105 1466.94 517.23 1467.36 Q515.378 1467.78 513.434 1468.66 L513.434 1451.3 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M886.147 1481.92 L893.786 1481.92 L893.786 1455.55 L885.475 1457.22 L885.475 1452.96 L893.739 1451.3 L898.415 1451.3 L898.415 1481.92 L906.054 1481.92 L906.054 1485.86 L886.147 1485.86 L886.147 1481.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M925.498 1454.37 Q921.887 1454.37 920.059 1457.94 Q918.253 1461.48 918.253 1468.61 Q918.253 1475.72 920.059 1479.28 Q921.887 1482.82 925.498 1482.82 Q929.133 1482.82 930.938 1479.28 Q932.767 1475.72 932.767 1468.61 Q932.767 1461.48 930.938 1457.94 Q929.133 1454.37 925.498 1454.37 M925.498 1450.67 Q931.309 1450.67 934.364 1455.28 Q937.443 1459.86 937.443 1468.61 Q937.443 1477.34 934.364 1481.94 Q931.309 1486.53 925.498 1486.53 Q919.688 1486.53 916.61 1481.94 Q913.554 1477.34 913.554 1468.61 Q913.554 1459.86 916.61 1455.28 Q919.688 1450.67 925.498 1450.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1274.95 1481.92 L1282.59 1481.92 L1282.59 1455.55 L1274.28 1457.22 L1274.28 1452.96 L1282.54 1451.3 L1287.22 1451.3 L1287.22 1481.92 L1294.85 1481.92 L1294.85 1485.86 L1274.95 1485.86 L1274.95 1481.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1304.35 1451.3 L1322.7 1451.3 L1322.7 1455.23 L1308.63 1455.23 L1308.63 1463.7 Q1309.65 1463.36 1310.66 1463.19 Q1311.68 1463.01 1312.7 1463.01 Q1318.49 1463.01 1321.87 1466.18 Q1325.25 1469.35 1325.25 1474.77 Q1325.25 1480.35 1321.78 1483.45 Q1318.3 1486.53 1311.98 1486.53 Q1309.81 1486.53 1307.54 1486.16 Q1305.29 1485.79 1302.89 1485.05 L1302.89 1480.35 Q1304.97 1481.48 1307.19 1482.04 Q1309.41 1482.59 1311.89 1482.59 Q1315.9 1482.59 1318.23 1480.49 Q1320.57 1478.38 1320.57 1474.77 Q1320.57 1471.16 1318.23 1469.05 Q1315.9 1466.94 1311.89 1466.94 Q1310.02 1466.94 1308.14 1467.36 Q1306.29 1467.78 1304.35 1468.66 L1304.35 1451.3 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1666.84 1481.92 L1683.16 1481.92 L1683.16 1485.86 L1661.21 1485.86 L1661.21 1481.92 Q1663.88 1479.17 1668.46 1474.54 Q1673.07 1469.88 1674.25 1468.54 Q1676.49 1466.02 1677.37 1464.28 Q1678.27 1462.52 1678.27 1460.83 Q1678.27 1458.08 1676.33 1456.34 Q1674.41 1454.61 1671.31 1454.61 Q1669.11 1454.61 1666.65 1455.37 Q1664.22 1456.13 1661.44 1457.68 L1661.44 1452.96 Q1664.27 1451.83 1666.72 1451.25 Q1669.18 1450.67 1671.21 1450.67 Q1676.58 1450.67 1679.78 1453.36 Q1682.97 1456.04 1682.97 1460.53 Q1682.97 1462.66 1682.16 1464.58 Q1681.38 1466.48 1679.27 1469.07 Q1678.69 1469.74 1675.59 1472.96 Q1672.49 1476.16 1666.84 1481.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1702.97 1454.37 Q1699.36 1454.37 1697.53 1457.94 Q1695.73 1461.48 1695.73 1468.61 Q1695.73 1475.72 1697.53 1479.28 Q1699.36 1482.82 1702.97 1482.82 Q1706.61 1482.82 1708.41 1479.28 Q1710.24 1475.72 1710.24 1468.61 Q1710.24 1461.48 1708.41 1457.94 Q1706.61 1454.37 1702.97 1454.37 M1702.97 1450.67 Q1708.78 1450.67 1711.84 1455.28 Q1714.92 1459.86 1714.92 1468.61 Q1714.92 1477.34 1711.84 1481.94 Q1708.78 1486.53 1702.97 1486.53 Q1697.16 1486.53 1694.08 1481.94 Q1691.03 1477.34 1691.03 1468.61 Q1691.03 1459.86 1694.08 1455.28 Q1697.16 1450.67 1702.97 1450.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2055.64 1481.92 L2071.96 1481.92 L2071.96 1485.86 L2050.01 1485.86 L2050.01 1481.92 Q2052.68 1479.17 2057.26 1474.54 Q2061.87 1469.88 2063.05 1468.54 Q2065.29 1466.02 2066.17 1464.28 Q2067.07 1462.52 2067.07 1460.83 Q2067.07 1458.08 2065.13 1456.34 Q2063.21 1454.61 2060.11 1454.61 Q2057.91 1454.61 2055.45 1455.37 Q2053.02 1456.13 2050.25 1457.68 L2050.25 1452.96 Q2053.07 1451.83 2055.52 1451.25 Q2057.98 1450.67 2060.01 1450.67 Q2065.38 1450.67 2068.58 1453.36 Q2071.77 1456.04 2071.77 1460.53 Q2071.77 1462.66 2070.96 1464.58 Q2070.18 1466.48 2068.07 1469.07 Q2067.49 1469.74 2064.39 1472.96 Q2061.29 1476.16 2055.64 1481.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2081.82 1451.3 L2100.18 1451.3 L2100.18 1455.23 L2086.1 1455.23 L2086.1 1463.7 Q2087.12 1463.36 2088.14 1463.19 Q2089.16 1463.01 2090.18 1463.01 Q2095.96 1463.01 2099.34 1466.18 Q2102.72 1469.35 2102.72 1474.77 Q2102.72 1480.35 2099.25 1483.45 Q2095.78 1486.53 2089.46 1486.53 Q2087.28 1486.53 2085.01 1486.16 Q2082.77 1485.79 2080.36 1485.05 L2080.36 1480.35 Q2082.44 1481.48 2084.67 1482.04 Q2086.89 1482.59 2089.37 1482.59 Q2093.37 1482.59 2095.71 1480.49 Q2098.05 1478.38 2098.05 1474.77 Q2098.05 1471.16 2095.71 1469.05 Q2093.37 1466.94 2089.37 1466.94 Q2087.49 1466.94 2085.62 1467.36 Q2083.76 1467.78 2081.82 1468.66 L2081.82 1451.3 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1309.88 2132.28,1309.88 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,1075.45 2132.28,1075.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,841.021 2132.28,841.021 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,606.593 2132.28,606.593 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,372.164 2132.28,372.164 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.598,137.736 2132.28,137.736 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1423.46 156.598,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2132.28,1423.46 2132.28,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1309.88 175.496,1309.88 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,1075.45 175.496,1075.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,841.021 175.496,841.021 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,606.593 175.496,606.593 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,372.164 175.496,372.164 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.598,137.736 175.496,137.736 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"M64.6495 1295.68 Q61.0384 1295.68 59.2097 1299.24 Q57.4041 1302.78 57.4041 1309.91 Q57.4041 1317.02 59.2097 1320.58 Q61.0384 1324.12 64.6495 1324.12 Q68.2837 1324.12 70.0892 1320.58 Q71.9179 1317.02 71.9179 1309.91 Q71.9179 1302.78 70.0892 1299.24 Q68.2837 1295.68 64.6495 1295.68 M64.6495 1291.97 Q70.4596 1291.97 73.5152 1296.58 Q76.5938 1301.16 76.5938 1309.91 Q76.5938 1318.64 73.5152 1323.25 Q70.4596 1327.83 64.6495 1327.83 Q58.8393 1327.83 55.7606 1323.25 Q52.7051 1318.64 52.7051 1309.91 Q52.7051 1301.16 55.7606 1296.58 Q58.8393 1291.97 64.6495 1291.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M84.8114 1321.28 L89.6956 1321.28 L89.6956 1327.16 L84.8114 1327.16 L84.8114 1321.28 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M100.691 1323.22 L108.33 1323.22 L108.33 1296.86 L100.02 1298.52 L100.02 1294.26 L108.283 1292.6 L112.959 1292.6 L112.959 1323.22 L120.598 1323.22 L120.598 1327.16 L100.691 1327.16 L100.691 1323.22 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M65.0198 1061.25 Q61.4087 1061.25 59.58 1064.81 Q57.7745 1068.35 57.7745 1075.48 Q57.7745 1082.59 59.58 1086.15 Q61.4087 1089.7 65.0198 1089.7 Q68.6541 1089.7 70.4596 1086.15 Q72.2883 1082.59 72.2883 1075.48 Q72.2883 1068.35 70.4596 1064.81 Q68.6541 1061.25 65.0198 1061.25 M65.0198 1057.54 Q70.83 1057.54 73.8855 1062.15 Q76.9642 1066.73 76.9642 1075.48 Q76.9642 1084.21 73.8855 1088.82 Q70.83 1093.4 65.0198 1093.4 Q59.2097 1093.4 56.131 1088.82 Q53.0754 1084.21 53.0754 1075.48 Q53.0754 1066.73 56.131 1062.15 Q59.2097 1057.54 65.0198 1057.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M85.1818 1086.85 L90.066 1086.85 L90.066 1092.73 L85.1818 1092.73 L85.1818 1086.85 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M104.279 1088.79 L120.598 1088.79 L120.598 1092.73 L98.6539 1092.73 L98.6539 1088.79 Q101.316 1086.04 105.899 1081.41 Q110.506 1076.76 111.686 1075.41 Q113.932 1072.89 114.811 1071.15 Q115.714 1069.4 115.714 1067.71 Q115.714 1064.95 113.77 1063.22 Q111.848 1061.48 108.746 1061.48 Q106.547 1061.48 104.094 1062.24 Q101.663 1063.01 98.8854 1064.56 L98.8854 1059.84 Q101.709 1058.7 104.163 1058.12 Q106.617 1057.54 108.654 1057.54 Q114.024 1057.54 117.219 1060.23 Q120.413 1062.91 120.413 1067.41 Q120.413 1069.53 119.603 1071.46 Q118.816 1073.35 116.709 1075.95 Q116.131 1076.62 113.029 1079.84 Q109.927 1083.03 104.279 1088.79 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M64.0708 826.819 Q60.4597 826.819 58.631 830.384 Q56.8254 833.926 56.8254 841.055 Q56.8254 848.162 58.631 851.727 Q60.4597 855.268 64.0708 855.268 Q67.705 855.268 69.5105 851.727 Q71.3392 848.162 71.3392 841.055 Q71.3392 833.926 69.5105 830.384 Q67.705 826.819 64.0708 826.819 M64.0708 823.116 Q69.8809 823.116 72.9365 827.722 Q76.0151 832.306 76.0151 841.055 Q76.0151 849.782 72.9365 854.389 Q69.8809 858.972 64.0708 858.972 Q58.2606 858.972 55.1819 854.389 Q52.1264 849.782 52.1264 841.055 Q52.1264 832.306 55.1819 827.722 Q58.2606 823.116 64.0708 823.116 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M84.2327 852.421 L89.1169 852.421 L89.1169 858.301 L84.2327 858.301 L84.2327 852.421 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M113.469 839.667 Q116.825 840.384 118.7 842.653 Q120.598 844.921 120.598 848.255 Q120.598 853.37 117.08 856.171 Q113.561 858.972 107.08 858.972 Q104.904 858.972 102.589 858.532 Q100.297 858.116 97.8437 857.259 L97.8437 852.745 Q99.7882 853.879 102.103 854.458 Q104.418 855.037 106.941 855.037 Q111.339 855.037 113.631 853.301 Q115.945 851.565 115.945 848.255 Q115.945 845.199 113.793 843.486 Q111.663 841.75 107.844 841.75 L103.816 841.75 L103.816 837.907 L108.029 837.907 Q111.478 837.907 113.307 836.542 Q115.135 835.153 115.135 832.56 Q115.135 829.898 113.237 828.486 Q111.362 827.051 107.844 827.051 Q105.922 827.051 103.723 827.468 Q101.524 827.884 98.8854 828.764 L98.8854 824.597 Q101.547 823.857 103.862 823.486 Q106.2 823.116 108.26 823.116 Q113.584 823.116 116.686 825.546 Q119.788 827.954 119.788 832.074 Q119.788 834.944 118.145 836.935 Q116.501 838.903 113.469 839.667 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M62.9365 592.391 Q59.3254 592.391 57.4967 595.956 Q55.6912 599.498 55.6912 606.627 Q55.6912 613.734 57.4967 617.299 Q59.3254 620.84 62.9365 620.84 Q66.5707 620.84 68.3763 617.299 Q70.205 613.734 70.205 606.627 Q70.205 599.498 68.3763 595.956 Q66.5707 592.391 62.9365 592.391 M62.9365 588.688 Q68.7467 588.688 71.8022 593.294 Q74.8809 597.877 74.8809 606.627 Q74.8809 615.354 71.8022 619.961 Q68.7467 624.544 62.9365 624.544 Q57.1264 624.544 54.0477 619.961 Q50.9921 615.354 50.9921 606.627 Q50.9921 597.877 54.0477 593.294 Q57.1264 588.688 62.9365 588.688 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M83.0984 617.993 L87.9827 617.993 L87.9827 623.873 L83.0984 623.873 L83.0984 617.993 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M111.015 593.387 L99.2095 611.836 L111.015 611.836 L111.015 593.387 M109.788 589.313 L115.668 589.313 L115.668 611.836 L120.598 611.836 L120.598 615.724 L115.668 615.724 L115.668 623.873 L111.015 623.873 L111.015 615.724 L95.4132 615.724 L95.4132 611.211 L109.788 589.313 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M64.418 357.963 Q60.8069 357.963 58.9782 361.528 Q57.1726 365.07 57.1726 372.199 Q57.1726 379.306 58.9782 382.87 Q60.8069 386.412 64.418 386.412 Q68.0522 386.412 69.8578 382.87 Q71.6865 379.306 71.6865 372.199 Q71.6865 365.07 69.8578 361.528 Q68.0522 357.963 64.418 357.963 M64.418 354.259 Q70.2281 354.259 73.2837 358.866 Q76.3624 363.449 76.3624 372.199 Q76.3624 380.926 73.2837 385.532 Q70.2281 390.116 64.418 390.116 Q58.6078 390.116 55.5291 385.532 Q52.4736 380.926 52.4736 372.199 Q52.4736 363.449 55.5291 358.866 Q58.6078 354.259 64.418 354.259 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M84.5799 383.565 L89.4641 383.565 L89.4641 389.444 L84.5799 389.444 L84.5799 383.565 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M99.6956 354.884 L118.052 354.884 L118.052 358.82 L103.978 358.82 L103.978 367.292 Q104.996 366.945 106.015 366.782 Q107.033 366.597 108.052 366.597 Q113.839 366.597 117.219 369.769 Q120.598 372.94 120.598 378.357 Q120.598 383.935 117.126 387.037 Q113.654 390.116 107.334 390.116 Q105.159 390.116 102.89 389.745 Q100.645 389.375 98.2372 388.634 L98.2372 383.935 Q100.321 385.069 102.543 385.625 Q104.765 386.181 107.242 386.181 Q111.246 386.181 113.584 384.074 Q115.922 381.968 115.922 378.357 Q115.922 374.745 113.584 372.639 Q111.246 370.532 107.242 370.532 Q105.367 370.532 103.492 370.949 Q101.64 371.366 99.6956 372.245 L99.6956 354.884 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M63.2606 123.535 Q59.6495 123.535 57.8208 127.1 Q56.0152 130.641 56.0152 137.771 Q56.0152 144.877 57.8208 148.442 Q59.6495 151.984 63.2606 151.984 Q66.8948 151.984 68.7004 148.442 Q70.5291 144.877 70.5291 137.771 Q70.5291 130.641 68.7004 127.1 Q66.8948 123.535 63.2606 123.535 M63.2606 119.831 Q69.0707 119.831 72.1263 124.438 Q75.205 129.021 75.205 137.771 Q75.205 146.498 72.1263 151.104 Q69.0707 155.688 63.2606 155.688 Q57.4504 155.688 54.3717 151.104 Q51.3162 146.498 51.3162 137.771 Q51.3162 129.021 54.3717 124.438 Q57.4504 119.831 63.2606 119.831 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M83.4225 149.137 L88.3067 149.137 L88.3067 155.016 L83.4225 155.016 L83.4225 149.137 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M109.071 135.873 Q105.922 135.873 104.071 138.026 Q102.242 140.178 102.242 143.928 Q102.242 147.655 104.071 149.831 Q105.922 151.984 109.071 151.984 Q112.219 151.984 114.047 149.831 Q115.899 147.655 115.899 143.928 Q115.899 140.178 114.047 138.026 Q112.219 135.873 109.071 135.873 M118.353 121.22 L118.353 125.479 Q116.594 124.646 114.788 124.206 Q113.006 123.766 111.246 123.766 Q106.617 123.766 104.163 126.891 Q101.733 130.016 101.385 136.336 Q102.751 134.322 104.811 133.257 Q106.871 132.169 109.348 132.169 Q114.557 132.169 117.566 135.34 Q120.598 138.489 120.598 143.928 Q120.598 149.252 117.45 152.47 Q114.302 155.688 109.071 155.688 Q103.075 155.688 99.9039 151.104 Q96.7326 146.498 96.7326 137.771 Q96.7326 129.577 100.621 124.715 Q104.51 119.831 111.061 119.831 Q112.82 119.831 114.603 120.178 Q116.408 120.526 118.353 121.22 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip582)\" style=\"stroke:#ff0000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.514,86.1935 290.174,273.023 367.835,398.612 445.496,481.198 523.156,558.682 600.817,632.595 678.477,692.144 756.138,752.979 833.799,812.113 911.459,874.648 \n",
       "  989.12,929.004 1066.78,977.465 1144.44,1026.99 1222.1,1070.48 1299.76,1114.81 1377.42,1150.88 1455.08,1187.95 1532.74,1219.53 1610.4,1248.66 1688.06,1279.03 \n",
       "  1765.73,1303.46 1843.39,1327.78 1921.05,1348.78 1998.71,1365.18 2076.37,1384.51 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"\n",
       "M222.454 761.27 L526.766 761.27 L526.766 657.59 L222.454 657.59  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  222.454,761.27 526.766,761.27 526.766,657.59 222.454,657.59 222.454,761.27 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#ff0000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  244.406,709.43 376.119,709.43 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"M398.071 690.692 L402.33 690.692 L402.33 726.71 L398.071 726.71 L398.071 690.692 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M421.288 703.77 Q417.862 703.77 415.872 706.455 Q413.881 709.117 413.881 713.77 Q413.881 718.423 415.849 721.108 Q417.839 723.77 421.288 723.77 Q424.691 723.77 426.682 721.085 Q428.673 718.4 428.673 713.77 Q428.673 709.164 426.682 706.479 Q424.691 703.77 421.288 703.77 M421.288 700.159 Q426.844 700.159 430.015 703.77 Q433.186 707.381 433.186 713.77 Q433.186 720.136 430.015 723.77 Q426.844 727.381 421.288 727.381 Q415.71 727.381 412.538 723.77 Q409.39 720.136 409.39 713.77 Q409.39 707.381 412.538 703.77 Q415.71 700.159 421.288 700.159 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M456.774 701.548 L456.774 705.576 Q454.969 704.65 453.024 704.187 Q451.08 703.724 448.997 703.724 Q445.825 703.724 444.228 704.696 Q442.654 705.668 442.654 707.613 Q442.654 709.094 443.788 709.951 Q444.922 710.784 448.348 711.548 L449.807 711.872 Q454.344 712.844 456.242 714.627 Q458.163 716.386 458.163 719.557 Q458.163 723.168 455.293 725.275 Q452.446 727.381 447.446 727.381 Q445.362 727.381 443.094 726.965 Q440.848 726.571 438.348 725.761 L438.348 721.363 Q440.71 722.59 443.001 723.215 Q445.293 723.816 447.538 723.816 Q450.547 723.816 452.168 722.798 Q453.788 721.756 453.788 719.881 Q453.788 718.145 452.608 717.219 Q451.45 716.293 447.492 715.437 L446.01 715.09 Q442.052 714.256 440.293 712.543 Q438.534 710.807 438.534 707.798 Q438.534 704.141 441.126 702.15 Q443.719 700.159 448.487 700.159 Q450.848 700.159 452.932 700.506 Q455.015 700.854 456.774 701.548 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M481.473 701.548 L481.473 705.576 Q479.668 704.65 477.723 704.187 Q475.779 703.724 473.695 703.724 Q470.524 703.724 468.927 704.696 Q467.353 705.668 467.353 707.613 Q467.353 709.094 468.487 709.951 Q469.621 710.784 473.047 711.548 L474.506 711.872 Q479.043 712.844 480.941 714.627 Q482.862 716.386 482.862 719.557 Q482.862 723.168 479.992 725.275 Q477.145 727.381 472.145 727.381 Q470.061 727.381 467.793 726.965 Q465.547 726.571 463.047 725.761 L463.047 721.363 Q465.408 722.59 467.7 723.215 Q469.992 723.816 472.237 723.816 Q475.246 723.816 476.867 722.798 Q478.487 721.756 478.487 719.881 Q478.487 718.145 477.307 717.219 Q476.149 716.293 472.191 715.437 L470.709 715.09 Q466.751 714.256 464.992 712.543 Q463.233 710.807 463.233 707.798 Q463.233 704.141 465.825 702.15 Q468.418 700.159 473.186 700.159 Q475.547 700.159 477.631 700.506 Q479.714 700.854 481.473 701.548 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"\n",
       "M156.598 1423.46 L2132.28 1423.46 L2132.28 47.2441 L156.598 47.2441  Z\n",
       "  \" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"0\"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"M513.434 1451.3 L531.79 1451.3 L531.79 1455.23 L517.716 1455.23 L517.716 1463.7 Q518.735 1463.36 519.753 1463.19 Q520.772 1463.01 521.79 1463.01 Q527.577 1463.01 530.957 1466.18 Q534.337 1469.35 534.337 1474.77 Q534.337 1480.35 530.864 1483.45 Q527.392 1486.53 521.073 1486.53 Q518.897 1486.53 516.628 1486.16 Q514.383 1485.79 511.976 1485.05 L511.976 1480.35 Q514.059 1481.48 516.281 1482.04 Q518.503 1482.59 520.98 1482.59 Q524.985 1482.59 527.323 1480.49 Q529.661 1478.38 529.661 1474.77 Q529.661 1471.16 527.323 1469.05 Q524.985 1466.94 520.98 1466.94 Q519.105 1466.94 517.23 1467.36 Q515.378 1467.78 513.434 1468.66 L513.434 1451.3 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M886.147 1481.92 L893.786 1481.92 L893.786 1455.55 L885.475 1457.22 L885.475 1452.96 L893.739 1451.3 L898.415 1451.3 L898.415 1481.92 L906.054 1481.92 L906.054 1485.86 L886.147 1485.86 L886.147 1481.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M925.498 1454.37 Q921.887 1454.37 920.059 1457.94 Q918.253 1461.48 918.253 1468.61 Q918.253 1475.72 920.059 1479.28 Q921.887 1482.82 925.498 1482.82 Q929.133 1482.82 930.938 1479.28 Q932.767 1475.72 932.767 1468.61 Q932.767 1461.48 930.938 1457.94 Q929.133 1454.37 925.498 1454.37 M925.498 1450.67 Q931.309 1450.67 934.364 1455.28 Q937.443 1459.86 937.443 1468.61 Q937.443 1477.34 934.364 1481.94 Q931.309 1486.53 925.498 1486.53 Q919.688 1486.53 916.61 1481.94 Q913.554 1477.34 913.554 1468.61 Q913.554 1459.86 916.61 1455.28 Q919.688 1450.67 925.498 1450.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1274.95 1481.92 L1282.59 1481.92 L1282.59 1455.55 L1274.28 1457.22 L1274.28 1452.96 L1282.54 1451.3 L1287.22 1451.3 L1287.22 1481.92 L1294.85 1481.92 L1294.85 1485.86 L1274.95 1485.86 L1274.95 1481.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1304.35 1451.3 L1322.7 1451.3 L1322.7 1455.23 L1308.63 1455.23 L1308.63 1463.7 Q1309.65 1463.36 1310.66 1463.19 Q1311.68 1463.01 1312.7 1463.01 Q1318.49 1463.01 1321.87 1466.18 Q1325.25 1469.35 1325.25 1474.77 Q1325.25 1480.35 1321.78 1483.45 Q1318.3 1486.53 1311.98 1486.53 Q1309.81 1486.53 1307.54 1486.16 Q1305.29 1485.79 1302.89 1485.05 L1302.89 1480.35 Q1304.97 1481.48 1307.19 1482.04 Q1309.41 1482.59 1311.89 1482.59 Q1315.9 1482.59 1318.23 1480.49 Q1320.57 1478.38 1320.57 1474.77 Q1320.57 1471.16 1318.23 1469.05 Q1315.9 1466.94 1311.89 1466.94 Q1310.02 1466.94 1308.14 1467.36 Q1306.29 1467.78 1304.35 1468.66 L1304.35 1451.3 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1666.84 1481.92 L1683.16 1481.92 L1683.16 1485.86 L1661.21 1485.86 L1661.21 1481.92 Q1663.88 1479.17 1668.46 1474.54 Q1673.07 1469.88 1674.25 1468.54 Q1676.49 1466.02 1677.37 1464.28 Q1678.27 1462.52 1678.27 1460.83 Q1678.27 1458.08 1676.33 1456.34 Q1674.41 1454.61 1671.31 1454.61 Q1669.11 1454.61 1666.65 1455.37 Q1664.22 1456.13 1661.44 1457.68 L1661.44 1452.96 Q1664.27 1451.83 1666.72 1451.25 Q1669.18 1450.67 1671.21 1450.67 Q1676.58 1450.67 1679.78 1453.36 Q1682.97 1456.04 1682.97 1460.53 Q1682.97 1462.66 1682.16 1464.58 Q1681.38 1466.48 1679.27 1469.07 Q1678.69 1469.74 1675.59 1472.96 Q1672.49 1476.16 1666.84 1481.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1702.97 1454.37 Q1699.36 1454.37 1697.53 1457.94 Q1695.73 1461.48 1695.73 1468.61 Q1695.73 1475.72 1697.53 1479.28 Q1699.36 1482.82 1702.97 1482.82 Q1706.61 1482.82 1708.41 1479.28 Q1710.24 1475.72 1710.24 1468.61 Q1710.24 1461.48 1708.41 1457.94 Q1706.61 1454.37 1702.97 1454.37 M1702.97 1450.67 Q1708.78 1450.67 1711.84 1455.28 Q1714.92 1459.86 1714.92 1468.61 Q1714.92 1477.34 1711.84 1481.94 Q1708.78 1486.53 1702.97 1486.53 Q1697.16 1486.53 1694.08 1481.94 Q1691.03 1477.34 1691.03 1468.61 Q1691.03 1459.86 1694.08 1455.28 Q1697.16 1450.67 1702.97 1450.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2055.64 1481.92 L2071.96 1481.92 L2071.96 1485.86 L2050.01 1485.86 L2050.01 1481.92 Q2052.68 1479.17 2057.26 1474.54 Q2061.87 1469.88 2063.05 1468.54 Q2065.29 1466.02 2066.17 1464.28 Q2067.07 1462.52 2067.07 1460.83 Q2067.07 1458.08 2065.13 1456.34 Q2063.21 1454.61 2060.11 1454.61 Q2057.91 1454.61 2055.45 1455.37 Q2053.02 1456.13 2050.25 1457.68 L2050.25 1452.96 Q2053.07 1451.83 2055.52 1451.25 Q2057.98 1450.67 2060.01 1450.67 Q2065.38 1450.67 2068.58 1453.36 Q2071.77 1456.04 2071.77 1460.53 Q2071.77 1462.66 2070.96 1464.58 Q2070.18 1466.48 2068.07 1469.07 Q2067.49 1469.74 2064.39 1472.96 Q2061.29 1476.16 2055.64 1481.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2081.82 1451.3 L2100.18 1451.3 L2100.18 1455.23 L2086.1 1455.23 L2086.1 1463.7 Q2087.12 1463.36 2088.14 1463.19 Q2089.16 1463.01 2090.18 1463.01 Q2095.96 1463.01 2099.34 1466.18 Q2102.72 1469.35 2102.72 1474.77 Q2102.72 1480.35 2099.25 1483.45 Q2095.78 1486.53 2089.46 1486.53 Q2087.28 1486.53 2085.01 1486.16 Q2082.77 1485.79 2080.36 1485.05 L2080.36 1480.35 Q2082.44 1481.48 2084.67 1482.04 Q2086.89 1482.59 2089.37 1482.59 Q2093.37 1482.59 2095.71 1480.49 Q2098.05 1478.38 2098.05 1474.77 Q2098.05 1471.16 2095.71 1469.05 Q2093.37 1466.94 2089.37 1466.94 Q2087.49 1466.94 2085.62 1467.36 Q2083.76 1467.78 2081.82 1468.66 L2081.82 1451.3 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1082.79 1549.03 L1082.79 1551.9 L1055.86 1551.9 Q1056.24 1557.94 1059.49 1561.13 Q1062.77 1564.28 1068.59 1564.28 Q1071.97 1564.28 1075.12 1563.45 Q1078.3 1562.62 1081.42 1560.97 L1081.42 1566.51 Q1078.27 1567.84 1074.96 1568.54 Q1071.65 1569.24 1068.24 1569.24 Q1059.71 1569.24 1054.72 1564.28 Q1049.75 1559.31 1049.75 1550.85 Q1049.75 1542.09 1054.46 1536.97 Q1059.2 1531.81 1067.22 1531.81 Q1074.42 1531.81 1078.59 1536.46 Q1082.79 1541.07 1082.79 1549.03 M1076.93 1547.31 Q1076.87 1542.51 1074.23 1539.64 Q1071.62 1536.78 1067.29 1536.78 Q1062.39 1536.78 1059.43 1539.55 Q1056.5 1542.32 1056.05 1547.34 L1076.93 1547.31 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1098.07 1562.97 L1098.07 1581.88 L1092.18 1581.88 L1092.18 1532.67 L1098.07 1532.67 L1098.07 1538.08 Q1099.91 1534.9 1102.71 1533.37 Q1105.55 1531.81 1109.46 1531.81 Q1115.95 1531.81 1120 1536.97 Q1124.07 1542.12 1124.07 1550.53 Q1124.07 1558.93 1120 1564.09 Q1115.95 1569.24 1109.46 1569.24 Q1105.55 1569.24 1102.71 1567.72 Q1099.91 1566.16 1098.07 1562.97 M1117.99 1550.53 Q1117.99 1544.07 1115.32 1540.41 Q1112.68 1536.71 1108.03 1536.71 Q1103.38 1536.71 1100.71 1540.41 Q1098.07 1544.07 1098.07 1550.53 Q1098.07 1556.99 1100.71 1560.68 Q1103.38 1564.34 1108.03 1564.34 Q1112.68 1564.34 1115.32 1560.68 Q1117.99 1556.99 1117.99 1550.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1147.59 1536.78 Q1142.88 1536.78 1140.14 1540.47 Q1137.41 1544.13 1137.41 1550.53 Q1137.41 1556.93 1140.11 1560.62 Q1142.85 1564.28 1147.59 1564.28 Q1152.27 1564.28 1155.01 1560.59 Q1157.75 1556.89 1157.75 1550.53 Q1157.75 1544.19 1155.01 1540.5 Q1152.27 1536.78 1147.59 1536.78 M1147.59 1531.81 Q1155.23 1531.81 1159.59 1536.78 Q1163.95 1541.74 1163.95 1550.53 Q1163.95 1559.28 1159.59 1564.28 Q1155.23 1569.24 1147.59 1569.24 Q1139.92 1569.24 1135.56 1564.28 Q1131.23 1559.28 1131.23 1550.53 Q1131.23 1541.74 1135.56 1536.78 Q1139.92 1531.81 1147.59 1531.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1199.31 1534.04 L1199.31 1539.51 Q1196.83 1538.15 1194.32 1537.48 Q1191.83 1536.78 1189.29 1536.78 Q1183.59 1536.78 1180.44 1540.41 Q1177.29 1544 1177.29 1550.53 Q1177.29 1557.05 1180.44 1560.68 Q1183.59 1564.28 1189.29 1564.28 Q1191.83 1564.28 1194.32 1563.61 Q1196.83 1562.91 1199.31 1561.54 L1199.31 1566.95 Q1196.86 1568.1 1194.22 1568.67 Q1191.61 1569.24 1188.65 1569.24 Q1180.6 1569.24 1175.86 1564.18 Q1171.11 1559.12 1171.11 1550.53 Q1171.11 1541.81 1175.89 1536.81 Q1180.69 1531.81 1189.03 1531.81 Q1191.74 1531.81 1194.32 1532.39 Q1196.89 1532.93 1199.31 1534.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1239.13 1546.8 L1239.13 1568.32 L1233.27 1568.32 L1233.27 1546.99 Q1233.27 1541.93 1231.3 1539.42 Q1229.33 1536.9 1225.38 1536.9 Q1220.64 1536.9 1217.9 1539.93 Q1215.16 1542.95 1215.16 1548.17 L1215.16 1568.32 L1209.28 1568.32 L1209.28 1518.79 L1215.16 1518.79 L1215.16 1538.21 Q1217.26 1535 1220.1 1533.4 Q1222.96 1531.81 1226.69 1531.81 Q1232.83 1531.81 1235.98 1535.63 Q1239.13 1539.42 1239.13 1546.8 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2132.28,1423.46 2132.28,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2132.28,1156 2113.39,1156 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2132.28,828.828 2113.39,828.828 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2132.28,501.654 2113.39,501.654 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2132.28,174.479 2113.39,174.479 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"M2180.23 1141.8 Q2176.62 1141.8 2174.79 1145.37 Q2172.98 1148.91 2172.98 1156.04 Q2172.98 1163.14 2174.79 1166.71 Q2176.62 1170.25 2180.23 1170.25 Q2183.86 1170.25 2185.67 1166.71 Q2187.5 1163.14 2187.5 1156.04 Q2187.5 1148.91 2185.67 1145.37 Q2183.86 1141.8 2180.23 1141.8 M2180.23 1138.1 Q2186.04 1138.1 2189.09 1142.7 Q2192.17 1147.29 2192.17 1156.04 Q2192.17 1164.76 2189.09 1169.37 Q2186.04 1173.95 2180.23 1173.95 Q2174.42 1173.95 2171.34 1169.37 Q2168.28 1164.76 2168.28 1156.04 Q2168.28 1147.29 2171.34 1142.7 Q2174.42 1138.1 2180.23 1138.1 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2200.39 1167.4 L2205.27 1167.4 L2205.27 1173.28 L2200.39 1173.28 L2200.39 1167.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2214.28 1138.72 L2236.5 1138.72 L2236.5 1140.71 L2223.95 1173.28 L2219.07 1173.28 L2230.88 1142.66 L2214.28 1142.66 L2214.28 1138.72 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2256.2 1154.14 Q2253.05 1154.14 2251.2 1156.29 Q2249.37 1158.45 2249.37 1162.2 Q2249.37 1165.92 2251.2 1168.1 Q2253.05 1170.25 2256.2 1170.25 Q2259.35 1170.25 2261.18 1168.1 Q2263.03 1165.92 2263.03 1162.2 Q2263.03 1158.45 2261.18 1156.29 Q2259.35 1154.14 2256.2 1154.14 M2265.48 1139.49 L2265.48 1143.75 Q2263.72 1142.91 2261.92 1142.47 Q2260.13 1142.03 2258.38 1142.03 Q2253.75 1142.03 2251.29 1145.16 Q2248.86 1148.28 2248.51 1154.6 Q2249.88 1152.59 2251.94 1151.52 Q2254 1150.44 2256.48 1150.44 Q2261.69 1150.44 2264.69 1153.61 Q2267.73 1156.76 2267.73 1162.2 Q2267.73 1167.52 2264.58 1170.74 Q2261.43 1173.95 2256.2 1173.95 Q2250.2 1173.95 2247.03 1169.37 Q2243.86 1164.76 2243.86 1156.04 Q2243.86 1147.84 2247.75 1142.98 Q2251.64 1138.1 2258.19 1138.1 Q2259.95 1138.1 2261.73 1138.45 Q2263.54 1138.79 2265.48 1139.49 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2180.23 814.627 Q2176.62 814.627 2174.79 818.192 Q2172.98 821.734 2172.98 828.863 Q2172.98 835.97 2174.79 839.534 Q2176.62 843.076 2180.23 843.076 Q2183.86 843.076 2185.67 839.534 Q2187.5 835.97 2187.5 828.863 Q2187.5 821.734 2185.67 818.192 Q2183.86 814.627 2180.23 814.627 M2180.23 810.923 Q2186.04 810.923 2189.09 815.53 Q2192.17 820.113 2192.17 828.863 Q2192.17 837.59 2189.09 842.196 Q2186.04 846.78 2180.23 846.78 Q2174.42 846.78 2171.34 842.196 Q2168.28 837.59 2168.28 828.863 Q2168.28 820.113 2171.34 815.53 Q2174.42 810.923 2180.23 810.923 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2200.39 840.229 L2205.27 840.229 L2205.27 846.108 L2200.39 846.108 L2200.39 840.229 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2214.28 811.548 L2236.5 811.548 L2236.5 813.539 L2223.95 846.108 L2219.07 846.108 L2230.88 815.484 L2214.28 815.484 L2214.28 811.548 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2255.62 829.696 Q2252.29 829.696 2250.37 831.479 Q2248.47 833.261 2248.47 836.386 Q2248.47 839.511 2250.37 841.294 Q2252.29 843.076 2255.62 843.076 Q2258.95 843.076 2260.88 841.294 Q2262.8 839.488 2262.8 836.386 Q2262.8 833.261 2260.88 831.479 Q2258.98 829.696 2255.62 829.696 M2250.95 827.706 Q2247.94 826.965 2246.25 824.905 Q2244.58 822.845 2244.58 819.882 Q2244.58 815.738 2247.52 813.331 Q2250.48 810.923 2255.62 810.923 Q2260.78 810.923 2263.72 813.331 Q2266.66 815.738 2266.66 819.882 Q2266.66 822.845 2264.97 824.905 Q2263.31 826.965 2260.32 827.706 Q2263.7 828.493 2265.57 830.784 Q2267.47 833.076 2267.47 836.386 Q2267.47 841.409 2264.39 844.095 Q2261.34 846.78 2255.62 846.78 Q2249.9 846.78 2246.82 844.095 Q2243.77 841.409 2243.77 836.386 Q2243.77 833.076 2245.67 830.784 Q2247.57 828.493 2250.95 827.706 M2249.23 820.322 Q2249.23 823.007 2250.9 824.511 Q2252.59 826.016 2255.62 826.016 Q2258.63 826.016 2260.32 824.511 Q2262.03 823.007 2262.03 820.322 Q2262.03 817.636 2260.32 816.132 Q2258.63 814.627 2255.62 814.627 Q2252.59 814.627 2250.9 816.132 Q2249.23 817.636 2249.23 820.322 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2180.23 487.452 Q2176.62 487.452 2174.79 491.017 Q2172.98 494.559 2172.98 501.688 Q2172.98 508.795 2174.79 512.36 Q2176.62 515.901 2180.23 515.901 Q2183.86 515.901 2185.67 512.36 Q2187.5 508.795 2187.5 501.688 Q2187.5 494.559 2185.67 491.017 Q2183.86 487.452 2180.23 487.452 M2180.23 483.749 Q2186.04 483.749 2189.09 488.355 Q2192.17 492.938 2192.17 501.688 Q2192.17 510.415 2189.09 515.022 Q2186.04 519.605 2180.23 519.605 Q2174.42 519.605 2171.34 515.022 Q2168.28 510.415 2168.28 501.688 Q2168.28 492.938 2171.34 488.355 Q2174.42 483.749 2180.23 483.749 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2200.39 513.054 L2205.27 513.054 L2205.27 518.934 L2200.39 518.934 L2200.39 513.054 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2225.46 502.522 Q2222.13 502.522 2220.2 504.304 Q2218.31 506.086 2218.31 509.211 Q2218.31 512.336 2220.2 514.119 Q2222.13 515.901 2225.46 515.901 Q2228.79 515.901 2230.71 514.119 Q2232.63 512.313 2232.63 509.211 Q2232.63 506.086 2230.71 504.304 Q2228.82 502.522 2225.46 502.522 M2220.78 500.531 Q2217.77 499.79 2216.08 497.73 Q2214.42 495.67 2214.42 492.707 Q2214.42 488.563 2217.36 486.156 Q2220.32 483.749 2225.46 483.749 Q2230.62 483.749 2233.56 486.156 Q2236.5 488.563 2236.5 492.707 Q2236.5 495.67 2234.81 497.73 Q2233.14 499.79 2230.16 500.531 Q2233.54 501.318 2235.41 503.61 Q2237.31 505.901 2237.31 509.211 Q2237.31 514.235 2234.23 516.92 Q2231.18 519.605 2225.46 519.605 Q2219.74 519.605 2216.66 516.92 Q2213.61 514.235 2213.61 509.211 Q2213.61 505.901 2215.51 503.61 Q2217.4 501.318 2220.78 500.531 M2219.07 493.147 Q2219.07 495.832 2220.74 497.336 Q2222.43 498.841 2225.46 498.841 Q2228.47 498.841 2230.16 497.336 Q2231.87 495.832 2231.87 493.147 Q2231.87 490.462 2230.16 488.957 Q2228.47 487.452 2225.46 487.452 Q2222.43 487.452 2220.74 488.957 Q2219.07 490.462 2219.07 493.147 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2255.62 487.452 Q2252.01 487.452 2250.18 491.017 Q2248.38 494.559 2248.38 501.688 Q2248.38 508.795 2250.18 512.36 Q2252.01 515.901 2255.62 515.901 Q2259.26 515.901 2261.06 512.36 Q2262.89 508.795 2262.89 501.688 Q2262.89 494.559 2261.06 491.017 Q2259.26 487.452 2255.62 487.452 M2255.62 483.749 Q2261.43 483.749 2264.49 488.355 Q2267.57 492.938 2267.57 501.688 Q2267.57 510.415 2264.49 515.022 Q2261.43 519.605 2255.62 519.605 Q2249.81 519.605 2246.73 515.022 Q2243.68 510.415 2243.68 501.688 Q2243.68 492.938 2246.73 488.355 Q2249.81 483.749 2255.62 483.749 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2180.23 160.277 Q2176.62 160.277 2174.79 163.842 Q2172.98 167.384 2172.98 174.513 Q2172.98 181.62 2174.79 185.185 Q2176.62 188.726 2180.23 188.726 Q2183.86 188.726 2185.67 185.185 Q2187.5 181.62 2187.5 174.513 Q2187.5 167.384 2185.67 163.842 Q2183.86 160.277 2180.23 160.277 M2180.23 156.574 Q2186.04 156.574 2189.09 161.18 Q2192.17 165.764 2192.17 174.513 Q2192.17 183.24 2189.09 187.847 Q2186.04 192.43 2180.23 192.43 Q2174.42 192.43 2171.34 187.847 Q2168.28 183.24 2168.28 174.513 Q2168.28 165.764 2171.34 161.18 Q2174.42 156.574 2180.23 156.574 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2200.39 185.879 L2205.27 185.879 L2205.27 191.759 L2200.39 191.759 L2200.39 185.879 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2225.46 175.347 Q2222.13 175.347 2220.2 177.129 Q2218.31 178.912 2218.31 182.037 Q2218.31 185.162 2220.2 186.944 Q2222.13 188.726 2225.46 188.726 Q2228.79 188.726 2230.71 186.944 Q2232.63 185.138 2232.63 182.037 Q2232.63 178.912 2230.71 177.129 Q2228.82 175.347 2225.46 175.347 M2220.78 173.356 Q2217.77 172.615 2216.08 170.555 Q2214.42 168.495 2214.42 165.532 Q2214.42 161.389 2217.36 158.981 Q2220.32 156.574 2225.46 156.574 Q2230.62 156.574 2233.56 158.981 Q2236.5 161.389 2236.5 165.532 Q2236.5 168.495 2234.81 170.555 Q2233.14 172.615 2230.16 173.356 Q2233.54 174.143 2235.41 176.435 Q2237.31 178.726 2237.31 182.037 Q2237.31 187.06 2234.23 189.745 Q2231.18 192.43 2225.46 192.43 Q2219.74 192.43 2216.66 189.745 Q2213.61 187.06 2213.61 182.037 Q2213.61 178.726 2215.51 176.435 Q2217.4 174.143 2220.78 173.356 M2219.07 165.972 Q2219.07 168.657 2220.74 170.162 Q2222.43 171.666 2225.46 171.666 Q2228.47 171.666 2230.16 170.162 Q2231.87 168.657 2231.87 165.972 Q2231.87 163.287 2230.16 161.782 Q2228.47 160.277 2225.46 160.277 Q2222.43 160.277 2220.74 161.782 Q2219.07 163.287 2219.07 165.972 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2249.65 187.824 L2265.97 187.824 L2265.97 191.759 L2244.02 191.759 L2244.02 187.824 Q2246.69 185.069 2251.27 180.439 Q2255.88 175.787 2257.06 174.444 Q2259.3 171.921 2260.18 170.185 Q2261.08 168.426 2261.08 166.736 Q2261.08 163.981 2259.14 162.245 Q2257.22 160.509 2254.12 160.509 Q2251.92 160.509 2249.46 161.273 Q2247.03 162.037 2244.26 163.588 L2244.26 158.865 Q2247.08 157.731 2249.53 157.152 Q2251.99 156.574 2254.02 156.574 Q2259.39 156.574 2262.59 159.259 Q2265.78 161.944 2265.78 166.435 Q2265.78 168.564 2264.97 170.486 Q2264.19 172.384 2262.08 174.976 Q2261.5 175.648 2258.4 178.865 Q2255.3 182.06 2249.65 187.824 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip582)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.514,1384.51 290.174,865.181 367.835,86.1935 445.496,345.856 523.156,345.856 600.817,345.856 678.477,605.519 756.138,865.181 833.799,865.181 911.459,865.181 \n",
       "  989.12,865.181 1066.78,865.181 1144.44,605.519 1222.1,605.519 1299.76,605.519 1377.42,605.519 1455.08,865.181 1532.74,605.519 1610.4,865.181 1688.06,865.181 \n",
       "  1765.73,1124.84 1843.39,1124.84 1921.05,1124.84 1998.71,1124.84 2076.37,1124.84 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"\n",
       "M1637.28 761.27 L2066.43 761.27 L2066.43 657.59 L1637.28 657.59  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1637.28,761.27 2066.43,761.27 2066.43,657.59 1637.28,657.59 1637.28,761.27 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1659.23,709.43 1790.94,709.43 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"M1826.3 713.678 Q1821.14 713.678 1819.14 714.858 Q1817.15 716.039 1817.15 718.886 Q1817.15 721.154 1818.64 722.497 Q1820.14 723.816 1822.71 723.816 Q1826.25 723.816 1828.38 721.316 Q1830.53 718.793 1830.53 714.627 L1830.53 713.678 L1826.3 713.678 M1834.79 711.918 L1834.79 726.71 L1830.53 726.71 L1830.53 722.775 Q1829.08 725.136 1826.9 726.27 Q1824.72 727.381 1821.58 727.381 Q1817.59 727.381 1815.23 725.159 Q1812.89 722.914 1812.89 719.164 Q1812.89 714.789 1815.81 712.566 Q1818.75 710.344 1824.56 710.344 L1830.53 710.344 L1830.53 709.928 Q1830.53 706.988 1828.59 705.391 Q1826.67 703.77 1823.17 703.77 Q1820.95 703.77 1818.84 704.303 Q1816.74 704.835 1814.79 705.9 L1814.79 701.965 Q1817.13 701.062 1819.33 700.622 Q1821.53 700.159 1823.61 700.159 Q1829.24 700.159 1832.01 703.076 Q1834.79 705.992 1834.79 711.918 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1862.22 701.779 L1862.22 705.761 Q1860.42 704.766 1858.59 704.279 Q1856.78 703.77 1854.93 703.77 Q1850.79 703.77 1848.5 706.409 Q1846.2 709.025 1846.2 713.77 Q1846.2 718.516 1848.5 721.154 Q1850.79 723.77 1854.93 723.77 Q1856.78 723.77 1858.59 723.284 Q1860.42 722.775 1862.22 721.779 L1862.22 725.715 Q1860.44 726.548 1858.52 726.965 Q1856.62 727.381 1854.47 727.381 Q1848.61 727.381 1845.16 723.701 Q1841.71 720.02 1841.71 713.77 Q1841.71 707.428 1845.19 703.793 Q1848.68 700.159 1854.75 700.159 Q1856.71 700.159 1858.59 700.576 Q1860.46 700.969 1862.22 701.779 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1888.29 701.779 L1888.29 705.761 Q1886.48 704.766 1884.65 704.279 Q1882.85 703.77 1881 703.77 Q1876.85 703.77 1874.56 706.409 Q1872.27 709.025 1872.27 713.77 Q1872.27 718.516 1874.56 721.154 Q1876.85 723.77 1881 723.77 Q1882.85 723.77 1884.65 723.284 Q1886.48 722.775 1888.29 721.779 L1888.29 725.715 Q1886.51 726.548 1884.58 726.965 Q1882.69 727.381 1880.53 727.381 Q1874.68 727.381 1871.23 723.701 Q1867.78 720.02 1867.78 713.77 Q1867.78 707.428 1871.25 703.793 Q1874.75 700.159 1880.81 700.159 Q1882.78 700.159 1884.65 700.576 Q1886.53 700.969 1888.29 701.779 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1895.26 716.478 L1895.26 700.784 L1899.51 700.784 L1899.51 716.316 Q1899.51 719.997 1900.95 721.849 Q1902.38 723.678 1905.26 723.678 Q1908.7 723.678 1910.7 721.478 Q1912.71 719.279 1912.71 715.483 L1912.71 700.784 L1916.97 700.784 L1916.97 726.71 L1912.71 726.71 L1912.71 722.728 Q1911.16 725.09 1909.1 726.247 Q1907.06 727.381 1904.35 727.381 Q1899.88 727.381 1897.57 724.603 Q1895.26 721.826 1895.26 716.478 M1905.97 700.159 L1905.97 700.159 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1940.76 704.766 Q1940.05 704.349 1939.19 704.164 Q1938.36 703.955 1937.34 703.955 Q1933.73 703.955 1931.78 706.317 Q1929.86 708.654 1929.86 713.053 L1929.86 726.71 L1925.58 726.71 L1925.58 700.784 L1929.86 700.784 L1929.86 704.812 Q1931.2 702.451 1933.36 701.317 Q1935.51 700.159 1938.59 700.159 Q1939.03 700.159 1939.56 700.229 Q1940.09 700.275 1940.74 700.391 L1940.76 704.766 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1957.01 713.678 Q1951.85 713.678 1949.86 714.858 Q1947.87 716.039 1947.87 718.886 Q1947.87 721.154 1949.35 722.497 Q1950.86 723.816 1953.43 723.816 Q1956.97 723.816 1959.1 721.316 Q1961.25 718.793 1961.25 714.627 L1961.25 713.678 L1957.01 713.678 M1965.51 711.918 L1965.51 726.71 L1961.25 726.71 L1961.25 722.775 Q1959.79 725.136 1957.62 726.27 Q1955.44 727.381 1952.29 727.381 Q1948.31 727.381 1945.95 725.159 Q1943.61 722.914 1943.61 719.164 Q1943.61 714.789 1946.53 712.566 Q1949.47 710.344 1955.28 710.344 L1961.25 710.344 L1961.25 709.928 Q1961.25 706.988 1959.31 705.391 Q1957.38 703.77 1953.89 703.77 Q1951.67 703.77 1949.56 704.303 Q1947.45 704.835 1945.51 705.9 L1945.51 701.965 Q1947.85 701.062 1950.05 700.622 Q1952.25 700.159 1954.33 700.159 Q1959.95 700.159 1962.73 703.076 Q1965.51 705.992 1965.51 711.918 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M1992.94 701.779 L1992.94 705.761 Q1991.13 704.766 1989.31 704.279 Q1987.5 703.77 1985.65 703.77 Q1981.5 703.77 1979.21 706.409 Q1976.92 709.025 1976.92 713.77 Q1976.92 718.516 1979.21 721.154 Q1981.5 723.77 1985.65 723.77 Q1987.5 723.77 1989.31 723.284 Q1991.13 722.775 1992.94 721.779 L1992.94 725.715 Q1991.16 726.548 1989.24 726.965 Q1987.34 727.381 1985.19 727.381 Q1979.33 727.381 1975.88 723.701 Q1972.43 720.02 1972.43 713.77 Q1972.43 707.428 1975.9 703.793 Q1979.4 700.159 1985.46 700.159 Q1987.43 700.159 1989.31 700.576 Q1991.18 700.969 1992.94 701.779 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M2011.13 729.117 Q2009.33 733.747 2007.62 735.159 Q2005.9 736.571 2003.03 736.571 L1999.63 736.571 L1999.63 733.006 L2002.13 733.006 Q2003.89 733.006 2004.86 732.173 Q2005.83 731.34 2007.01 728.238 L2007.78 726.293 L1997.29 700.784 L2001.81 700.784 L2009.91 721.062 L2018.01 700.784 L2022.52 700.784 L2011.13 729.117 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "plot(loss_vector, label=\"loss\", legend=:left, color=:red, rightmargin = 1.5Plots.cm, bottommargin = 0.5Plots.cm, box = :on)\n",
    "plot!(twinx(), accuracy_vector, label=\"accuracy\", legend=:right, xlabel=\"epoch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JuliaLuxMLUtils 1.7.3",
   "language": "julia",
   "name": "julialuxmlutils-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
