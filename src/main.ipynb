{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `XTBTSScreener.jl` - Screening Likely Transition States with Julia and Machine Learning\n",
    "This Jupyter notebook demonstrates the use of machine learning to predict if a partially-optimized initialization of a transition state, used in the study of chemical kinetics to predict rate constants, is _like to converge\"_ and produze a valid transition state or not after further simulation with expensive Density Functional Theory simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "The input data is saved in a CSV file, load it using `CSV.jl` and then partition the data into training and testing sets using `MLUtils.jl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLUtils, CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_dataloaders (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_dataloaders()\n",
    "    csv_reader = CSV.File(\"data/roo_co2_full_data.csv\")\n",
    "    n_samples = 16517\n",
    "    x_data = Array{Float32}(undef, 55, 6, n_samples)\n",
    "    labels = Float32[]\n",
    "    iter = 1\n",
    "    println(\"Progress:\")\n",
    "    for row in csv_reader[1:n_samples]\n",
    "        # print some updates as we go\n",
    "        if mod(iter, div(n_samples, 25)) == 0\n",
    "            println(\" - row $iter of $n_samples\")\n",
    "            flush(stdout)\n",
    "        end\n",
    "        \n",
    "        # get if it converged or not\n",
    "        if parse(Bool, \"$(row.converged)\")\n",
    "            push!(labels, 1.0f0)\n",
    "        else\n",
    "            push!(labels, 0.0f0)\n",
    "        end\n",
    "\n",
    "        # get the final coordinates of the atoms\n",
    "        split_array = split(\"$(row.std_xyz)\")\n",
    "        n_atoms = Int(length(split_array)/6)\n",
    "        m = Array{Float32}(undef, 55, 6)\n",
    "        row_counter = 1\n",
    "        column_counter = 1\n",
    "        for value in split_array\n",
    "            temp = String(value)\n",
    "            temp = replace(temp,\"]\"=>\"\")\n",
    "            temp = replace(temp,\"[\"=>\"\")\n",
    "            temp = replace(temp,\",\"=>\"\")\n",
    "            m[row_counter, column_counter] = parse(Float32, temp)\n",
    "            column_counter += 1\n",
    "            if column_counter > 6\n",
    "                column_counter = 1\n",
    "                row_counter += 1\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # zero-padding\n",
    "        for i in n_atoms+1:55\n",
    "            m[i, 1:6] = [0,0,0,0,0,0]\n",
    "        end\n",
    "        x_data[1:55, 1:6, iter] = m\n",
    "        iter += 1\n",
    "    end\n",
    "    println(\"loading done, partitioning data.\")\n",
    "    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)\n",
    "    return (DataLoader(collect.((x_train, y_train)); batchsize=2^6, shuffle=true),\n",
    "            DataLoader(collect.((x_val, y_val)); batchsize=2^6, shuffle=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of debuggin and as a reference, the original tutorial dataloading function is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_tutorial_dataloaders (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_tutorial_dataloaders()\n",
    "    dataset_size=1000\n",
    "    sequence_length=50\n",
    "    data = [MLUtils.Datasets.make_spiral(sequence_length) for _ in 1:dataset_size]\n",
    "    # Get the labels\n",
    "    labels = vcat(repeat([0.0f0], dataset_size ÷ 2), repeat([1.0f0], dataset_size ÷ 2))\n",
    "    clockwise_spirals = [reshape(d[1][:, 1:sequence_length], :, sequence_length, 1)\n",
    "                         for d in data[1:(dataset_size ÷ 2)]]\n",
    "    anticlockwise_spirals = [reshape(d[1][:, (sequence_length + 1):end], :, sequence_length,\n",
    "                                     1) for d in data[((dataset_size ÷ 2) + 1):end]]\n",
    "    x_data = Float32.(cat(clockwise_spirals..., anticlockwise_spirals...; dims=3))\n",
    "    # Split the dataset\n",
    "    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)\n",
    "    return (DataLoader(collect.((x_train, y_train)); batchsize=128, shuffle=true),\n",
    "            DataLoader(collect.((x_val, y_val)); batchsize=128, shuffle=false))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Neural Network\n",
    "Following from the tutorial in the [Lux documentation](https://lux.csail.mit.edu/stable/examples/generated/beginner/SimpleRNN/main/) we write a series of functions that will create our NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Lux, Random, Optimisers, Zygote, NNlib, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeding\n",
    "rng = Random.default_rng()\n",
    "Random.seed!(rng, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct StateClassifier{L, C} <:\n",
    "       Lux.AbstractExplicitContainerLayer{(:lstm_cell, :classifier)}\n",
    "    lstm_cell::L\n",
    "    classifier::C\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateClassifier"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function StateClassifier(in_dims, hidden_dims, out_dims)\n",
    "    return StateClassifier(LSTMCell(in_dims => hidden_dims),\n",
    "                            Dense(hidden_dims => out_dims, sigmoid))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (s::StateClassifier)(x::AbstractArray{T, 3}, ps::NamedTuple,\n",
    "                               st::NamedTuple) where {T}\n",
    "    x_init, x_rest = Iterators.peel(eachslice(x; dims=2))\n",
    "    (y, carry), st_lstm = s.lstm_cell(x_init, ps.lstm_cell, st.lstm_cell)\n",
    "    for x in x_rest\n",
    "        (y, carry), st_lstm = s.lstm_cell((x, carry), ps.lstm_cell, st_lstm)\n",
    "    end\n",
    "    y, st_classifier = s.classifier(y, ps.classifier, st.classifier)\n",
    "    st = merge(st, (classifier=st_classifier, lstm_cell=st_lstm))\n",
    "    return vec(y), st\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function xlogy(x, y)\n",
    "    result = x * log(y)\n",
    "    return ifelse(iszero(x), zero(result), result)\n",
    "end\n",
    "\n",
    "function binarycrossentropy(y_pred, y_true)\n",
    "    y_pred = y_pred .+ eps(eltype(y_pred))\n",
    "    return mean(@. -xlogy(y_true, y_pred) - xlogy(1 - y_true, 1 - y_pred))\n",
    "end\n",
    "\n",
    "function compute_loss(x, y, model, ps, st)\n",
    "    y_pred, st = model(x, ps, st)\n",
    "    return binarycrossentropy(y_pred, y), y_pred, st\n",
    "end\n",
    "\n",
    "matches(y_pred, y_true) = sum((y_pred .> 0.5) .== y_true)\n",
    "accuracy(y_pred, y_true) = matches(y_pred, y_true) / length(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_optimiser (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_optimiser(ps)\n",
    "    opt = Optimisers.ADAM(0.01f0)\n",
    "    return Optimisers.setup(opt, ps)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NN\n",
    "Actual training and evaluation steps.\n",
    "\n",
    "Load the data from the file and parition it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:\n",
      " - row 660 of 16517\n",
      " - row 1320 of 16517\n",
      " - row 1980 of 16517\n",
      " - row 2640 of 16517\n",
      " - row 3300 of 16517\n",
      " - row 3960 of 16517\n",
      " - row 4620 of 16517\n",
      " - row 5280 of 16517\n",
      " - row 5940 of 16517\n",
      " - row 6600 of 16517\n",
      " - row 7260 of 16517\n",
      " - row 7920 of 16517\n",
      " - row 8580 of 16517\n",
      " - row 9240 of 16517\n",
      " - row 9900 of 16517\n",
      " - row 10560 of 16517\n",
      " - row 11220 of 16517\n",
      " - row 11880 of 16517\n",
      " - row 12540 of 16517\n",
      " - row 13200 of 16517\n",
      " - row 13860 of 16517\n",
      " - row 14520 of 16517\n",
      " - row 15180 of 16517\n",
      " - row 15840 of 16517\n",
      " - row 16500 of 16517\n",
      "loading done, partitioning data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DataLoader(::Tuple{Array{Float32, 3}, Vector{Float32}}, shuffle=true, batchsize=64), DataLoader(::Tuple{Array{Float32, 3}, Vector{Float32}}, batchsize=64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_loader, val_loader) = get_dataloaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(lstm_cell = (weight_i = \u001b[32mLeaf(Adam{Float32}(0.01, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, weight_h = \u001b[32mLeaf(Adam{Float32}(0.01, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam{Float32}(0.01, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0; 0.0; … ; 0.0; 0.0;;], Float32[0.0; 0.0; … ; 0.0; 0.0;;], (0.9, 0.999))\u001b[32m)\u001b[39m), classifier = (weight = \u001b[32mLeaf(Adam{Float32}(0.01, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam{Float32}(0.01, (0.9, 0.999), 1.19209f-7), \u001b[39m(Float32[0.0;;], Float32[0.0;;], (0.9, 0.999))\u001b[32m)\u001b[39m))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StateClassifier(55, 6, 1)\n",
    "rng = Random.default_rng()\n",
    "Random.seed!(rng, 0)\n",
    "ps, st = Lux.setup(rng, model)\n",
    "opt_state = create_optimiser(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual model training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1:\n",
      " - loss of 0.48685051076078184\n",
      " - accuracy of 0.8065366124260355\n",
      "Epoch # 2:\n",
      " - loss of 0.47336750502747615\n",
      " - accuracy of 0.8062361316568047\n",
      "Epoch # 3:\n",
      " - loss of 0.4666447519968097\n",
      " - accuracy of 0.8062361316568047\n",
      "Epoch # 4:\n",
      " - loss of 0.4629714838836504\n",
      " - accuracy of 0.8056351701183432\n",
      "Epoch # 5:\n",
      " - loss of 0.4570619589176731\n",
      " - accuracy of 0.8047337278106509\n",
      "Epoch # 6:\n",
      " - loss of 0.4524433393985177\n",
      " - accuracy of 0.8050342085798816\n",
      "Epoch # 7:\n",
      " - loss of 0.44906442968741705\n",
      " - accuracy of 0.8047337278106509\n",
      "Epoch # 8:\n",
      " - loss of 0.4447438512447376\n",
      " - accuracy of 0.8008274778106509\n",
      "Epoch # 9:\n",
      " - loss of 0.44139255691265716\n",
      " - accuracy of 0.7978226701183432\n",
      "Epoch # 10:\n",
      " - loss of 0.43807190483894903\n",
      " - accuracy of 0.7969212278106509\n",
      "Epoch # 11:\n",
      " - loss of 0.43688222996278664\n",
      " - accuracy of 0.7961276503944773\n",
      "Epoch # 12:\n",
      " - loss of 0.4335442839037393\n",
      " - accuracy of 0.7982310157790926\n",
      "Epoch # 13:\n",
      " - loss of 0.43123862579248956\n",
      " - accuracy of 0.7963202662721893\n",
      "Epoch # 14:\n",
      " - loss of 0.42843107512031775\n",
      " - accuracy of 0.7951183431952663\n",
      "Epoch # 15:\n",
      " - loss of 0.42431746084908933\n",
      " - accuracy of 0.7916204388560157\n",
      "Epoch # 16:\n",
      " - loss of 0.4244908475933444\n",
      " - accuracy of 0.7952262080867849\n",
      "Epoch # 17:\n",
      " - loss of 0.422213446834813\n",
      " - accuracy of 0.7933154585798816\n",
      "Epoch # 18:\n",
      " - loss of 0.4203860248632477\n",
      " - accuracy of 0.7905263806706114\n",
      "Epoch # 19:\n",
      " - loss of 0.4168446014324824\n",
      " - accuracy of 0.7905263806706114\n",
      "Epoch # 20:\n",
      " - loss of 0.41787606801675714\n",
      " - accuracy of 0.788615631163708\n",
      "Epoch # 21:\n",
      " - loss of 0.41538915757971684\n",
      " - accuracy of 0.7878220537475346\n",
      "Epoch # 22:\n",
      " - loss of 0.4150647700264834\n",
      " - accuracy of 0.7904185157790926\n",
      "Epoch # 23:\n",
      " - loss of 0.41077755542768946\n",
      " - accuracy of 0.7853103427021696\n",
      "Epoch # 24:\n",
      " - loss of 0.41093666966698594\n",
      " - accuracy of 0.7817045734714003\n",
      "Epoch # 25:\n",
      " - loss of 0.40981788587742957\n",
      " - accuracy of 0.7848172460552268\n",
      "Epoch # 26:\n",
      " - loss of 0.40781330659193693\n",
      " - accuracy of 0.7856108234714003\n",
      "Epoch # 27:\n",
      " - loss of 0.40592448701317185\n",
      " - accuracy of 0.7856108234714003\n",
      "Epoch # 28:\n",
      " - loss of 0.40598003055162474\n",
      " - accuracy of 0.7797090729783037\n",
      "Epoch # 29:\n",
      " - loss of 0.40304507775871073\n",
      " - accuracy of 0.7823055350098619\n",
      "Epoch # 30:\n",
      " - loss of 0.40157873331060734\n",
      " - accuracy of 0.7765964003944773\n",
      "Epoch # 31:\n",
      " - loss of 0.4041576164500149\n",
      " - accuracy of 0.782498150887574\n",
      "Epoch # 32:\n",
      " - loss of 0.4031555737562226\n",
      " - accuracy of 0.7815119575936884\n",
      "Epoch # 33:\n",
      " - loss of 0.40013003968386257\n",
      " - accuracy of 0.7774978427021696\n",
      "Epoch # 34:\n",
      " - loss of 0.40089317875495856\n",
      " - accuracy of 0.7805026503944773\n",
      "Epoch # 35:\n",
      " - loss of 0.39742454202566746\n",
      " - accuracy of 0.7791928624260355\n",
      "Epoch # 36:\n",
      " - loss of 0.3967181431210559\n",
      " - accuracy of 0.7770047460552268\n",
      "Epoch # 37:\n",
      " - loss of 0.3961184150786791\n",
      " - accuracy of 0.7671967455621301\n",
      "Epoch # 38:\n",
      " - loss of 0.3940106699432152\n",
      " - accuracy of 0.7736994575936884\n",
      "Epoch # 39:\n",
      " - loss of 0.396400783372962\n",
      " - accuracy of 0.7735068417159763\n",
      "Epoch # 40:\n",
      " - loss of 0.3939524283587645\n",
      " - accuracy of 0.7771973619329388\n",
      "Epoch # 41:\n",
      " - loss of 0.39332078224506933\n",
      " - accuracy of 0.776511649408284\n",
      "Epoch # 42:\n",
      " - loss of 0.39421339570612146\n",
      " - accuracy of 0.7681829388560157\n",
      "Epoch # 43:\n",
      " - loss of 0.3920942416081682\n",
      " - accuracy of 0.7799016888560157\n",
      "Epoch # 44:\n",
      " - loss of 0.3909399961503807\n",
      " - accuracy of 0.7687839003944773\n",
      "Epoch # 45:\n",
      " - loss of 0.38950327845011357\n",
      " - accuracy of 0.7697932075936884\n",
      "Epoch # 46:\n",
      " - loss of 0.39174519457678864\n",
      " - accuracy of 0.7774978427021696\n",
      "Epoch # 47:\n",
      " - loss of 0.38733748134207613\n",
      " - accuracy of 0.7710798816568047\n",
      "Epoch # 48:\n",
      " - loss of 0.3903512093036071\n",
      " - accuracy of 0.7720891888560157\n",
      "Epoch # 49:\n",
      " - loss of 0.38931085284493394\n",
      " - accuracy of 0.7687839003944773\n",
      "Epoch # 50:\n",
      " - loss of 0.3867448089635315\n",
      " - accuracy of 0.7720891888560157\n",
      "Epoch # 51:\n",
      " - loss of 0.3856453960356505\n",
      " - accuracy of 0.7741925542406312\n",
      "Epoch # 52:\n",
      " - loss of 0.389197685652309\n",
      " - accuracy of 0.761271881163708\n",
      "Epoch # 53:\n",
      " - loss of 0.38845703855228886\n",
      " - accuracy of 0.7658869575936884\n",
      "Epoch # 54:\n",
      " - loss of 0.3868415162759127\n",
      " - accuracy of 0.7723896696252465\n",
      "Epoch # 55:\n",
      " - loss of 0.3866967579736802\n",
      " - accuracy of 0.7675819773175542\n",
      "Epoch # 56:\n",
      " - loss of 0.38540407403367727\n",
      " - accuracy of 0.771981323964497\n",
      "Epoch # 57:\n",
      " - loss of 0.38835995057642747\n",
      " - accuracy of 0.7708872657790926\n",
      "Epoch # 58:\n",
      " - loss of 0.38675005294850484\n",
      " - accuracy of 0.772990631163708\n",
      "Epoch # 59:\n",
      " - loss of 0.3831807121562497\n",
      " - accuracy of 0.761271881163708\n",
      "Epoch # 60:\n",
      " - loss of 0.38186103501469615\n",
      " - accuracy of 0.765178131163708\n",
      "Epoch # 61:\n",
      " - loss of 0.386140167641179\n",
      " - accuracy of 0.7716808431952663\n",
      "Epoch # 62:\n",
      " - loss of 0.3829007166739247\n",
      " - accuracy of 0.7735915927021696\n",
      "Epoch # 63:\n",
      " - loss of 0.3800021863502005\n",
      " - accuracy of 0.7693848619329388\n",
      "Epoch # 64:\n",
      " - loss of 0.3828122721634049\n",
      " - accuracy of 0.7696853427021696\n",
      "Epoch # 65:\n",
      " - loss of 0.3820971710526425\n",
      " - accuracy of 0.7639762080867849\n",
      "Epoch # 66:\n",
      " - loss of 0.3820995288914528\n",
      " - accuracy of 0.7681829388560157\n",
      "Epoch # 67:\n",
      " - loss of 0.38154777546147794\n",
      " - accuracy of 0.7631826306706114\n",
      "Epoch # 68:\n",
      " - loss of 0.37970111738656454\n",
      " - accuracy of 0.7623890532544378\n",
      "Epoch # 69:\n",
      " - loss of 0.3803054681002806\n",
      " - accuracy of 0.7678824580867849\n",
      "Epoch # 70:\n",
      " - loss of 0.37967509988713377\n",
      " - accuracy of 0.7673893614398423\n",
      "Epoch # 71:\n",
      " - loss of 0.3790635812109795\n",
      " - accuracy of 0.7563794378698224\n",
      "Epoch # 72:\n",
      " - loss of 0.3773170903972957\n",
      " - accuracy of 0.761271881163708\n",
      "Epoch # 73:\n",
      " - loss of 0.3771549569091935\n",
      " - accuracy of 0.769084381163708\n",
      "Epoch # 74:\n",
      " - loss of 0.37736588306185126\n",
      " - accuracy of 0.7678824580867849\n",
      "Epoch # 75:\n",
      " - loss of 0.3774627236208478\n",
      " - accuracy of 0.7647697855029586\n",
      "Epoch # 76:\n",
      " - loss of 0.3775238351545472\n",
      " - accuracy of 0.7576661119329388\n",
      "Epoch # 77:\n",
      " - loss of 0.3778908187928407\n",
      " - accuracy of 0.7646850345167653\n",
      "Epoch # 78:\n",
      " - loss of 0.3778441772944685\n",
      " - accuracy of 0.7634831114398423\n",
      "Epoch # 79:\n",
      " - loss of 0.3786308750294257\n",
      " - accuracy of 0.7618728427021696\n",
      "Epoch # 80:\n",
      " - loss of 0.3776813455393925\n",
      " - accuracy of 0.7584596893491125\n",
      "Epoch # 81:\n",
      " - loss of 0.3775311069931961\n",
      " - accuracy of 0.7660795734714003\n",
      "Epoch # 82:\n",
      " - loss of 0.37515022292517236\n",
      " - accuracy of 0.7698779585798816\n",
      "Epoch # 83:\n",
      " - loss of 0.3770341480123824\n",
      " - accuracy of 0.7644693047337279\n",
      "Epoch # 84:\n",
      " - loss of 0.3774736322066634\n",
      " - accuracy of 0.7578587278106509\n",
      "Epoch # 85:\n",
      " - loss of 0.3747918997409839\n",
      " - accuracy of 0.7633752465483234\n",
      "Epoch # 86:\n",
      " - loss of 0.3815992573897044\n",
      " - accuracy of 0.763783592209073\n",
      "Epoch # 87:\n",
      " - loss of 0.3836729584828667\n",
      " - accuracy of 0.7590837647928994\n",
      "Epoch # 88:\n",
      " - loss of 0.3780940362940664\n",
      " - accuracy of 0.7604783037475346\n",
      "Epoch # 89:\n",
      " - loss of 0.3781338048298002\n",
      " - accuracy of 0.7631826306706114\n",
      "Epoch # 90:\n",
      " - loss of 0.37623994981033215\n",
      " - accuracy of 0.7616802268244576\n",
      "Epoch # 91:\n",
      " - loss of 0.3751999525632259\n",
      " - accuracy of 0.7623890532544378\n",
      "Epoch # 92:\n",
      " - loss of 0.3743631481980356\n",
      " - accuracy of 0.764168823964497\n",
      "Epoch # 93:\n",
      " - loss of 0.3744767621375512\n",
      " - accuracy of 0.7619807075936884\n",
      "Epoch # 94:\n",
      " - loss of 0.37741915701668044\n",
      " - accuracy of 0.7597694773175542\n",
      "Epoch # 95:\n",
      " - loss of 0.3745751268621804\n",
      " - accuracy of 0.7584596893491125\n",
      "Epoch # 96:\n",
      " - loss of 0.3738147727245294\n",
      " - accuracy of 0.7552622657790926\n",
      "Epoch # 97:\n",
      " - loss of 0.36829166416672693\n",
      " - accuracy of 0.7511633999013807\n",
      "Epoch # 98:\n",
      " - loss of 0.37231341940193363\n",
      " - accuracy of 0.7582670734714003\n",
      "Epoch # 99:\n",
      " - loss of 0.37165382007757825\n",
      " - accuracy of 0.7642766888560157\n",
      "Epoch # 100:\n",
      " - loss of 0.36978171017146916\n",
      " - accuracy of 0.7615723619329388\n",
      "Epoch # 101:\n",
      " - loss of 0.37134912307711615\n",
      " - accuracy of 0.7517643614398423\n",
      "Epoch # 102:\n",
      " - loss of 0.37204356793908105\n",
      " - accuracy of 0.7558632273175542\n",
      "Epoch # 103:\n",
      " - loss of 0.37210005824116693\n",
      " - accuracy of 0.7465714373767258\n",
      "Epoch # 104:\n",
      " - loss of 0.3713556204873007\n",
      " - accuracy of 0.7615723619329388\n",
      "Epoch # 105:\n",
      " - loss of 0.37289420994007644\n",
      " - accuracy of 0.7589758999013807\n",
      "Epoch # 106:\n",
      " - loss of 0.37498601400045956\n",
      " - accuracy of 0.7618728427021696\n",
      "Epoch # 107:\n",
      " - loss of 0.3742343892077893\n",
      " - accuracy of 0.747341900887574\n",
      "Epoch # 108:\n",
      " - loss of 0.3697610048280246\n",
      " - accuracy of 0.7592532667652859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 109:\n",
      " - loss of 0.3725320664436921\n",
      " - accuracy of 0.7571730152859961\n",
      "Epoch # 110:\n",
      " - loss of 0.3741567327780424\n",
      " - accuracy of 0.7599852071005917\n",
      "Epoch # 111:\n",
      " - loss of 0.3719594785268756\n",
      " - accuracy of 0.7585906681459567\n",
      "Epoch # 112:\n",
      " - loss of 0.37043100271535956\n",
      " - accuracy of 0.7565720537475346\n",
      "Epoch # 113:\n",
      " - loss of 0.3695730718149655\n",
      " - accuracy of 0.759877342209073\n",
      "Epoch # 114:\n",
      " - loss of 0.36716788200940487\n",
      " - accuracy of 0.7616802268244576\n",
      "Epoch # 115:\n",
      " - loss of 0.36516805986563367\n",
      " - accuracy of 0.7545765532544378\n",
      "Epoch # 116:\n",
      " - loss of 0.3661393193519058\n",
      " - accuracy of 0.7532667652859961\n",
      "Epoch # 117:\n",
      " - loss of 0.364970616168446\n",
      " - accuracy of 0.7495762450690335\n",
      "Epoch # 118:\n",
      " - loss of 0.3643284175850919\n",
      " - accuracy of 0.7503929363905326\n",
      "Epoch # 119:\n",
      " - loss of 0.3641648907304386\n",
      " - accuracy of 0.7564873027613412\n",
      "Epoch # 120:\n",
      " - loss of 0.36703292867123793\n",
      " - accuracy of 0.7564873027613412\n",
      "Epoch # 121:\n",
      " - loss of 0.36584849461265234\n",
      " - accuracy of 0.7560789571005917\n",
      "Epoch # 122:\n",
      " - loss of 0.3639966846232253\n",
      " - accuracy of 0.756980399408284\n",
      "Epoch # 123:\n",
      " - loss of 0.36626663825650146\n",
      " - accuracy of 0.7556706114398423\n",
      "Epoch # 124:\n",
      " - loss of 0.36879820624987286\n",
      " - accuracy of 0.7532667652859961\n",
      "Epoch # 125:\n",
      " - loss of 0.3654995171920113\n",
      " - accuracy of 0.7597925912228797\n",
      "Epoch # 126:\n",
      " - loss of 0.3683954561534135\n",
      " - accuracy of 0.7525810527613412\n",
      "Epoch # 127:\n",
      " - loss of 0.36852832937586133\n",
      " - accuracy of 0.7535672460552268\n",
      "Epoch # 128:\n",
      " - loss of 0.3657253183748411\n",
      " - accuracy of 0.7554779955621301\n",
      "Epoch # 129:\n",
      " - loss of 0.366680306656925\n",
      " - accuracy of 0.760886649408284\n",
      "Epoch # 130:\n",
      " - loss of 0.3630709417776209\n",
      " - accuracy of 0.7563794378698224\n",
      "Epoch # 131:\n",
      " - loss of 0.36399116773824186\n",
      " - accuracy of 0.7441675912228797\n",
      "Epoch # 132:\n",
      " - loss of 0.3646202213378344\n",
      " - accuracy of 0.7520879561143984\n",
      "Epoch # 133:\n",
      " - loss of 0.36784216833575334\n",
      " - accuracy of 0.755585860453649\n",
      "Epoch # 134:\n",
      " - loss of 0.3660938644034851\n",
      " - accuracy of 0.7517643614398423\n",
      "Epoch # 135:\n",
      " - loss of 0.36683261804822564\n",
      " - accuracy of 0.7575582470414202\n",
      "Epoch # 136:\n",
      " - loss of 0.3674394887858543\n",
      " - accuracy of 0.7584828032544378\n",
      "Epoch # 137:\n",
      " - loss of 0.36274551078317246\n",
      " - accuracy of 0.7586754191321499\n",
      "Epoch # 138:\n",
      " - loss of 0.36452128389031413\n",
      " - accuracy of 0.7557784763313609\n",
      "Epoch # 139:\n",
      " - loss of 0.3668037884045338\n",
      " - accuracy of 0.7577739768244576\n",
      "Epoch # 140:\n",
      " - loss of 0.3645698279862243\n",
      " - accuracy of 0.7565720537475346\n",
      "Epoch # 141:\n",
      " - loss of 0.3655883610824456\n",
      " - accuracy of 0.7556706114398423\n",
      "Epoch # 142:\n",
      " - loss of 0.3638207589946507\n",
      " - accuracy of 0.7594689965483234\n",
      "Epoch # 143:\n",
      " - loss of 0.36206779157481905\n",
      " - accuracy of 0.7604783037475346\n",
      "Epoch # 144:\n",
      " - loss of 0.3628010060908138\n",
      " - accuracy of 0.7547691691321499\n",
      "Epoch # 145:\n",
      " - loss of 0.3647715188022973\n",
      " - accuracy of 0.7554779955621301\n",
      "Epoch # 146:\n",
      " - loss of 0.3640149919595119\n",
      " - accuracy of 0.7529662845167653\n",
      "Epoch # 147:\n",
      " - loss of 0.36517344062455037\n",
      " - accuracy of 0.7509707840236686\n",
      "Epoch # 148:\n",
      " - loss of 0.36163548383735805\n",
      " - accuracy of 0.7553701306706114\n",
      "Epoch # 149:\n",
      " - loss of 0.36128950421360956\n",
      " - accuracy of 0.7546613042406312\n",
      "Epoch # 150:\n",
      " - loss of 0.3594619204888597\n",
      " - accuracy of 0.7586754191321499\n",
      "Epoch # 151:\n",
      " - loss of 0.36174653837646265\n",
      " - accuracy of 0.7510555350098619\n",
      "Epoch # 152:\n",
      " - loss of 0.363184020643073\n",
      " - accuracy of 0.7532667652859961\n",
      "Epoch # 153:\n",
      " - loss of 0.3670418598657645\n",
      " - accuracy of 0.7529662845167653\n",
      "Epoch # 154:\n",
      " - loss of 0.36305529930165426\n",
      " - accuracy of 0.761703340729783\n",
      "Epoch # 155:\n",
      " - loss of 0.36148583118754307\n",
      " - accuracy of 0.7578587278106509\n",
      "Epoch # 156:\n",
      " - loss of 0.3630917404872784\n",
      " - accuracy of 0.7636757273175542\n",
      "Epoch # 157:\n",
      " - loss of 0.3625689010689224\n",
      " - accuracy of 0.7607787845167653\n",
      "Epoch # 158:\n",
      " - loss of 0.3595333854501374\n",
      " - accuracy of 0.7634831114398423\n",
      "Epoch # 159:\n",
      " - loss of 0.36362183007641113\n",
      " - accuracy of 0.7573887450690335\n",
      "Epoch # 160:\n",
      " - loss of 0.3595572870566649\n",
      " - accuracy of 0.7582670734714003\n",
      "Epoch # 161:\n",
      " - loss of 0.35902695480176217\n",
      " - accuracy of 0.7583749383629191\n",
      "Epoch # 162:\n",
      " - loss of 0.3607362337446443\n",
      " - accuracy of 0.7619807075936884\n",
      "Epoch # 163:\n",
      " - loss of 0.3593157740030888\n",
      " - accuracy of 0.7596616124260355\n",
      "Epoch # 164:\n",
      " - loss of 0.36072120459183404\n",
      " - accuracy of 0.755971092209073\n",
      "Epoch # 165:\n",
      " - loss of 0.36313417633086587\n",
      " - accuracy of 0.7527736686390532\n",
      "Epoch # 166:\n",
      " - loss of 0.36138681959414826\n",
      " - accuracy of 0.7560789571005917\n",
      "Epoch # 167:\n",
      " - loss of 0.3590557632094996\n",
      " - accuracy of 0.7568725345167653\n",
      "Epoch # 168:\n",
      " - loss of 0.3599559766226921\n",
      " - accuracy of 0.7535672460552268\n",
      "Epoch # 169:\n",
      " - loss of 0.3609214123464437\n",
      " - accuracy of 0.7623659393491125\n",
      "Epoch # 170:\n",
      " - loss of 0.3609628092839522\n",
      " - accuracy of 0.7563794378698224\n",
      "Epoch # 171:\n",
      " - loss of 0.3624576885919064\n",
      " - accuracy of 0.7508629191321499\n",
      "Epoch # 172:\n",
      " - loss of 0.3608458684262446\n",
      " - accuracy of 0.7609714003944773\n",
      "Epoch # 173:\n",
      " - loss of 0.35762173527680735\n",
      " - accuracy of 0.7574734960552268\n",
      "Epoch # 174:\n",
      " - loss of 0.3551893026212563\n",
      " - accuracy of 0.7577739768244576\n",
      "Epoch # 175:\n",
      " - loss of 0.35907740235904567\n",
      " - accuracy of 0.757365631163708\n",
      "Epoch # 176:\n",
      " - loss of 0.3593938914330109\n",
      " - accuracy of 0.7488674186390532\n",
      "Epoch # 177:\n",
      " - loss of 0.3579237438774339\n",
      " - accuracy of 0.756980399408284\n",
      "Epoch # 178:\n",
      " - loss of 0.35768198520665007\n",
      " - accuracy of 0.7558632273175542\n",
      "Epoch # 179:\n",
      " - loss of 0.35681234199355766\n",
      " - accuracy of 0.7550696499013807\n",
      "Epoch # 180:\n",
      " - loss of 0.3617871582220142\n",
      " - accuracy of 0.7604783037475346\n",
      "Epoch # 181:\n",
      " - loss of 0.35809968865436054\n",
      " - accuracy of 0.7515717455621301\n",
      "Epoch # 182:\n",
      " - loss of 0.36150078849803996\n",
      " - accuracy of 0.7553701306706114\n",
      "Epoch # 183:\n",
      " - loss of 0.35886587022583266\n",
      " - accuracy of 0.7551775147928994\n",
      "Epoch # 184:\n",
      " - loss of 0.36065390108576145\n",
      " - accuracy of 0.7572808801775147\n",
      "Epoch # 185:\n",
      " - loss of 0.35684151573169637\n",
      " - accuracy of 0.7586754191321499\n",
      "Epoch # 186:\n",
      " - loss of 0.35593869612700696\n",
      " - accuracy of 0.7630747657790926\n",
      "Epoch # 187:\n",
      " - loss of 0.35940912279529846\n",
      " - accuracy of 0.7605861686390532\n",
      "Epoch # 188:\n",
      " - loss of 0.3586953248522708\n",
      " - accuracy of 0.7508629191321499\n",
      "Epoch # 189:\n",
      " - loss of 0.35839165264857564\n",
      " - accuracy of 0.7568725345167653\n",
      "Epoch # 190:\n",
      " - loss of 0.3631430072484961\n",
      " - accuracy of 0.7552622657790926\n",
      "Epoch # 191:\n",
      " - loss of 0.36445841358767617\n",
      " - accuracy of 0.7628821499013807\n",
      "Epoch # 192:\n",
      " - loss of 0.3598660433637923\n",
      " - accuracy of 0.7607787845167653\n",
      "Epoch # 193:\n",
      " - loss of 0.3603262196560413\n",
      " - accuracy of 0.7575813609467456\n",
      "Epoch # 194:\n",
      " - loss of 0.35951815725524644\n",
      " - accuracy of 0.7566799186390532\n",
      "Epoch # 195:\n",
      " - loss of 0.3597796934382351\n",
      " - accuracy of 0.7518491124260355\n",
      "Epoch # 196:\n",
      " - loss of 0.36280786494414013\n",
      " - accuracy of 0.7590837647928994\n",
      "Epoch # 197:\n",
      " - loss of 0.360676577269743\n",
      " - accuracy of 0.7613797460552268\n",
      "Epoch # 198:\n",
      " - loss of 0.3562942250915196\n",
      " - accuracy of 0.7550696499013807\n",
      "Epoch # 199:\n",
      " - loss of 0.3548251567543417\n",
      " - accuracy of 0.7589758999013807\n",
      "Epoch # 200:\n",
      " - loss of 0.35713792768653463\n",
      " - accuracy of 0.7551775147928994\n",
      "Epoch # 201:\n",
      " - loss of 0.3589420645421254\n",
      " - accuracy of 0.7593842455621301\n",
      "Epoch # 202:\n",
      " - loss of 0.35837372755946745\n",
      " - accuracy of 0.750369822485207\n",
      "Epoch # 203:\n",
      " - loss of 0.3625120650167051\n",
      " - accuracy of 0.752881533530572\n",
      "Epoch # 204:\n",
      " - loss of 0.35847782865526595\n",
      " - accuracy of 0.7631826306706114\n",
      "Epoch # 205:\n",
      " - loss of 0.35749475737124825\n",
      " - accuracy of 0.7585906681459567\n",
      "Epoch # 206:\n",
      " - loss of 0.35446102146941105\n",
      " - accuracy of 0.7524731878698224\n",
      "Epoch # 207:\n",
      " - loss of 0.35561369323500114\n",
      " - accuracy of 0.7478581114398423\n",
      "Epoch # 208:\n",
      " - loss of 0.35194428092327673\n",
      " - accuracy of 0.7590837647928994\n",
      "Epoch # 209:\n",
      " - loss of 0.35096360498292434\n",
      " - accuracy of 0.7603704388560157\n",
      "Epoch # 210:\n",
      " - loss of 0.35337522690710815\n",
      " - accuracy of 0.7560558431952663\n",
      "Epoch # 211:\n",
      " - loss of 0.35894512820646957\n",
      " - accuracy of 0.7538677268244576\n",
      "Epoch # 212:\n",
      " - loss of 0.3581985294242988\n",
      " - accuracy of 0.7614644970414202\n",
      "Epoch # 213:\n",
      " - loss of 0.3554258255854897\n",
      " - accuracy of 0.7571730152859961\n",
      "Epoch # 214:\n",
      " - loss of 0.35385085829502144\n",
      " - accuracy of 0.7495762450690335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 215:\n",
      " - loss of 0.35881887412301583\n",
      " - accuracy of 0.7547691691321499\n",
      "Epoch # 216:\n",
      " - loss of 0.35899857593619305\n",
      " - accuracy of 0.7543608234714003\n",
      "Epoch # 217:\n",
      " - loss of 0.363528528507205\n",
      " - accuracy of 0.7602856878698224\n",
      "Epoch # 218:\n",
      " - loss of 0.3602865310250849\n",
      " - accuracy of 0.757365631163708\n",
      "Epoch # 219:\n",
      " - loss of 0.355107432042343\n",
      " - accuracy of 0.7572577662721893\n",
      "Epoch # 220:\n",
      " - loss of 0.3578649893906957\n",
      " - accuracy of 0.7514638806706114\n",
      "Epoch # 221:\n",
      " - loss of 0.36102575366047845\n",
      " - accuracy of 0.7517643614398423\n",
      "Epoch # 222:\n",
      " - loss of 0.35945990883209855\n",
      " - accuracy of 0.7548770340236686\n",
      "Epoch # 223:\n",
      " - loss of 0.3549792971012097\n",
      " - accuracy of 0.7450459196252465\n",
      "Epoch # 224:\n",
      " - loss of 0.353390345826817\n",
      " - accuracy of 0.7596847263313609\n",
      "Epoch # 225:\n",
      " - loss of 0.3530448145336575\n",
      " - accuracy of 0.7531589003944773\n",
      "Epoch # 226:\n",
      " - loss of 0.357308744304422\n",
      " - accuracy of 0.7579665927021696\n",
      "Epoch # 227:\n",
      " - loss of 0.35656438335992285\n",
      " - accuracy of 0.7497688609467456\n",
      "Epoch # 228:\n",
      " - loss of 0.3543092528547066\n",
      " - accuracy of 0.7502619575936884\n",
      "Epoch # 229:\n",
      " - loss of 0.35888889187200057\n",
      " - accuracy of 0.756980399408284\n",
      "Epoch # 230:\n",
      " - loss of 0.35753805683430845\n",
      " - accuracy of 0.7562715729783037\n",
      "Epoch # 231:\n",
      " - loss of 0.35965513096051516\n",
      " - accuracy of 0.7475576306706114\n",
      "Epoch # 232:\n",
      " - loss of 0.3551041498996209\n",
      " - accuracy of 0.7531589003944773\n",
      "Epoch # 233:\n",
      " - loss of 0.35568777806517005\n",
      " - accuracy of 0.7571730152859961\n",
      "Epoch # 234:\n",
      " - loss of 0.3503555384091133\n",
      " - accuracy of 0.7500693417159763\n",
      "Epoch # 235:\n",
      " - loss of 0.35407161755838257\n",
      " - accuracy of 0.7539755917159763\n",
      "Epoch # 236:\n",
      " - loss of 0.3584300728091871\n",
      " - accuracy of 0.7469566691321499\n",
      "Epoch # 237:\n",
      " - loss of 0.35335260672845703\n",
      " - accuracy of 0.748158592209073\n",
      "Epoch # 238:\n",
      " - loss of 0.35089589389050063\n",
      " - accuracy of 0.7534824950690335\n",
      "Epoch # 239:\n",
      " - loss of 0.3510376805988487\n",
      " - accuracy of 0.7447685527613412\n",
      "Epoch # 240:\n",
      " - loss of 0.3507543535192232\n",
      " - accuracy of 0.7434587647928994\n",
      "Epoch # 241:\n",
      " - loss of 0.3558118252650551\n",
      " - accuracy of 0.7483743219921105\n",
      "Epoch # 242:\n",
      " - loss of 0.34994628010452655\n",
      " - accuracy of 0.745069033530572\n",
      "Epoch # 243:\n",
      " - loss of 0.3510021365783065\n",
      " - accuracy of 0.7513791296844181\n",
      "Epoch # 244:\n",
      " - loss of 0.35726289544704454\n",
      " - accuracy of 0.7587832840236686\n",
      "Epoch # 245:\n",
      " - loss of 0.35252506383087323\n",
      " - accuracy of 0.7405618219921105\n",
      "Epoch # 246:\n",
      " - loss of 0.3581189953762552\n",
      " - accuracy of 0.752881533530572\n",
      "Epoch # 247:\n",
      " - loss of 0.35706971931284753\n",
      " - accuracy of 0.7459704758382644\n",
      "Epoch # 248:\n",
      " - loss of 0.353990587707303\n",
      " - accuracy of 0.7583749383629191\n",
      "Epoch # 249:\n",
      " - loss of 0.3532470505018741\n",
      " - accuracy of 0.7551775147928994\n",
      "Epoch # 250:\n",
      " - loss of 0.3509435049721584\n",
      " - accuracy of 0.7523653229783037\n",
      "Epoch # 251:\n",
      " - loss of 0.3580894304646386\n",
      " - accuracy of 0.750369822485207\n",
      "Epoch # 252:\n",
      " - loss of 0.35418761935498977\n",
      " - accuracy of 0.7494683801775147\n",
      "Epoch # 253:\n",
      " - loss of 0.3511325113727275\n",
      " - accuracy of 0.7515717455621301\n",
      "Epoch # 254:\n",
      " - loss of 0.3544905301597383\n",
      " - accuracy of 0.751679610453649\n",
      "Epoch # 255:\n",
      " - loss of 0.35579268886271304\n",
      " - accuracy of 0.7507781681459567\n",
      "Epoch # 256:\n",
      " - loss of 0.35187293373156286\n",
      " - accuracy of 0.7499614768244576\n",
      "Epoch # 257:\n",
      " - loss of 0.3515124760820094\n",
      " - accuracy of 0.7453695142998028\n",
      "Epoch # 258:\n",
      " - loss of 0.35118694567450004\n",
      " - accuracy of 0.7525810527613412\n",
      "Epoch # 259:\n",
      " - loss of 0.3511350221823955\n",
      " - accuracy of 0.748975283530572\n",
      "Epoch # 260:\n",
      " - loss of 0.35012857263214925\n",
      " - accuracy of 0.7543608234714003\n",
      "Epoch # 261:\n",
      " - loss of 0.3501139928177359\n",
      " - accuracy of 0.7519800912228797\n",
      "Epoch # 262:\n",
      " - loss of 0.35481470564137335\n",
      " - accuracy of 0.7479659763313609\n",
      "Epoch # 263:\n",
      " - loss of 0.3508641326772994\n",
      " - accuracy of 0.7527736686390532\n",
      "Epoch # 264:\n",
      " - loss of 0.3501076358527953\n",
      " - accuracy of 0.7544686883629191\n",
      "Epoch # 265:\n",
      " - loss of 0.3535034824972567\n",
      " - accuracy of 0.756787783530572\n",
      "Epoch # 266:\n",
      " - loss of 0.352785251494767\n",
      " - accuracy of 0.7539755917159763\n",
      "Epoch # 267:\n",
      " - loss of 0.3531616793018608\n",
      " - accuracy of 0.7522805719921105\n",
      "Epoch # 268:\n",
      " - loss of 0.35134215919291917\n",
      " - accuracy of 0.7514638806706114\n",
      "Epoch # 269:\n",
      " - loss of 0.35237429316205104\n",
      " - accuracy of 0.7502850714990138\n",
      "Epoch # 270:\n",
      " - loss of 0.3506769646625012\n",
      " - accuracy of 0.7517643614398423\n",
      "Epoch # 271:\n",
      " - loss of 0.3549041380196954\n",
      " - accuracy of 0.7515717455621301\n",
      "Epoch # 272:\n",
      " - loss of 0.3501367985050459\n",
      " - accuracy of 0.7521727071005917\n",
      "Epoch # 273:\n",
      " - loss of 0.3507392747678619\n",
      " - accuracy of 0.749167899408284\n",
      "Epoch # 274:\n",
      " - loss of 0.351423351733005\n",
      " - accuracy of 0.7441675912228797\n",
      "Epoch # 275:\n",
      " - loss of 0.3575907346707035\n",
      " - accuracy of 0.754276072485207\n",
      "Epoch # 276:\n",
      " - loss of 0.35240372216355975\n",
      " - accuracy of 0.746463572485207\n",
      "Epoch # 277:\n",
      " - loss of 0.34897639678008313\n",
      " - accuracy of 0.7427730522682445\n",
      "Epoch # 278:\n",
      " - loss of 0.3492729212494864\n",
      " - accuracy of 0.7506703032544378\n",
      "Epoch # 279:\n",
      " - loss of 0.3502075469148332\n",
      " - accuracy of 0.7479659763313609\n",
      "Epoch # 280:\n",
      " - loss of 0.34939958651860553\n",
      " - accuracy of 0.7509707840236686\n",
      "Epoch # 281:\n",
      " - loss of 0.3518453165528855\n",
      " - accuracy of 0.7526658037475346\n",
      "Epoch # 282:\n",
      " - loss of 0.34855335266981724\n",
      " - accuracy of 0.7509707840236686\n",
      "Epoch # 283:\n",
      " - loss of 0.3510840869900109\n",
      " - accuracy of 0.7462709566074951\n",
      "Epoch # 284:\n",
      " - loss of 0.35285672941357615\n",
      " - accuracy of 0.7469566691321499\n",
      "Epoch # 285:\n",
      " - loss of 0.3483168132207244\n",
      " - accuracy of 0.7510786489151874\n",
      "Epoch # 286:\n",
      " - loss of 0.3482354831868324\n",
      " - accuracy of 0.7446606878698224\n",
      "Epoch # 287:\n",
      " - loss of 0.35106150841943307\n",
      " - accuracy of 0.745069033530572\n",
      "Epoch # 288:\n",
      " - loss of 0.3487645794372052\n",
      " - accuracy of 0.7468719181459567\n",
      "Epoch # 289:\n",
      " - loss of 0.34863175847680095\n",
      " - accuracy of 0.7459704758382644\n",
      "Epoch # 290:\n",
      " - loss of 0.35161940105583356\n",
      " - accuracy of 0.7437592455621301\n",
      "Epoch # 291:\n",
      " - loss of 0.34960143498464485\n",
      " - accuracy of 0.7479659763313609\n",
      "Epoch # 292:\n",
      " - loss of 0.34708917652063326\n",
      " - accuracy of 0.7468719181459567\n",
      "Epoch # 293:\n",
      " - loss of 0.34628479737014584\n",
      " - accuracy of 0.7441675912228797\n",
      "Epoch # 294:\n",
      " - loss of 0.34890878502873407\n",
      " - accuracy of 0.750369822485207\n",
      "Epoch # 295:\n",
      " - loss of 0.35500602834466577\n",
      " - accuracy of 0.7440597263313609\n",
      "Epoch # 296:\n",
      " - loss of 0.3502659962517052\n",
      " - accuracy of 0.7474728796844181\n",
      "Epoch # 297:\n",
      " - loss of 0.35126984832079516\n",
      " - accuracy of 0.7497688609467456\n",
      "Epoch # 298:\n",
      " - loss of 0.3484661728863555\n",
      " - accuracy of 0.7505624383629191\n",
      "Epoch # 299:\n",
      " - loss of 0.35345116596003084\n",
      " - accuracy of 0.751679610453649\n",
      "Epoch # 300:\n",
      " - loss of 0.35194038898472624\n",
      " - accuracy of 0.7476654955621301\n",
      "Epoch # 301:\n",
      " - loss of 0.35294617064621137\n",
      " - accuracy of 0.7473650147928994\n",
      "Epoch # 302:\n",
      " - loss of 0.3498000288067233\n",
      " - accuracy of 0.7538677268244576\n",
      "Epoch # 303:\n",
      " - loss of 0.3509298606195312\n",
      " - accuracy of 0.745069033530572\n",
      "Epoch # 304:\n",
      " - loss of 0.34945656438380623\n",
      " - accuracy of 0.7427730522682445\n",
      "Epoch # 305:\n",
      " - loss of 0.3539589353373661\n",
      " - accuracy of 0.7480738412228797\n",
      "Epoch # 306:\n",
      " - loss of 0.35282662366899314\n",
      " - accuracy of 0.7473650147928994\n",
      "Epoch # 307:\n",
      " - loss of 0.3529372897700987\n",
      " - accuracy of 0.7429656681459567\n",
      "Epoch # 308:\n",
      " - loss of 0.3505029172281136\n",
      " - accuracy of 0.7554779955621301\n",
      "Epoch # 309:\n",
      " - loss of 0.34716230299737716\n",
      " - accuracy of 0.7401534763313609\n",
      "Epoch # 310:\n",
      " - loss of 0.34492239593595697\n",
      " - accuracy of 0.7431582840236686\n",
      "Epoch # 311:\n",
      " - loss of 0.34867414774526145\n",
      " - accuracy of 0.740346092209073\n",
      "Epoch # 312:\n",
      " - loss of 0.3502606134051862\n",
      " - accuracy of 0.747773360453649\n",
      "Epoch # 313:\n",
      " - loss of 0.3478265935960023\n",
      " - accuracy of 0.7395525147928994\n",
      "Epoch # 314:\n",
      " - loss of 0.34628725807735883\n",
      " - accuracy of 0.742172090729783\n",
      "Epoch # 315:\n",
      " - loss of 0.3553149315038165\n",
      " - accuracy of 0.7493605152859961\n",
      "Epoch # 316:\n",
      " - loss of 0.35423333338205365\n",
      " - accuracy of 0.7437592455621301\n",
      "Epoch # 317:\n",
      " - loss of 0.35343479195942623\n",
      " - accuracy of 0.7418484960552268\n",
      "Epoch # 318:\n",
      " - loss of 0.3496128620876782\n",
      " - accuracy of 0.7499614768244576\n",
      "Epoch # 319:\n",
      " - loss of 0.35265169958561515\n",
      " - accuracy of 0.752064842209073\n",
      "Epoch # 320:\n",
      " - loss of 0.35268837407879206\n",
      " - accuracy of 0.7529662845167653\n",
      "Epoch # 321:\n",
      " - loss of 0.3503013767194057\n",
      " - accuracy of 0.7440597263313609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 322:\n",
      " - loss of 0.34881644008528206\n",
      " - accuracy of 0.734744822485207\n",
      "Epoch # 323:\n",
      " - loss of 0.350515260644581\n",
      " - accuracy of 0.7367634368836291\n",
      "Epoch # 324:\n",
      " - loss of 0.3542271384582427\n",
      " - accuracy of 0.7480738412228797\n",
      "Epoch # 325:\n",
      " - loss of 0.35274624162250096\n",
      " - accuracy of 0.7519800912228797\n",
      "Epoch # 326:\n",
      " - loss of 0.3534018762301708\n",
      " - accuracy of 0.7562715729783037\n",
      "Epoch # 327:\n",
      " - loss of 0.3505738818127176\n",
      " - accuracy of 0.7479659763313609\n",
      "Epoch # 328:\n",
      " - loss of 0.3529860390269238\n",
      " - accuracy of 0.741162783530572\n",
      "Epoch # 329:\n",
      " - loss of 0.3525622739020177\n",
      " - accuracy of 0.7550696499013807\n",
      "Epoch # 330:\n",
      " - loss of 0.35265788327956543\n",
      " - accuracy of 0.7534824950690335\n",
      "Epoch # 331:\n",
      " - loss of 0.3507796442451108\n",
      " - accuracy of 0.7485669378698224\n",
      "Epoch # 332:\n",
      " - loss of 0.34783248279405676\n",
      " - accuracy of 0.7498767258382644\n",
      "Epoch # 333:\n",
      " - loss of 0.3470951910468115\n",
      " - accuracy of 0.7496609960552268\n",
      "Epoch # 334:\n",
      " - loss of 0.34312817101605275\n",
      " - accuracy of 0.7439518614398423\n",
      "Epoch # 335:\n",
      " - loss of 0.34603517239796366\n",
      " - accuracy of 0.7457778599605522\n",
      "Epoch # 336:\n",
      " - loss of 0.3462207290717369\n",
      " - accuracy of 0.7418484960552268\n",
      "Epoch # 337:\n",
      " - loss of 0.3482053681560185\n",
      " - accuracy of 0.7390594181459567\n",
      "Epoch # 338:\n",
      " - loss of 0.3473829486663791\n",
      " - accuracy of 0.7473881286982249\n",
      "Epoch # 339:\n",
      " - loss of 0.34484249058265043\n",
      " - accuracy of 0.7451768984220907\n",
      "Epoch # 340:\n",
      " - loss of 0.35438237249275334\n",
      " - accuracy of 0.751679610453649\n",
      "Epoch # 341:\n",
      " - loss of 0.3530188624697607\n",
      " - accuracy of 0.7458626109467456\n",
      "Epoch # 342:\n",
      " - loss of 0.35063554555321663\n",
      " - accuracy of 0.7415480152859961\n",
      "Epoch # 343:\n",
      " - loss of 0.3482824273155507\n",
      " - accuracy of 0.7523653229783037\n",
      "Epoch # 344:\n",
      " - loss of 0.3506121722540418\n",
      " - accuracy of 0.748158592209073\n",
      "Epoch # 345:\n",
      " - loss of 0.3478794736418747\n",
      " - accuracy of 0.7422568417159763\n",
      "Epoch # 346:\n",
      " - loss of 0.3457167049249013\n",
      " - accuracy of 0.7436513806706114\n",
      "Epoch # 347:\n",
      " - loss of 0.3508515542975946\n",
      " - accuracy of 0.754276072485207\n",
      "Epoch # 348:\n",
      " - loss of 0.35241860849557866\n",
      " - accuracy of 0.7458394970414202\n",
      "Epoch # 349:\n",
      " - loss of 0.3492369700745108\n",
      " - accuracy of 0.7444680719921105\n",
      "Epoch # 350:\n",
      " - loss of 0.34634739340503434\n",
      " - accuracy of 0.7461630917159763\n",
      "Epoch # 351:\n",
      " - loss of 0.3484446611525356\n",
      " - accuracy of 0.7486516888560157\n",
      "Epoch # 352:\n",
      " - loss of 0.35132052904165884\n",
      " - accuracy of 0.7460552268244576\n",
      "Epoch # 353:\n",
      " - loss of 0.34853147790915723\n",
      " - accuracy of 0.7368481878698224\n",
      "Epoch # 354:\n",
      " - loss of 0.3499099694300389\n",
      " - accuracy of 0.7465483234714003\n",
      "Epoch # 355:\n",
      " - loss of 0.3512820304159957\n",
      " - accuracy of 0.7485669378698224\n",
      "Epoch # 356:\n",
      " - loss of 0.3495539117982422\n",
      " - accuracy of 0.742557322485207\n",
      "Epoch # 357:\n",
      " - loss of 0.3486075480491067\n",
      " - accuracy of 0.7458626109467456\n",
      "Epoch # 358:\n",
      " - loss of 0.34582847788713983\n",
      " - accuracy of 0.7457547460552268\n",
      "Epoch # 359:\n",
      " - loss of 0.3491872556975498\n",
      " - accuracy of 0.7490600345167653\n",
      "Epoch # 360:\n",
      " - loss of 0.35360768458981445\n",
      " - accuracy of 0.7514638806706114\n",
      "Epoch # 361:\n",
      " - loss of 0.34646814068158466\n",
      " - accuracy of 0.7508629191321499\n",
      "Epoch # 362:\n",
      " - loss of 0.346640771785796\n",
      " - accuracy of 0.7461630917159763\n",
      "Epoch # 363:\n",
      " - loss of 0.3467889498685293\n",
      " - accuracy of 0.7418484960552268\n",
      "Epoch # 364:\n",
      " - loss of 0.34518193133211367\n",
      " - accuracy of 0.7507550542406312\n",
      "Epoch # 365:\n",
      " - loss of 0.3486161576089076\n",
      " - accuracy of 0.7471492850098619\n",
      "Epoch # 366:\n",
      " - loss of 0.3473533214146388\n",
      " - accuracy of 0.7515717455621301\n",
      "Epoch # 367:\n",
      " - loss of 0.3515588014885999\n",
      " - accuracy of 0.748158592209073\n",
      "Epoch # 368:\n",
      " - loss of 0.3483230968316396\n",
      " - accuracy of 0.7481817061143984\n",
      "Epoch # 369:\n",
      " - loss of 0.35104604828472874\n",
      " - accuracy of 0.7482664571005917\n",
      "Epoch # 370:\n",
      " - loss of 0.35019461249095807\n",
      " - accuracy of 0.7509707840236686\n",
      "Epoch # 371:\n",
      " - loss of 0.3492418556397664\n",
      " - accuracy of 0.7459473619329388\n",
      "Epoch # 372:\n",
      " - loss of 0.3476009247959524\n",
      " - accuracy of 0.7453464003944773\n",
      "Epoch # 373:\n",
      " - loss of 0.3476791615071504\n",
      " - accuracy of 0.7438439965483234\n",
      "Epoch # 374:\n",
      " - loss of 0.3449349556712137\n",
      " - accuracy of 0.7430504191321499\n",
      "Epoch # 375:\n",
      " - loss of 0.3427636426860008\n",
      " - accuracy of 0.749167899408284\n",
      "Epoch # 376:\n",
      " - loss of 0.34626698349984947\n",
      " - accuracy of 0.7478581114398423\n",
      "Epoch # 377:\n",
      " - loss of 0.3514119865381775\n",
      " - accuracy of 0.7473650147928994\n",
      "Epoch # 378:\n",
      " - loss of 0.344336718176874\n",
      " - accuracy of 0.7456699950690335\n",
      "Epoch # 379:\n",
      " - loss of 0.3456507957931878\n",
      " - accuracy of 0.741355399408284\n",
      "Epoch # 380:\n",
      " - loss of 0.34582726556609794\n",
      " - accuracy of 0.7433508999013807\n",
      "Epoch # 381:\n",
      " - loss of 0.342827456800834\n",
      " - accuracy of 0.740346092209073\n",
      "Epoch # 382:\n",
      " - loss of 0.3468564056255967\n",
      " - accuracy of 0.7461630917159763\n",
      "Epoch # 383:\n",
      " - loss of 0.3453499707190887\n",
      " - accuracy of 0.7426651873767258\n",
      "Epoch # 384:\n",
      " - loss of 0.34467982346021037\n",
      " - accuracy of 0.748975283530572\n",
      "Epoch # 385:\n",
      " - loss of 0.3452798834313517\n",
      " - accuracy of 0.7527736686390532\n",
      "Epoch # 386:\n",
      " - loss of 0.34580056686044314\n",
      " - accuracy of 0.7540834566074951\n",
      "Epoch # 387:\n",
      " - loss of 0.3471724989189618\n",
      " - accuracy of 0.7334581484220907\n",
      "Epoch # 388:\n",
      " - loss of 0.3486829522439247\n",
      " - accuracy of 0.7348526873767258\n",
      "Epoch # 389:\n",
      " - loss of 0.3475068272743824\n",
      " - accuracy of 0.7415480152859961\n",
      "Epoch # 390:\n",
      " - loss of 0.3451529574998911\n",
      " - accuracy of 0.7428578032544378\n",
      "Epoch # 391:\n",
      " - loss of 0.3434157730732563\n",
      " - accuracy of 0.7457778599605522\n",
      "Epoch # 392:\n",
      " - loss of 0.3441770245199618\n",
      " - accuracy of 0.745261649408284\n",
      "Epoch # 393:\n",
      " - loss of 0.3434913761661824\n",
      " - accuracy of 0.745069033530572\n",
      "Epoch # 394:\n",
      " - loss of 0.34630898173880464\n",
      " - accuracy of 0.7405618219921105\n",
      "Epoch # 395:\n",
      " - loss of 0.3464158938990699\n",
      " - accuracy of 0.7475576306706114\n",
      "Epoch # 396:\n",
      " - loss of 0.3465972257697064\n",
      " - accuracy of 0.7398529955621301\n",
      "Epoch # 397:\n",
      " - loss of 0.342479778084778\n",
      " - accuracy of 0.7439518614398423\n",
      "Epoch # 398:\n",
      " - loss of 0.3442540108293727\n",
      " - accuracy of 0.7417637450690335\n",
      "Epoch # 399:\n",
      " - loss of 0.3455041907547753\n",
      " - accuracy of 0.7383505917159763\n",
      "Epoch # 400:\n",
      " - loss of 0.34849938836650574\n",
      " - accuracy of 0.7478581114398423\n",
      "Epoch # 401:\n",
      " - loss of 0.35788014056026074\n",
      " - accuracy of 0.7471723989151874\n",
      "Epoch # 402:\n",
      " - loss of 0.3539906676840667\n",
      " - accuracy of 0.7501772066074951\n",
      "Epoch # 403:\n",
      " - loss of 0.3492982205417421\n",
      " - accuracy of 0.7500693417159763\n",
      "Epoch # 404:\n",
      " - loss of 0.3541858789425541\n",
      " - accuracy of 0.7440828402366864\n",
      "Epoch # 405:\n",
      " - loss of 0.35495531782147965\n",
      " - accuracy of 0.7513791296844181\n",
      "Epoch # 406:\n",
      " - loss of 0.3471259887235752\n",
      " - accuracy of 0.749167899408284\n",
      "Epoch # 407:\n",
      " - loss of 0.3463546608525198\n",
      " - accuracy of 0.7445528229783037\n",
      "Epoch # 408:\n",
      " - loss of 0.34567508878915204\n",
      " - accuracy of 0.7455621301775147\n",
      "Epoch # 409:\n",
      " - loss of 0.3416427905864762\n",
      " - accuracy of 0.7434587647928994\n",
      "Epoch # 410:\n",
      " - loss of 0.34433028713804514\n",
      " - accuracy of 0.7494452662721893\n",
      "Epoch # 411:\n",
      " - loss of 0.3498271932636482\n",
      " - accuracy of 0.7468488042406312\n",
      "Epoch # 412:\n",
      " - loss of 0.3458353215513598\n",
      " - accuracy of 0.7493605152859961\n",
      "Epoch # 413:\n",
      " - loss of 0.34229010545113236\n",
      " - accuracy of 0.7428578032544378\n",
      "Epoch # 414:\n",
      " - loss of 0.34445993955008647\n",
      " - accuracy of 0.7455621301775147\n",
      "Epoch # 415:\n",
      " - loss of 0.34458332699566074\n",
      " - accuracy of 0.7436744945759368\n",
      "Epoch # 416:\n",
      " - loss of 0.3454891444692289\n",
      " - accuracy of 0.744252342209073\n",
      "Epoch # 417:\n",
      " - loss of 0.3437735025145581\n",
      " - accuracy of 0.7445528229783037\n",
      "Epoch # 418:\n",
      " - loss of 0.34755919772933647\n",
      " - accuracy of 0.7500693417159763\n",
      "Epoch # 419:\n",
      " - loss of 0.348124037762195\n",
      " - accuracy of 0.7470645340236686\n",
      "Epoch # 420:\n",
      " - loss of 0.3453257736088573\n",
      " - accuracy of 0.744252342209073\n",
      "Epoch # 421:\n",
      " - loss of 0.3468532918587975\n",
      " - accuracy of 0.7488674186390532\n",
      "Epoch # 422:\n",
      " - loss of 0.3473233875013204\n",
      " - accuracy of 0.7462478427021696\n",
      "Epoch # 423:\n",
      " - loss of 0.349693500045417\n",
      " - accuracy of 0.7454542652859961\n",
      "Epoch # 424:\n",
      " - loss of 0.3498227785606891\n",
      " - accuracy of 0.7429425542406312\n",
      "Epoch # 425:\n",
      " - loss of 0.34653324910983946\n",
      " - accuracy of 0.7385432075936884\n",
      "Epoch # 426:\n",
      " - loss of 0.34954385063498494\n",
      " - accuracy of 0.7410549186390532\n",
      "Epoch # 427:\n",
      " - loss of 0.34718019929197097\n",
      " - accuracy of 0.7406465729783037\n",
      "Epoch # 428:\n",
      " - loss of 0.34542069011840265\n",
      " - accuracy of 0.7459473619329388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 429:\n",
      " - loss of 0.34733988222292655\n",
      " - accuracy of 0.7462709566074951\n",
      "Epoch # 430:\n",
      " - loss of 0.34711334771580166\n",
      " - accuracy of 0.7467640532544378\n",
      "Epoch # 431:\n",
      " - loss of 0.3474951664318785\n",
      " - accuracy of 0.7427499383629191\n",
      "Epoch # 432:\n",
      " - loss of 0.3497470035645121\n",
      " - accuracy of 0.7463788214990138\n",
      "Epoch # 433:\n",
      " - loss of 0.34929013266655556\n",
      " - accuracy of 0.7474728796844181\n",
      "Epoch # 434:\n",
      " - loss of 0.34822204781039323\n",
      " - accuracy of 0.7414632642998028\n",
      "Epoch # 435:\n",
      " - loss of 0.3484659682293445\n",
      " - accuracy of 0.7401534763313609\n",
      "Epoch # 436:\n",
      " - loss of 0.3446296434039655\n",
      " - accuracy of 0.746463572485207\n",
      "Epoch # 437:\n",
      " - loss of 0.3427773933623724\n",
      " - accuracy of 0.7495762450690335\n",
      "Epoch # 438:\n",
      " - loss of 0.3446231961682223\n",
      " - accuracy of 0.7466561883629191\n",
      "Epoch # 439:\n",
      " - loss of 0.34550452707470325\n",
      " - accuracy of 0.7455621301775147\n",
      "Epoch # 440:\n",
      " - loss of 0.34176704532282365\n",
      " - accuracy of 0.746078340729783\n",
      "Epoch # 441:\n",
      " - loss of 0.3447835071795229\n",
      " - accuracy of 0.7416558801775147\n",
      "Epoch # 442:\n",
      " - loss of 0.34574845483625566\n",
      " - accuracy of 0.746463572485207\n",
      "Epoch # 443:\n",
      " - loss of 0.3427209436605518\n",
      " - accuracy of 0.736439842209073\n",
      "Epoch # 444:\n",
      " - loss of 0.34583708269584584\n",
      " - accuracy of 0.7399377465483234\n",
      "Epoch # 445:\n",
      " - loss of 0.3497260377026986\n",
      " - accuracy of 0.7435666296844181\n",
      "Epoch # 446:\n",
      " - loss of 0.34653254206053874\n",
      " - accuracy of 0.7437592455621301\n",
      "Epoch # 447:\n",
      " - loss of 0.34719367080552566\n",
      " - accuracy of 0.7524731878698224\n",
      "Epoch # 448:\n",
      " - loss of 0.3452416305668688\n",
      " - accuracy of 0.7396603796844181\n",
      "Epoch # 449:\n",
      " - loss of 0.34748691356412453\n",
      " - accuracy of 0.7422568417159763\n",
      "Epoch # 450:\n",
      " - loss of 0.34613303055509853\n",
      " - accuracy of 0.7509707840236686\n",
      "Epoch # 451:\n",
      " - loss of 0.3466051805422502\n",
      " - accuracy of 0.7433740138067061\n",
      "Epoch # 452:\n",
      " - loss of 0.3453447810837612\n",
      " - accuracy of 0.7492757642998028\n",
      "Epoch # 453:\n",
      " - loss of 0.3491676297884632\n",
      " - accuracy of 0.7462709566074951\n",
      "Epoch # 454:\n",
      " - loss of 0.3459468722919335\n",
      " - accuracy of 0.7482664571005917\n",
      "Epoch # 455:\n",
      " - loss of 0.3438583928461812\n",
      " - accuracy of 0.7443602071005917\n",
      "Epoch # 456:\n",
      " - loss of 0.3406674355124506\n",
      " - accuracy of 0.7457778599605522\n",
      "Epoch # 457:\n",
      " - loss of 0.345646230134987\n",
      " - accuracy of 0.7496841099605522\n",
      "Epoch # 458:\n",
      " - loss of 0.3478433394777602\n",
      " - accuracy of 0.7419563609467456\n",
      "Epoch # 459:\n",
      " - loss of 0.3432722563184978\n",
      " - accuracy of 0.7410549186390532\n",
      "Epoch # 460:\n",
      " - loss of 0.34117626783928434\n",
      " - accuracy of 0.7393367850098619\n",
      "Epoch # 461:\n",
      " - loss of 0.34522807137401784\n",
      " - accuracy of 0.7478812253451677\n",
      "Epoch # 462:\n",
      " - loss of 0.34610904940372506\n",
      " - accuracy of 0.7445759368836291\n",
      "Epoch # 463:\n",
      " - loss of 0.34822099515493365\n",
      " - accuracy of 0.747773360453649\n",
      "Epoch # 464:\n",
      " - loss of 0.34681091122869134\n",
      " - accuracy of 0.748975283530572\n",
      "Epoch # 465:\n",
      " - loss of 0.3469670325661627\n",
      " - accuracy of 0.7381579758382644\n",
      "Epoch # 466:\n",
      " - loss of 0.3423359017585211\n",
      " - accuracy of 0.748975283530572\n",
      "Epoch # 467:\n",
      " - loss of 0.3455469719885628\n",
      " - accuracy of 0.7384584566074951\n",
      "Epoch # 468:\n",
      " - loss of 0.3518627154222433\n",
      " - accuracy of 0.7455621301775147\n",
      "Epoch # 469:\n",
      " - loss of 0.3483001562420297\n",
      " - accuracy of 0.745069033530572\n",
      "Epoch # 470:\n",
      " - loss of 0.3469608707560433\n",
      " - accuracy of 0.7466793022682445\n",
      "Epoch # 471:\n",
      " - loss of 0.3487344427385192\n",
      " - accuracy of 0.7502619575936884\n",
      "Epoch # 472:\n",
      " - loss of 0.3466130750622726\n",
      " - accuracy of 0.7468488042406312\n",
      "Epoch # 473:\n",
      " - loss of 0.3436307801644583\n",
      " - accuracy of 0.7455621301775147\n",
      "Epoch # 474:\n",
      " - loss of 0.3461644737328884\n",
      " - accuracy of 0.7401534763313609\n",
      "Epoch # 475:\n",
      " - loss of 0.34935518732105475\n",
      " - accuracy of 0.7404539571005917\n",
      "Epoch # 476:\n",
      " - loss of 0.3442080713412612\n",
      " - accuracy of 0.750369822485207\n",
      "Epoch # 477:\n",
      " - loss of 0.34326182413792267\n",
      " - accuracy of 0.7514638806706114\n",
      "Epoch # 478:\n",
      " - loss of 0.34398984736290533\n",
      " - accuracy of 0.7475807445759368\n",
      "Epoch # 479:\n",
      " - loss of 0.3434103667592081\n",
      " - accuracy of 0.7465714373767258\n",
      "Epoch # 480:\n",
      " - loss of 0.3401199723211464\n",
      " - accuracy of 0.7466561883629191\n",
      "Epoch # 481:\n",
      " - loss of 0.3426132754283251\n",
      " - accuracy of 0.7429425542406312\n",
      "Epoch # 482:\n",
      " - loss of 0.3422742618454827\n",
      " - accuracy of 0.7461630917159763\n",
      "Epoch # 483:\n",
      " - loss of 0.3399296888838644\n",
      " - accuracy of 0.744252342209073\n",
      "Epoch # 484:\n",
      " - loss of 0.3416049101790368\n",
      " - accuracy of 0.743867110453649\n",
      "Epoch # 485:\n",
      " - loss of 0.34104673283687537\n",
      " - accuracy of 0.7436513806706114\n",
      "Epoch # 486:\n",
      " - loss of 0.3443208810499901\n",
      " - accuracy of 0.7465714373767258\n",
      "Epoch # 487:\n",
      " - loss of 0.3413395589388511\n",
      " - accuracy of 0.7447685527613412\n",
      "Epoch # 488:\n",
      " - loss of 0.3446582345570919\n",
      " - accuracy of 0.7339512450690335\n",
      "Epoch # 489:\n",
      " - loss of 0.3406725008994485\n",
      " - accuracy of 0.733542899408284\n",
      "Epoch # 490:\n",
      " - loss of 0.34301362715769507\n",
      " - accuracy of 0.7366555719921105\n",
      "Epoch # 491:\n",
      " - loss of 0.3392502710871074\n",
      " - accuracy of 0.7350453032544378\n",
      "Epoch # 492:\n",
      " - loss of 0.3395962360256536\n",
      " - accuracy of 0.7403692061143984\n",
      "Epoch # 493:\n",
      " - loss of 0.34236553714471163\n",
      " - accuracy of 0.7364629561143984\n",
      "Epoch # 494:\n",
      " - loss of 0.3417246250282739\n",
      " - accuracy of 0.7447685527613412\n",
      "Epoch # 495:\n",
      " - loss of 0.3397744582327092\n",
      " - accuracy of 0.7390594181459567\n",
      "Epoch # 496:\n",
      " - loss of 0.34041130909885187\n",
      " - accuracy of 0.7354536489151874\n",
      "Epoch # 497:\n",
      " - loss of 0.34124190169544033\n",
      " - accuracy of 0.7357541296844181\n",
      "Epoch # 498:\n",
      " - loss of 0.343782269652339\n",
      " - accuracy of 0.7392520340236686\n",
      "Epoch # 499:\n",
      " - loss of 0.3458383641957085\n",
      " - accuracy of 0.7441675912228797\n",
      "Epoch # 500:\n",
      " - loss of 0.3460313376885105\n",
      " - accuracy of 0.7426651873767258\n"
     ]
    }
   ],
   "source": [
    "loss_vector = Float64[]\n",
    "accuracy_vector = Float64[]\n",
    "for epoch in 1:500\n",
    "    # Train the model\n",
    "    epoch_loss = Float64[]\n",
    "    for (x, y) in train_loader\n",
    "        (loss, y_pred, st), back = pullback(p -> compute_loss(x, y, model, p, st), ps)\n",
    "        gs = back((one(loss), nothing, nothing))[1]\n",
    "        opt_state, ps = Optimisers.update(opt_state, ps, gs)\n",
    "        push!(epoch_loss, loss)\n",
    "    end\n",
    "    avg_loss = mean(epoch_loss)\n",
    "    println(\"Epoch # $epoch:\\n - loss of $avg_loss\")\n",
    "    push!(loss_vector, avg_loss)\n",
    "\n",
    "    # Validate the model\n",
    "    epoch_accuracy = Float64[]\n",
    "    st_ = Lux.testmode(st)\n",
    "    for (x, y) in val_loader\n",
    "        (loss, y_pred, st_) = compute_loss(x, y, model, ps, st_)\n",
    "        acc = accuracy(y_pred, y)\n",
    "        push!(epoch_accuracy, acc)\n",
    "    end\n",
    "    avg_accuracy = mean(epoch_accuracy)\n",
    "    println(\" - accuracy of $avg_accuracy\")\n",
    "    push!(accuracy_vector, avg_accuracy)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "plot(loss_vector, label=\"loss\", legend=:bottom, color=:red, rightmargin = 1.5Plots.cm, bottommargin = 0.5Plots.cm, box = :on, fmt = :png)\n",
    "plot!(twinx(), accuracy_vector, label=\"accuracy\", legend=:outertopright, xlabel=\"epoch\", rightmargin = 1.5Plots.cm, bottommargin = 0.5Plots.cm, box = :on)\n",
    "using Dates\n",
    "timestamp = now()\n",
    "savefig(\"result-$timestamp.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JuliaLuxMLUtils 1.7.3",
   "language": "julia",
   "name": "julialuxmlutils-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
